{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70259f60-6b83-4ed9-85e6-3c99689d8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pin NumPy to < 2 and reinstall compatible wheels\n",
    "# %pip install -q \"numpy<2\"\n",
    "\n",
    "# # Force-reinstall all geo deps to match the NumPy ABI\n",
    "# %pip install -q --force-reinstall \\\n",
    "#   \"scipy==1.10.*\" \\\n",
    "#   \"networkx==2.8.8\" \\\n",
    "#   \"shapely==2.0.*\" \\\n",
    "#   \"pyproj==3.6.*\" \\\n",
    "#   \"rtree==1.2.*\" \\\n",
    "#   \"fiona==1.9.*\" \\\n",
    "#   \"geopandas==0.14.*\" \\\n",
    "#   \"osmnx==1.9.4\" \\\n",
    "#   folium\n",
    "\n",
    "# # (Optional) GEE API if you use the NDVI script\n",
    "# %pip install -q earthengine-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b74769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from the top of the script\n"
     ]
    }
   ],
   "source": [
    "print(\"hello from the top of the script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e3d20-5ed2-4eb5-9663-999d63f5ffb3",
   "metadata": {},
   "source": [
    "GEEE toke: 4/1AVGzR1AS0MVg6BzSSkfBv0SS0xIVdGA7KB0veQckyspF7QvKqr5zTmdmOp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b071216-0424-47ab-952c-7da2ca7475cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geocoding AOI…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_nominatim.py:65: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  return _nominatim_request(params=params, request_type=request_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pedestrian network…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:359: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:369: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting graph to local metric CRS…\n",
      "Downloading OSM green areas (parks and related tags)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing NDVI green polygons from GEE (this is server-side fast)…\n",
      "GEE composite picked: S2_SR 2025-06-01..2025-09-25 cloud<80%\n",
      "Green polygons: OSM=25 | NDVI=600 | merged=625\n",
      "Computing destination nodes from green centroids…\n",
      "Assigning time costs to edges…\n",
      "Running multi-source shortest path (Dijkstra)…\n",
      "Classifying edges by coverage (5 and 10 minutes)…\n",
      "Uncovered road segments beyond 10 minutes: 32888\n",
      "Building isochrone polygons…\n",
      "Selecting candidate micro-park points…\n",
      "Building Folium map…\n",
      "✅ Saved map in current folder: narayanganj_green_access_ndvi_osm.html\n",
      "✅ Also saved to: C:\\Users\\Dipankar Mitra/Downloads\\narayanganj_green_access_ndvi_osm.html\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# narayanganj_green_access_ndvi_osm.py\n",
    "# Combines Google Earth Engine (Sentinel-2 NDVI) + OSM green areas to compute\n",
    "# 5/10-minute walking access and propose micro-park candidates in Narayanganj.\n",
    "#\n",
    "# Deps:\n",
    "#   pip install earthengine-api folium osmnx geopandas shapely networkx\n",
    "#   # If you hit NumPy 2.x ABI issues with GeoPandas/Shapely wheels:\n",
    "#   # pip install \"numpy<2\" && pip install --force-reinstall geopandas shapely pyproj fiona rtree\n",
    "#\n",
    "# First run will prompt a browser for Earth Engine auth (ee.Authenticate()).\n",
    "\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# ---- Load heavy libs with a friendly error if NumPy ABI is mismatched ----\n",
    "try:\n",
    "    import ee\n",
    "    import folium\n",
    "    import networkx as nx\n",
    "    import osmnx as ox\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point, LineString\n",
    "    from shapely.ops import unary_union\n",
    "except Exception as e:\n",
    "    raise SystemExit(\n",
    "        f\"\\nImport error: {e}\\n\\n\"\n",
    "        \"This often happens when GeoPandas/Shapely wheels were built for NumPy 1.x but you're on NumPy 2.x.\\n\"\n",
    "        \"Quick fix (in a clean venv):\\n\"\n",
    "        \"  pip install 'numpy<2'\\n\"\n",
    "        \"  pip install --force-reinstall geopandas shapely pyproj fiona rtree\\n\"\n",
    "        \"Or use a fresh 'conda create -n aoi python=3.11' env and install the deps.\\n\"\n",
    "    )\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ----------------------------\n",
    "# OSMNX COMPATIBILITY HELPERS\n",
    "# ----------------------------\n",
    "try:\n",
    "    # osmnx >= 2.x\n",
    "    from osmnx.features import features_from_polygon as osm_features_from_polygon\n",
    "except Exception:\n",
    "    try:\n",
    "        # osmnx <= 1.x\n",
    "        from osmnx import geometries_from_polygon as osm_features_from_polygon\n",
    "    except Exception:\n",
    "        raise SystemExit(\n",
    "            \"Your osmnx version is missing polygon geometries. Please: pip install --upgrade osmnx.\"\n",
    "        )\n",
    "\n",
    "# ----------------------------\n",
    "# SETTINGS\n",
    "# ----------------------------\n",
    "PLACE = \"Narayanganj, Dhaka Division, Bangladesh\"\n",
    "\n",
    "# NDVI thresholds\n",
    "NDVI_GREEN_MIN = 0.35   # pixels with NDVI >= 0.35 are considered 'green' (tweakable)\n",
    "\n",
    "# Walking thresholds (seconds)\n",
    "T5 = 5 * 60       # 5 minutes\n",
    "T10 = 10 * 60     # 10 minutes\n",
    "WALK_MPS = 1.3    # ~4.7 km/h\n",
    "\n",
    "# OSM tags to include as green destinations\n",
    "GREEN_TAGS = {\n",
    "    \"leisure\": [\"park\", \"garden\"],\n",
    "    \"landuse\": [\"recreation_ground\", \"grass\"],\n",
    "    \"natural\": [\"wood\"],\n",
    "}\n",
    "\n",
    "# Buffer for visualizing reachable edges as polygons (purely cosmetic on the map)\n",
    "EDGE_BUFFER_M = 25\n",
    "\n",
    "# Number of micro-park candidates to propose (midpoints of longest uncovered edges)\n",
    "TOP_N_CANDIDATES = 20\n",
    "\n",
    "# GEE composite tries (recent → broader → cloudier)\n",
    "DATE_TRIES = [\n",
    "    (\"2025-09-01\", \"2025-09-25\", 20),\n",
    "    (\"2025-08-01\", \"2025-09-25\", 40),\n",
    "    (\"2025-06-01\", \"2025-09-25\", 80),\n",
    "]\n",
    "\n",
    "# Output paths\n",
    "USER = os.getenv(\"USER\") or os.getenv(\"USERNAME\") or \"yourusername\"\n",
    "DOWNLOADS = os.path.expanduser(f\"~/Downloads\")\n",
    "OUT_HTML = os.path.join(DOWNLOADS, \"narayanganj_green_access_ndvi_osm.html\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# EARTH ENGINE HELPERS\n",
    "# ----------------------------\n",
    "def ee_init():\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except Exception:\n",
    "        ee.Authenticate()   # opens browser once\n",
    "        ee.Initialize()\n",
    "\n",
    "\n",
    "def choose_s2_composite(aoi_geom):\n",
    "    \"\"\"Pick a recent, low-cloud Sentinel-2 composite (L2A preferred, fallback to L1C).\"\"\"\n",
    "    for (start, end, cloud) in DATE_TRIES:\n",
    "        s2sr = (ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "                .filterBounds(aoi_geom)\n",
    "                .filterDate(start, end)\n",
    "                .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", cloud)))\n",
    "        if s2sr.size().getInfo() > 0:\n",
    "            return s2sr.median(), f\"S2_SR {start}..{end} cloud<{cloud}%\"\n",
    "        s2l1c = (ee.ImageCollection(\"COPERNICUS/S2\")\n",
    "                 .filterBounds(aoi_geom)\n",
    "                 .filterDate(start, end)\n",
    "                 .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", cloud)))\n",
    "        if s2l1c.size().getInfo() > 0:\n",
    "            return s2l1c.median(), f\"S2_L1C {start}..{end} cloud<{cloud}%\"\n",
    "    raise SystemExit(\"No recent Sentinel-2 scenes found for AOI after fallbacks.\")\n",
    "\n",
    "\n",
    "def gee_green_polygons(aoi_geom, ndvi_min=NDVI_GREEN_MIN, scale=30, max_features=500):\n",
    "    \"\"\"\n",
    "    Build green polygons from NDVI on GEE:\n",
    "      - Compute NDVI = (B8 - B4)/(B8 + B4)\n",
    "      - Threshold NDVI >= ndvi_min\n",
    "      - Vectorize (reduceToVectors), simplify, and return as GeoJSON-like dict\n",
    "    \"\"\"\n",
    "    composite, desc = choose_s2_composite(aoi_geom)\n",
    "    print(\"GEE composite picked:\", desc)\n",
    "    ndvi = composite.normalizedDifference([\"B8\", \"B4\"]).rename(\"NDVI\")\n",
    "    green_mask = ndvi.gte(ndvi_min).selfMask()\n",
    "\n",
    "    # Vectorize (beware of complexity → use bestEffort + limit)\n",
    "    vectors = green_mask.reduceToVectors(\n",
    "        geometry=aoi_geom,\n",
    "        scale=scale,                 # 10-30 m typical; larger → simpler geometry\n",
    "        geometryType=\"polygon\",\n",
    "        labelProperty=\"class\",\n",
    "        bestEffort=True,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "\n",
    "    vectors = vectors.limit(max_features)  # keep client payload manageable\n",
    "    fc = vectors.getInfo()  # bring small feature collection client-side\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    feats = fc.get(\"features\", [])\n",
    "    if not feats:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "\n",
    "    geoms = []\n",
    "    for f in feats:\n",
    "        geom = f.get(\"geometry\")\n",
    "        if geom:\n",
    "            geoms.append(geom)\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(feats, crs=\"EPSG:4326\")\n",
    "    # Keep only polygons\n",
    "    gdf = gdf[gdf.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])].copy()\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# CORE LOGIC\n",
    "# ----------------------------\n",
    "def line_midpoint(geom: LineString):\n",
    "    try:\n",
    "        return geom.interpolate(0.5, normalized=True)\n",
    "    except Exception:\n",
    "        if geom.geom_type == \"LineString\" and len(geom.coords) >= 2:\n",
    "            (x1, y1), (x2, y2) = geom.coords[0], geom.coords[-1]\n",
    "            return Point((x1 + x2) / 2.0, (y1 + y2) / 2.0)\n",
    "        return geom.centroid\n",
    "\n",
    "\n",
    "def make_iso_polygon(edges_subset, buffer_m=EDGE_BUFFER_M):\n",
    "    if edges_subset.empty:\n",
    "        return None\n",
    "    buffered = edges_subset.geometry.buffer(buffer_m)\n",
    "    merged = unary_union(list(buffered.values))\n",
    "    return gpd.GeoSeries([merged], crs=edges_subset.crs)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Earth Engine init\n",
    "    ee_init()\n",
    "\n",
    "    # OSMnx settings\n",
    "    ox.settings.log_console = True\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.timeout = 180\n",
    "\n",
    "    print(\"Geocoding AOI…\")\n",
    "    aoi = ox.geocode_to_gdf(PLACE)\n",
    "    if aoi.empty:\n",
    "        raise SystemExit(\"Could not geocode the AOI name.\")\n",
    "    aoi_polygon = aoi.geometry.iloc[0]\n",
    "\n",
    "    print(\"Downloading pedestrian network…\")\n",
    "    G = ox.graph_from_polygon(aoi_polygon, network_type=\"walk\", simplify=True)\n",
    "\n",
    "    print(\"Projecting graph to local metric CRS…\")\n",
    "    Gp = ox.project_graph(G)\n",
    "    nodes_gdf, edges_gdf = ox.graph_to_gdfs(Gp)\n",
    "    if \"u\" not in edges_gdf.columns or \"v\" not in edges_gdf.columns:\n",
    "        edges_gdf = edges_gdf.reset_index()\n",
    "    graph_crs = nodes_gdf.crs\n",
    "\n",
    "    # ---- Pull OSM green polygons\n",
    "    print(\"Downloading OSM green areas (parks and related tags)…\")\n",
    "    green_layers = []\n",
    "    for k, v in GREEN_TAGS.items():\n",
    "        try:\n",
    "            g = osm_features_from_polygon(aoi_polygon, tags={k: v})\n",
    "            if g is not None and not g.empty:\n",
    "                green_layers.append(g)\n",
    "        except Exception:\n",
    "            pass\n",
    "    osm_greens = None\n",
    "    if green_layers:\n",
    "        base_crs = getattr(green_layers[0], \"crs\", None) or \"EPSG:4326\"\n",
    "        osm_greens = gpd.GeoDataFrame(\n",
    "            gpd.pd.concat(green_layers, ignore_index=True), crs=base_crs\n",
    "        )\n",
    "        osm_greens = osm_greens[osm_greens.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])].copy()\n",
    "\n",
    "    # ---- Pull NDVI-based green polygons from GEE (limited count/complexity)\n",
    "    print(\"Vectorizing NDVI green polygons from GEE (this is server-side fast)…\")\n",
    "    # Build a simple rectangle AOI for GEE from the OSM aoi bounds\n",
    "    minx, miny, maxx, maxy = aoi.to_crs(epsg=4326).total_bounds\n",
    "    gee_aoi = ee.Geometry.Rectangle([minx, miny, maxx, maxy])\n",
    "\n",
    "    ndvi_greens = gee_green_polygons(gee_aoi, ndvi_min=NDVI_GREEN_MIN, scale=30, max_features=600)\n",
    "\n",
    "    # ---- Merge OSM + NDVI polygons\n",
    "    greens_list = []\n",
    "    if osm_greens is not None and not osm_greens.empty:\n",
    "        greens_list.append(osm_greens.to_crs(epsg=4326))\n",
    "    if ndvi_greens is not None and not ndvi_greens.empty:\n",
    "        greens_list.append(ndvi_greens.to_crs(epsg=4326))\n",
    "\n",
    "    if not greens_list:\n",
    "        raise SystemExit(\"No green polygons found from OSM or NDVI. Try lowering NDVI_GREEN_MIN or broadening dates.\")\n",
    "    greens_all = gpd.GeoDataFrame(gpd.pd.concat(greens_list, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    print(f\"Green polygons: OSM={0 if osm_greens is None else len(osm_greens)} | NDVI={len(ndvi_greens)} | merged={len(greens_all)}\")\n",
    "\n",
    "    # Project green polygons to graph CRS\n",
    "    greens_poly_proj = greens_all.to_crs(graph_crs)\n",
    "\n",
    "    # Destination nodes = nearest graph nodes to green centroids\n",
    "    print(\"Computing destination nodes from green centroids…\")\n",
    "    greens_poly_proj[\"centroid\"] = greens_poly_proj.geometry.centroid\n",
    "    dest_nodes = set()\n",
    "    for c in greens_poly_proj[\"centroid\"]:\n",
    "        try:\n",
    "            nid = ox.distance.nearest_nodes(Gp, X=c.x, Y=c.y)\n",
    "            dest_nodes.add(nid)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if not dest_nodes:\n",
    "        raise SystemExit(\"No destination nodes mapped from green centroids. Check green layers / AOI.\")\n",
    "\n",
    "    # Edge travel times (seconds)\n",
    "    print(\"Assigning time costs to edges…\")\n",
    "    for u, v, k, data in Gp.edges(keys=True, data=True):\n",
    "        length_m = float(data.get(\"length\", 0.0)) or 0.0\n",
    "        data[\"time_s\"] = length_m / WALK_MPS\n",
    "\n",
    "    # Multi-source Dijkstra to nearest green (min time per node)\n",
    "    print(\"Running multi-source shortest path (Dijkstra)…\")\n",
    "    Gr = Gp.reverse()  # reverse trick for multi-destination\n",
    "    min_time_s = nx.multi_source_dijkstra_path_length(Gr, sources=list(dest_nodes), weight=\"time_s\")\n",
    "\n",
    "    def covered_by_threshold(u, v, threshold_s):\n",
    "        tu = min_time_s.get(u, math.inf)\n",
    "        tv = min_time_s.get(v, math.inf)\n",
    "        return (tu <= threshold_s) or (tv <= threshold_s)\n",
    "\n",
    "    def both_beyond_10(u, v):\n",
    "        return (min_time_s.get(u, math.inf) > T10) and (min_time_s.get(v, math.inf) > T10)\n",
    "\n",
    "    print(\"Classifying edges by coverage (5 and 10 minutes)…\")\n",
    "    edges_gdf[\"covered_5min\"] = edges_gdf.apply(lambda r: covered_by_threshold(r[\"u\"], r[\"v\"], T5), axis=1)\n",
    "    edges_gdf[\"covered_10min\"] = edges_gdf.apply(lambda r: covered_by_threshold(r[\"u\"], r[\"v\"], T10), axis=1)\n",
    "    edges_gdf[\"uncovered_10min\"] = edges_gdf.apply(lambda r: both_beyond_10(r[\"u\"], r[\"v\"]), axis=1)\n",
    "    uncovered = edges_gdf[edges_gdf[\"uncovered_10min\"]].copy()\n",
    "    print(f\"Uncovered road segments beyond 10 minutes: {len(uncovered)}\")\n",
    "\n",
    "    # Isochrone polygons (from covered edges)\n",
    "    print(\"Building isochrone polygons…\")\n",
    "    iso5_edges = edges_gdf[edges_gdf[\"covered_5min\"]]\n",
    "    iso10_edges = edges_gdf[edges_gdf[\"covered_10min\"]]\n",
    "    iso5_poly = make_iso_polygon(iso5_edges, buffer_m=EDGE_BUFFER_M)\n",
    "    iso10_poly = make_iso_polygon(iso10_edges, buffer_m=EDGE_BUFFER_M)\n",
    "\n",
    "    # Candidate micro-park points: midpoints of longest uncovered segments\n",
    "    print(\"Selecting candidate micro-park points…\")\n",
    "    uncovered[\"length_m\"] = uncovered.geometry.length\n",
    "    candidates = uncovered.sort_values(\"length_m\", ascending=False).head(TOP_N_CANDIDATES).copy()\n",
    "    candidates[\"midpt\"] = candidates.geometry.apply(line_midpoint)\n",
    "\n",
    "    # -----------------------\n",
    "    # Folium map (WGS84)\n",
    "    # -----------------------\n",
    "    print(\"Building Folium map…\")\n",
    "    aoi_latlon = aoi.to_crs(epsg=4326)\n",
    "    center = [aoi_latlon.geometry.iloc[0].centroid.y, aoi_latlon.geometry.iloc[0].centroid.x]\n",
    "\n",
    "    edges_latlon = edges_gdf.to_crs(epsg=4326)\n",
    "    uncovered_latlon = uncovered.to_crs(epsg=4326)\n",
    "    greens_latlon = greens_poly_proj.to_crs(epsg=4326)\n",
    "    cand_latlon = gpd.GeoDataFrame(geometry=candidates[\"midpt\"], crs=graph_crs).to_crs(epsg=4326)\n",
    "    iso5_latlon = iso5_poly.to_crs(epsg=4326) if iso5_poly is not None else None\n",
    "    iso10_latlon = iso10_poly.to_crs(epsg=4326) if iso10_poly is not None else None\n",
    "\n",
    "    m = folium.Map(location=center, zoom_start=12, control_scale=True, tiles=\"cartodbpositron\")\n",
    "\n",
    "    # Green polygons (merged OSM + NDVI)\n",
    "    folium.GeoJson(\n",
    "        greens_latlon[[\"geometry\"]],\n",
    "        name=f\"Green areas (OSM + NDVI≥{NDVI_GREEN_MIN:.2f})\",\n",
    "        style_function=lambda _: {\"color\": \"#2e7d32\", \"weight\": 1, \"fillColor\": \"#66bb6a\", \"fillOpacity\": 0.35},\n",
    "    ).add_to(m)\n",
    "\n",
    "    # 10-min isochrone\n",
    "    if iso10_latlon is not None:\n",
    "        folium.GeoJson(\n",
    "            iso10_latlon.__geo_interface__,\n",
    "            name=\"Within 10 min of green\",\n",
    "            style_function=lambda _: {\"color\": \"#ff9800\", \"weight\": 1, \"fillColor\": \"#ffcc80\", \"fillOpacity\": 0.25},\n",
    "        ).add_to(m)\n",
    "\n",
    "    # 5-min isochrone\n",
    "    if iso5_latlon is not None:\n",
    "        folium.GeoJson(\n",
    "            iso5_latlon.__geo_interface__,\n",
    "            name=\"Within 5 min of green\",\n",
    "            style_function=lambda _: {\"color\": \"#1976d2\", \"weight\": 1, \"fillColor\": \"#90caf9\", \"fillOpacity\": 0.25},\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Uncovered segments (>10 min)\n",
    "    folium.GeoJson(\n",
    "        uncovered_latlon[[\"geometry\"]],\n",
    "        name=\"Road segments beyond 10 min (need green access)\",\n",
    "        style_function=lambda _: {\"color\": \"#e53935\", \"weight\": 2, \"opacity\": 0.9},\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Candidate micro-park markers — DISTINCT COLOR (bright blue)\n",
    "    for i, row in cand_latlon.iterrows():\n",
    "        y, x = row.geometry.y, row.geometry.x\n",
    "        folium.CircleMarker(\n",
    "            location=(y, x),\n",
    "            radius=6,\n",
    "            color=\"#2962FF\",\n",
    "            fill=True,\n",
    "            fill_color=\"#2962FF\",\n",
    "            fill_opacity=0.95,\n",
    "            popup=f\"Candidate site #{i+1}\",\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Simple legend\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"position: fixed; bottom: 18px; left: 18px; z-index:9999; background: white;\n",
    "                padding: 10px 12px; border: 1px solid #ccc; border-radius: 6px; font-size: 13px;\">\n",
    "      <b>Legend</b><br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#66bb6a;border:1px solid #2e7d32;\"></span>\n",
    "      Green areas (OSM + NDVI≥{NDVI_GREEN_MIN:.2f})<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#ffcc80;border:1px solid #ff9800;\"></span>\n",
    "      ≤ 10 min walk<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#90caf9;border:1px solid #1976d2;\"></span>\n",
    "      ≤ 5 min walk<br>\n",
    "      <span style=\"display:inline-block;width:18px;height:2px;background:#e53935;vertical-align:middle;display:inline-block;\"></span>\n",
    "      Uncovered roads (>10 min)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#2962FF;border:1px solid #2962FF;\"></span>\n",
    "      Candidate micro-park\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    # Save map\n",
    "    out_cwd = \"narayanganj_green_access_ndvi_osm.html\"\n",
    "    m.save(out_cwd)\n",
    "    print(f\"✅ Saved map in current folder: {out_cwd}\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(DOWNLOADS, exist_ok=True)\n",
    "        m.save(OUT_HTML)\n",
    "        print(f\"✅ Also saved to: {OUT_HTML}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save to ~/Downloads:\", e)\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca0b5e",
   "metadata": {},
   "source": [
    "## Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff959ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DISTRICT_N     geom_type  \\\n",
      "0         Bagerhat       Polygon   \n",
      "1        Bandarban       Polygon   \n",
      "2          Barguna       Polygon   \n",
      "3         Barishal       Polygon   \n",
      "4            Bhola       Polygon   \n",
      "5           Bogura       Polygon   \n",
      "6     Brahmanbaria       Polygon   \n",
      "7         Chandpur       Polygon   \n",
      "8  Chapainababganj       Polygon   \n",
      "9       Chattogram  MultiPolygon   \n",
      "\n",
      "                                              bounds  \n",
      "0  (89.53096578800006, 21.729321597000023, 89.967...  \n",
      "1  (92.06212887200007, 21.183487962000072, 92.680...  \n",
      "2  (89.87748492500003, 21.844804644000078, 90.373...  \n",
      "3  (90.01724254800007, 22.453568824000058, 90.701...  \n",
      "4  (90.52266803000003, 21.838527058000068, 91.023...  \n",
      "5  (88.96305583600008, 24.535122898000054, 89.752...  \n",
      "6  (90.72118216400008, 23.646293997000043, 91.328...  \n",
      "7  (90.52720869200004, 22.983006697000064, 91.028...  \n",
      "8  (88.00816912400006, 24.416130831000032, 88.512...  \n",
      "9  (91.31120302500005, 21.855339392000076, 92.218...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dipankar Mitra\\AppData\\Local\\Temp\\ipykernel_11708\\450428360.py:53: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid = nar.geometry.centroid.iloc[0]  # OK for centering even in geographic CRS\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load upazila polygons\n",
    "# -----------------------------\n",
    "shapefile_path = \"Area boundary/Nasa-Area-Boundary/BD_Upazila_BBS21.shp\"\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Ensure WGS84 (lat/lon) for web maps\n",
    "if gdf.crs is None:\n",
    "    # If you know the original CRS, set it here instead of assuming WGS84.\n",
    "    # Example if it's already lon/lat WGS84:\n",
    "    gdf = gdf.set_crs(epsg=4326)\n",
    "else:\n",
    "    if gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build district boundaries\n",
    "# -----------------------------\n",
    "# Dissolve upazilas by district name to get district polygons\n",
    "dist = gdf[['DISTRICT_N', 'geometry']].dissolve(by='DISTRICT_N', as_index=False)\n",
    "dist = dist.sort_values('DISTRICT_N').reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Print compact preview\n",
    "# -----------------------------\n",
    "# geometry type + bounding box for a quick “print the district boundary” view\n",
    "preview = dist.copy()\n",
    "preview[\"geom_type\"] = preview.geometry.geom_type\n",
    "\n",
    "b = preview.geometry.bounds  # This is a DataFrame with columns: minx, miny, maxx, maxy\n",
    "preview[\"bounds\"] = list(zip(b[\"minx\"], b[\"miny\"], b[\"maxx\"], b[\"maxy\"]))\n",
    "\n",
    "print(preview[['DISTRICT_N', 'geom_type', 'bounds']].head(10))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Extract Dhaka district\n",
    "# -----------------------------\n",
    "target_name = \"Dhaka\"\n",
    "nar = dist[dist[\"DISTRICT_N\"].str.casefold() == target_name.casefold()]\n",
    "\n",
    "if nar.empty:\n",
    "    # Helpful hint if the name doesn't match exactly\n",
    "    available = \", \".join(dist[\"DISTRICT_N\"].head(10).tolist()) + (\"...\" if len(dist) > 10 else \"\")\n",
    "    raise ValueError(\n",
    "        f\"District '{target_name}' not found in DISTRICT_N. \"\n",
    "        f\"Example names in your data: {available}\"\n",
    "    )\n",
    "\n",
    "# Use centroid for initial map centering\n",
    "centroid = nar.geometry.centroid.iloc[0]  # OK for centering even in geographic CRS\n",
    "center_latlon = [centroid.y, centroid.x]\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Build Folium map\n",
    "# -----------------------------\n",
    "m = folium.Map(location=center_latlon, zoom_start=9, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Layer: all districts (thin outline, no fill)\n",
    "folium.GeoJson(\n",
    "    dist.__geo_interface__,\n",
    "    name=\"All District Boundaries\",\n",
    "    style_function=lambda feat: {\"color\": \"#555555\", \"weight\": 1, \"fill\": False},\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"DISTRICT_N\"], aliases=[\"District\"])\n",
    ").add_to(m)\n",
    "\n",
    "# Layer: Narayanganj (thicker red outline + light fill)\n",
    "folium.GeoJson(\n",
    "    nar.__geo_interface__,\n",
    "    name=\"Dhaka\",\n",
    "    style_function=lambda feat: {\n",
    "        \"color\": \"#d73027\",\n",
    "        \"weight\": 3,\n",
    "        \"fill\": True,\n",
    "        \"fillOpacity\": 0.25\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"DISTRICT_N\"], aliases=[\"District\"])\n",
    ").add_to(m)\n",
    "\n",
    "# # Marker at Narayanganj centroid\n",
    "# folium.Marker(\n",
    "#     location=center_latlon,\n",
    "#     popup=f\"{target_name} District\",\n",
    "#     icon=folium.Icon(color=\"red\", icon=\"info-sign\")\n",
    "# ).add_to(m)\n",
    "\n",
    "# # # Fit view to Narayanganj bounds (nice tight framing)\n",
    "# # minx, miny, maxx, maxy = nar.total_bounds\n",
    "# # m.fit_bounds([[miny, minx], [maxy, maxx]])\n",
    "\n",
    "# # folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# # # -----------------------------\n",
    "# # # 6) Save map\n",
    "# # # -----------------------------\n",
    "# # out_html = \"bangladesh_districts_narayanganj.html\"\n",
    "# # m.save(out_html)\n",
    "# # print(f\"Map saved to: {out_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb030c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    POLYGON ((90.52495 23.57348, 90.52442 23.57372...\n",
       "Name: geometry, dtype: geometry"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview[dist['DISTRICT_N'] == 'Narayanganj'].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc7417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90.42920437600009, 23.536132402000078, 90.74156867800008, 23.895628744000078]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview[dist['DISTRICT_N'] == 'Narayanganj'].bounds.iloc[0,:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de505cdb-e1e9-49d0-bc56-1f3fa451d3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Earth Engine…\n",
      "AOI: [90.42920437600009, 23.536132402000078, 90.74156867800008, 23.895628744000078] | Window: 2025-07-28 → 2025-09-26\n",
      "✅ Saved: /Users/Dipankar Mitra/Downloads/narayanganj_aq_hotspots_readable.html\n"
     ]
    }
   ],
   "source": [
    "# narayanganj_aq_hotspots_readable.py\n",
    "# Same data/logic as before (S5P NO2, S5P CO, MAIAC AOD -> PM2.5 proxy),\n",
    "# but with a presentation geared for general users.\n",
    "\n",
    "import os\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import ee\n",
    "import folium\n",
    "from folium.plugins import MiniMap, Fullscreen, MousePosition, MeasureControl\n",
    "from shapely.geometry import Point, MultiPoint, mapping\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "# AOI_BBOX = [90.32, 23.70, 90.52, 23.86]  # Narayanganj (W,S,E,N)\n",
    "        #    [minx, miny, maxx, maxy]\n",
    "DAYS_BACK = 60\n",
    "END = date.today()\n",
    "START = END - timedelta(days=DAYS_BACK)\n",
    "\n",
    "SCALE_M = 1000\n",
    "MAX_POINTS = 5000\n",
    "\n",
    "W_NO2 = 0.6\n",
    "W_PM25 = 0.6\n",
    "W_CO  = 0.3\n",
    "\n",
    "# Hotspot selection\n",
    "Z_THRESHOLD = 1.0\n",
    "PCTL_THRESHOLD = 85.0\n",
    "\n",
    "# Clustering (pure python)\n",
    "EPS_METERS = 1500.0\n",
    "MIN_SAMPLES = 6\n",
    "\n",
    "# Severity buckets (z-score of combined AQ index)\n",
    "SEVERE_Z = 2.0\n",
    "HIGH_Z   = 1.0\n",
    "ELEV_Z   = 0.5\n",
    "\n",
    "COLORS = {\n",
    "    \"severe\": \"#d32f2f\",\n",
    "    \"high\":   \"#fb8c00\",\n",
    "    \"elev\":   \"#ffd54f\",\n",
    "    \"hull\":   \"#444444\",\n",
    "    \"gray\":   \"#9e9e9e\",\n",
    "}\n",
    "\n",
    "USER = os.getenv(\"USER\") or os.getenv(\"USERNAME\") or \"user\"\n",
    "OUT_HTML = f\"/Users/{USER}/Downloads/narayanganj_aq_hotspots_readable.html\"\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "TARGET_DISTRICT = \"Narayanganj\"\n",
    "polygon = preview[preview['DISTRICT_N'] == TARGET_DISTRICT].geometry.iloc[0]\n",
    "geoJson = mapping(polygon)\n",
    "AOI_BBOX = preview[preview['DISTRICT_N'] == 'Narayanganj'].bounds.iloc[0,:].to_list()\n",
    "\n",
    "\n",
    "def ee_init():\n",
    "    try: ee.Initialize()\n",
    "    except Exception:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "\n",
    "\n",
    "def build_mean_images(aoi, start_iso, end_iso):\n",
    "    no2 = (ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_NO2\")\n",
    "           .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "           .select(\"tropospheric_NO2_column_number_density\")\n",
    "           .mean().rename(\"no2\")).clip(aoi)\n",
    "\n",
    "    co = (ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_CO\")\n",
    "          .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "          .select(\"CO_column_number_density\")\n",
    "          .mean().rename(\"co\")).clip(aoi)\n",
    "\n",
    "    aod = (ee.ImageCollection(\"MODIS/061/MCD19A2_GRANULES\")\n",
    "           .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "           .select(\"Optical_Depth_047\")\n",
    "           .mean().rename(\"aod\")).clip(aoi)\n",
    "\n",
    "    pm25 = aod.multiply(60.0).rename(\"pm25\")  # simple proxy\n",
    "    return no2, pm25, co\n",
    "\n",
    "\n",
    "def sample_grid(aoi, img_stack, scale_m=SCALE_M, max_points=MAX_POINTS):\n",
    "    fc = img_stack.sample(region=aoi, scale=scale_m, geometries=True)\n",
    "    feats = fc.limit(max_points).getInfo().get(\"features\", [])\n",
    "    rows = []\n",
    "    for f in feats:\n",
    "        geom = f.get(\"geometry\", {})\n",
    "        if geom.get(\"type\") != \"Point\": continue\n",
    "        lon, lat = geom[\"coordinates\"]\n",
    "        p = f.get(\"properties\", {})\n",
    "        no2, pm25, co = p.get(\"no2\"), p.get(\"pm25\"), p.get(\"co\")\n",
    "        if None in (no2, pm25, co): continue\n",
    "        rows.append({\"lat\": float(lat), \"lon\": float(lon),\n",
    "                     \"no2\": float(no2), \"pm25\": float(pm25), \"co\": float(co)})\n",
    "    return rows\n",
    "\n",
    "\n",
    "def zscores(vals):\n",
    "    good = [v for v in vals if v is not None and math.isfinite(v)]\n",
    "    if len(good) < 2: return [0.0 for _ in vals]\n",
    "    mean = sum(good)/len(good)\n",
    "    var  = sum((v-mean)**2 for v in good)/len(good)\n",
    "    std  = math.sqrt(max(var, 1e-12))\n",
    "    return [0.0 if (v is None or not math.isfinite(v)) else (v-mean)/std for v in vals]\n",
    "\n",
    "\n",
    "def p_rank(all_vals, v):\n",
    "    s = sorted(all_vals)\n",
    "    if not s: return 0.0\n",
    "    cnt = sum(1 for x in s if x <= v)\n",
    "    return 100.0 * cnt / len(s)\n",
    "\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = p2 - p1\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "\n",
    "def cluster_dbscan(points, eps_m=EPS_METERS, min_samples=MIN_SAMPLES):\n",
    "    n = len(points)\n",
    "    visited = [False]*n\n",
    "    clusters = [-1]*n\n",
    "    nbrs = [[] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if haversine_m(points[i][\"lat\"], points[i][\"lon\"], points[j][\"lat\"], points[j][\"lon\"]) <= eps_m:\n",
    "                nbrs[i].append(j); nbrs[j].append(i)\n",
    "    cid = 0\n",
    "    for i in range(n):\n",
    "        if visited[i]: continue\n",
    "        visited[i] = True\n",
    "        if len(nbrs[i]) + 1 < min_samples:\n",
    "            clusters[i] = -1; continue\n",
    "        clusters[i] = cid\n",
    "        seeds = list(nbrs[i]); k = 0\n",
    "        while k < len(seeds):\n",
    "            j = seeds[k]\n",
    "            if not visited[j]:\n",
    "                visited[j] = True\n",
    "                if len(nbrs[j]) + 1 >= min_samples:\n",
    "                    for q in nbrs[j]:\n",
    "                        if q not in seeds: seeds.append(q)\n",
    "            if clusters[j] < 0: clusters[j] = cid\n",
    "            k += 1\n",
    "        cid += 1\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def severity_from_z(z):\n",
    "    if z >= SEVERE_Z: return \"severe\"\n",
    "    if z >= HIGH_Z:   return \"high\"\n",
    "    if z >= ELEV_Z:   return \"elev\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_map(aoi_bbox, hotspots, clusters):\n",
    "    lat_c = (aoi_bbox[1] + aoi_bbox[3]) / 2.0\n",
    "    lon_c = (aoi_bbox[0] + aoi_bbox[2]) / 2.0\n",
    "    m = folium.Map(location=[lat_c, lon_c], zoom_start=12,\n",
    "                   tiles=\"cartodbpositron\", control_scale=True)\n",
    "\n",
    "    # Cluster hulls (soft polygons)\n",
    "    by_cluster = {}\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        if cid < 0: continue\n",
    "        by_cluster.setdefault(cid, []).append(hp)\n",
    "\n",
    "    for cid, pts in by_cluster.items():\n",
    "        zs = [p[\"aq_index_z\"] for p in pts]\n",
    "        avgz = sum(zs)/len(zs)\n",
    "        sev = severity_from_z(avgz) or \"elev\"\n",
    "        color = COLORS[sev]\n",
    "        # convex hull in WGS84 (approximate)\n",
    "        mp = MultiPoint([Point(p[\"lon\"], p[\"lat\"]) for p in pts])\n",
    "        try:\n",
    "            hull = mp.convex_hull\n",
    "            folium.GeoJson(\n",
    "                data=hull.__geo_interface__,\n",
    "                name=f\"Cluster {cid} ({sev}, n={len(pts)})\",\n",
    "                style_function=lambda _,\n",
    "                                   c=color: {\"color\": c, \"weight\": 2, \"fillColor\": c, \"fillOpacity\": 0.18},\n",
    "                tooltip=f\"Cluster {cid} — {sev.upper()} (n={len(pts)})\"\n",
    "            ).add_to(m)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Hotspot markers with intuitive size/color and plain-language popup\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        sev = severity_from_z(hp[\"aq_index_z\"])\n",
    "        if sev is None:\n",
    "            continue  # hide low-evidence points\n",
    "        color = COLORS[sev]\n",
    "        # size by severity\n",
    "        radius = 6 if sev == \"elev\" else (8 if sev == \"high\" else 10)\n",
    "        hint = []\n",
    "        if hp[\"no2_z\"] >= 1.0: hint.append(\"High NO₂ → traffic/industry\")\n",
    "        if hp[\"pm25_z\"] >= 1.0: hint.append(\"High PM₂.₅ (AOD proxy) → dust/combustion\")\n",
    "        if hp[\"co_z\"]  >= 1.0: hint.append(\"High CO → combustion/transport\")\n",
    "        hint_text = \"<br>\".join(hint) if hint else \"Mixed drivers\"\n",
    "\n",
    "        folium.CircleMarker(\n",
    "            location=(hp[\"lat\"], hp[\"lon\"]),\n",
    "            radius=radius,\n",
    "            color=color, fill=True, fill_color=color, fill_opacity=0.95,\n",
    "            tooltip=f\"{sev.upper()} hotspot\",\n",
    "            popup=(f\"<b>{sev.upper()} hotspot</b><br>\"\n",
    "                   f\"AQ index z = {hp['aq_index_z']:.2f} (top {int(hp['percentile'])}%)<br>\"\n",
    "                   f\"NO₂ z: {hp['no2_z']:.2f} | PM₂.₅ z: {hp['pm25_z']:.2f} | CO z: {hp['co_z']:.2f}<br>\"\n",
    "                   f\"{hint_text}\")\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Map widgets\n",
    "    MiniMap(toggle_display=True, position=\"bottomright\").add_to(m)\n",
    "    Fullscreen().add_to(m)\n",
    "    MousePosition(position=\"topright\",\n",
    "                  separator=\" | \",\n",
    "                  prefix=\"Lat/Lon:\").add_to(m)\n",
    "    MeasureControl(position=\"topright\", primary_length_unit='kilometers').add_to(m)\n",
    "\n",
    "    # Legend\n",
    "    legend = \"\"\"\n",
    "    <div style=\"position: fixed; bottom: 18px; left: 18px; z-index:9999; background: white;\n",
    "                padding: 10px 12px; border: 1px solid #ccc; border-radius: 6px; font-size: 13px;\">\n",
    "      <b>Air-Quality Hotspots (60-day avg)</b><br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#d32f2f;border:1px solid #d32f2f;\"></span>\n",
    "      Severe (≥ 2σ above AOI mean)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#fb8c00;border:1px solid #fb8c00;\"></span>\n",
    "      High (1–2σ)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#ffd54f;border:1px solid #ffd54f;\"></span>\n",
    "      Elevated (0.5–1σ)<br>\n",
    "      <i>Shaded polygons show cluster areas.</i>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend))\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing Earth Engine…\")\n",
    "    ee_init()\n",
    "\n",
    "    aoi = ee.Geometry(geoJson)\n",
    "    start_iso, end_iso = str(START), str(END)\n",
    "    print(f\"AOI: {AOI_BBOX} | Window: {start_iso} → {end_iso}\")\n",
    "\n",
    "    # Means\n",
    "    no2_img, pm25_img, co_img = build_mean_images(aoi, start_iso, end_iso)\n",
    "    stack = no2_img.addBands(pm25_img).addBands(co_img)\n",
    "\n",
    "    # Sample grid\n",
    "    rows = sample_grid(aoi, stack, scale_m=SCALE_M, max_points=MAX_POINTS)\n",
    "    if not rows:\n",
    "        raise SystemExit(\"No samples. Try expanding AOI or increasing DAYS_BACK.\")\n",
    "\n",
    "    # Z-scores\n",
    "    no2_z = zscores([r[\"no2\"] for r in rows])\n",
    "    pm25_z = zscores([r[\"pm25\"] for r in rows])\n",
    "    co_z   = zscores([r[\"co\"] for r in rows])\n",
    "    aq_raw = [W_NO2*n + W_PM25*p + W_CO*c for n, p, c in zip(no2_z, pm25_z, co_z)]\n",
    "    aq_index_z = zscores(aq_raw)\n",
    "\n",
    "    # Pick hotspots (≥1σ or ≥85th percentile)\n",
    "    def prc(vs, v): return p_rank(vs, v)\n",
    "    pcts = [prc(aq_index_z, v) for v in aq_index_z]\n",
    "    hotspots = []\n",
    "    for r, nz, pz, cz, az, pr in zip(rows, no2_z, pm25_z, co_z, aq_index_z, pcts):\n",
    "        if (az >= Z_THRESHOLD) or (pr >= PCTL_THRESHOLD):\n",
    "            hotspots.append({\n",
    "                \"lat\": r[\"lat\"], \"lon\": r[\"lon\"],\n",
    "                \"no2_z\": nz, \"pm25_z\": pz, \"co_z\": cz,\n",
    "                \"aq_index_z\": az, \"percentile\": pr\n",
    "            })\n",
    "\n",
    "    # Cluster\n",
    "    clusters = cluster_dbscan(hotspots, eps_m=EPS_METERS, min_samples=MIN_SAMPLES) if hotspots else []\n",
    "\n",
    "    # Map\n",
    "    m = build_map(AOI_BBOX, hotspots, clusters)\n",
    "    os.makedirs(os.path.dirname(OUT_HTML), exist_ok=True)\n",
    "    m.save(OUT_HTML)\n",
    "    print(f\"✅ Saved: {OUT_HTML}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048dd655-1a6e-4917-b140-710ce1880cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Earth Engine…\n",
      "AOI: [90.32, 23.7, 90.52, 23.86] | Window: 2025-07-28 → 2025-09-26\n",
      "Sampling ~1000 m grid (<= 5000 points)…\n",
      "Hotspot points selected: 79\n",
      "✅ Saved UHI map to: /Users/Dipankar Mitra/Downloads/narayanganj_uhi_hotspots.html\n",
      "Open this file in your browser to explore hotspots.\n"
     ]
    }
   ],
   "source": [
    "# narayanganj_uhi_hotspots.py\n",
    "# Urban heat island (UHI) hotspots from NASA MODIS LST (daytime), 60-day mean.\n",
    "# Makes an easy-to-read Folium map with hotspot polygons + markers.\n",
    "\n",
    "import os\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import ee\n",
    "import folium\n",
    "from folium.plugins import MiniMap, Fullscreen, MousePosition, MeasureControl\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "\n",
    "# ------------- CONFIG -------------\n",
    "AOI_BBOX = [90.32, 23.70, 90.52, 23.86]  # Narayanganj (W,S,E,N)\n",
    "DAYS_BACK = 60\n",
    "END = date.today()\n",
    "START = END - timedelta(days=DAYS_BACK)\n",
    "\n",
    "SCALE_M = 1000        # sampling grid; 1000 m ≈ MODIS 1km native\n",
    "MAX_POINTS = 5000\n",
    "\n",
    "# Hotspot selection\n",
    "Z_THRESHOLD = 1.0     # ≥1σ above AOI mean\n",
    "PCTL_THRESHOLD = 85.0 # or top 15%\n",
    "\n",
    "# Clustering (pure python DBSCAN)\n",
    "EPS_METERS = 1500.0\n",
    "MIN_SAMPLES = 6\n",
    "\n",
    "# Severity buckets by LST z-score\n",
    "SEVERE_Z = 2.0\n",
    "HIGH_Z   = 1.5\n",
    "ELEV_Z   = 1.0\n",
    "\n",
    "COLORS = {\n",
    "    \"severe\": \"#b71c1c\",  # dark red\n",
    "    \"high\":   \"#e53935\",  # red\n",
    "    \"elev\":   \"#fb8c00\",  # orange\n",
    "    \"hull\":   \"#444444\",\n",
    "    \"cool\":   \"#4fc3f7\",  # optional cool overlay color\n",
    "}\n",
    "\n",
    "USER = os.getenv(\"USER\") or os.getenv(\"USERNAME\") or \"user\"\n",
    "OUT_HTML = f\"/Users/{USER}/Downloads/narayanganj_uhi_hotspots.html\"\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "def ee_init():\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except Exception:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "\n",
    "\n",
    "def build_lst_day_mean(aoi, start_iso, end_iso):\n",
    "    \"\"\"\n",
    "    Use MODIS/061/MOD11A2 (8-day, 1km) Daytime LST.\n",
    "    Units: Kelvin * 0.02. Convert to °C and mask invalids.\n",
    "    \"\"\"\n",
    "    coll = (ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "            .filterBounds(aoi)\n",
    "            .filterDate(start_iso, end_iso)\n",
    "            .select(\"LST_Day_1km\"))\n",
    "    # mask zero or negative (fill) values\n",
    "    coll = coll.map(lambda img: img.updateMask(img.gt(0)))\n",
    "    lst_mean_k = coll.mean()  # still in scaled Kelvin\n",
    "    lst_c = lst_mean_k.multiply(0.02).subtract(273.15).rename(\"lst_c\").clip(aoi)\n",
    "    return lst_c\n",
    "\n",
    "\n",
    "def sample_grid(aoi, img, scale_m=SCALE_M, max_points=MAX_POINTS):\n",
    "    fc = img.sample(region=aoi, scale=scale_m, geometries=True)\n",
    "    feats = fc.limit(max_points).getInfo().get(\"features\", [])\n",
    "    rows = []\n",
    "    for f in feats:\n",
    "        geom = f.get(\"geometry\", {})\n",
    "        if geom.get(\"type\") != \"Point\":\n",
    "            continue\n",
    "        lon, lat = geom[\"coordinates\"]\n",
    "        v = f.get(\"properties\", {}).get(\"lst_c\", None)\n",
    "        if v is None or not math.isfinite(v):\n",
    "            continue\n",
    "        rows.append({\"lat\": float(lat), \"lon\": float(lon), \"lst_c\": float(v)})\n",
    "    return rows\n",
    "\n",
    "\n",
    "def zscores(vals):\n",
    "    good = [v for v in vals if v is not None and math.isfinite(v)]\n",
    "    if len(good) < 2:\n",
    "        return [0.0 for _ in vals]\n",
    "    mean = sum(good)/len(good)\n",
    "    var  = sum((v-mean)**2 for v in good)/len(good)\n",
    "    std  = math.sqrt(max(var, 1e-12))\n",
    "    return [0.0 if (v is None or not math.isfinite(v)) else (v-mean)/std for v in vals]\n",
    "\n",
    "\n",
    "def p_rank(all_vals, v):\n",
    "    s = sorted(all_vals)\n",
    "    if not s: return 0.0\n",
    "    cnt = sum(1 for x in s if x <= v)\n",
    "    return 100.0 * cnt / len(s)\n",
    "\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = p2 - p1\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "\n",
    "def cluster_dbscan(points, eps_m=EPS_METERS, min_samples=MIN_SAMPLES):\n",
    "    n = len(points)\n",
    "    visited = [False]*n\n",
    "    clusters = [-1]*n\n",
    "    nbrs = [[] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if haversine_m(points[i][\"lat\"], points[i][\"lon\"], points[j][\"lat\"], points[j][\"lon\"]) <= eps_m:\n",
    "                nbrs[i].append(j); nbrs[j].append(i)\n",
    "    cid = 0\n",
    "    for i in range(n):\n",
    "        if visited[i]: continue\n",
    "        visited[i] = True\n",
    "        if len(nbrs[i]) + 1 < min_samples:\n",
    "            clusters[i] = -1; continue\n",
    "        clusters[i] = cid\n",
    "        seeds = list(nbrs[i]); k = 0\n",
    "        while k < len(seeds):\n",
    "            j = seeds[k]\n",
    "            if not visited[j]:\n",
    "                visited[j] = True\n",
    "                if len(nbrs[j]) + 1 >= min_samples:\n",
    "                    for q in nbrs[j]:\n",
    "                        if q not in seeds: seeds.append(q)\n",
    "            if clusters[j] < 0: clusters[j] = cid\n",
    "            k += 1\n",
    "        cid += 1\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def severity_from_z(z):\n",
    "    if z >= SEVERE_Z: return \"severe\"\n",
    "    if z >= HIGH_Z:   return \"high\"\n",
    "    if z >= ELEV_Z:   return \"elev\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_map(aoi_bbox, hotspots, clusters):\n",
    "    lat_c = (aoi_bbox[1] + aoi_bbox[3]) / 2.0\n",
    "    lon_c = (aoi_bbox[0] + aoi_bbox[2]) / 2.0\n",
    "    m = folium.Map(location=[lat_c, lon_c], zoom_start=12,\n",
    "                   tiles=\"cartodbpositron\", control_scale=True)\n",
    "\n",
    "    # Draw cluster convex hulls (polygons) colored by average severity\n",
    "    by_cluster = {}\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        if cid < 0: continue\n",
    "        by_cluster.setdefault(cid, []).append(hp)\n",
    "\n",
    "    for cid, pts in by_cluster.items():\n",
    "        zs = [p[\"lst_z\"] for p in pts]\n",
    "        avgz = sum(zs)/len(zs)\n",
    "        sev = severity_from_z(avgz) or \"elev\"\n",
    "        color = COLORS[sev]\n",
    "        mp = MultiPoint([Point(p[\"lon\"], p[\"lat\"]) for p in pts])\n",
    "        try:\n",
    "            hull = mp.convex_hull\n",
    "            folium.GeoJson(\n",
    "                data=hull.__geo_interface__,\n",
    "                name=f\"Cluster {cid} ({sev}, n={len(pts)})\",\n",
    "                style_function=lambda _, c=color: {\"color\": c, \"weight\": 2,\n",
    "                                                   \"fillColor\": c, \"fillOpacity\": 0.18},\n",
    "                tooltip=f\"UHI Cluster {cid} — {sev.upper()} (n={len(pts)})\"\n",
    "            ).add_to(m)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Hotspot markers\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        sev = severity_from_z(hp[\"lst_z\"])\n",
    "        if sev is None:\n",
    "            continue\n",
    "        color = COLORS[sev]\n",
    "        radius = 6 if sev == \"elev\" else (8 if sev == \"high\" else 10)\n",
    "        folium.CircleMarker(\n",
    "            location=(hp[\"lat\"], hp[\"lon\"]),\n",
    "            radius=radius,\n",
    "            color=color, fill=True, fill_color=color, fill_opacity=0.95,\n",
    "            tooltip=f\"{sev.upper()} UHI hotspot\",\n",
    "            popup=(f\"<b>{sev.upper()} UHI hotspot</b><br>\"\n",
    "                   f\"LST: {hp['lst_c']:.1f} °C<br>\"\n",
    "                   f\"LST z-score: {hp['lst_z']:.2f} (top {int(hp['percentile'])}%)\")\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Widgets + legend\n",
    "    MiniMap(toggle_display=True, position=\"bottomright\").add_to(m)\n",
    "    Fullscreen().add_to(m)\n",
    "    MousePosition(position=\"topright\", separator=\" | \", prefix=\"Lat/Lon:\").add_to(m)\n",
    "    MeasureControl(position=\"topright\", primary_length_unit='kilometers').add_to(m)\n",
    "\n",
    "    legend = f\"\"\"\n",
    "    <div style=\"position: fixed; bottom: 18px; left: 18px; z-index:9999; background: white;\n",
    "                padding: 10px 12px; border: 1px solid #ccc; border-radius: 6px; font-size: 13px;\">\n",
    "      <b>Urban Heat Island Hotspots (Daytime LST, {DAYS_BACK}-day mean)</b><br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:{COLORS['severe']};border:1px solid {COLORS['severe']};\"></span>\n",
    "      Severe (≥{SEVERE_Z}σ above AOI mean)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:{COLORS['high']};border:1px solid {COLORS['high']};\"></span>\n",
    "      High ({HIGH_Z}–{SEVERE_Z}σ)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:{COLORS['elev']};border:1px solid {COLORS['elev']};\"></span>\n",
    "      Elevated ({ELEV_Z}–{HIGH_Z}σ)<br>\n",
    "      <i>Polygons show hotspot cluster areas.</i>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend))\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing Earth Engine…\")\n",
    "    ee_init()\n",
    "\n",
    "    aoi = ee.Geometry.Rectangle(AOI_BBOX)\n",
    "    start_iso, end_iso = str(START), str(END)\n",
    "    print(f\"AOI: {AOI_BBOX} | Window: {start_iso} → {end_iso}\")\n",
    "\n",
    "    # Build 60-day mean daytime LST (°C)\n",
    "    lst_img = build_lst_day_mean(aoi, start_iso, end_iso)\n",
    "\n",
    "    # Sample grid\n",
    "    print(f\"Sampling ~{SCALE_M} m grid (<= {MAX_POINTS} points)…\")\n",
    "    rows = sample_grid(aoi, lst_img, scale_m=SCALE_M, max_points=MAX_POINTS)\n",
    "    if not rows:\n",
    "        raise SystemExit(\"No samples. Try increasing AOI, DAYS_BACK, or MAX_POINTS.\")\n",
    "\n",
    "    # Z-scores and selection\n",
    "    lst_vals = [r[\"lst_c\"] for r in rows]\n",
    "    lst_z = zscores(lst_vals)\n",
    "    pcts  = [p_rank(lst_z, v) for v in lst_z]\n",
    "\n",
    "    hotspots = []\n",
    "    for r, z, pr in zip(rows, lst_z, pcts):\n",
    "        if (z >= Z_THRESHOLD) or (pr >= PCTL_THRESHOLD):\n",
    "            hotspots.append({\n",
    "                \"lat\": r[\"lat\"], \"lon\": r[\"lon\"],\n",
    "                \"lst_c\": r[\"lst_c\"], \"lst_z\": z, \"percentile\": pr\n",
    "            })\n",
    "\n",
    "    print(f\"Hotspot points selected: {len(hotspots)}\")\n",
    "\n",
    "    # Cluster\n",
    "    clusters = cluster_dbscan(hotspots, eps_m=EPS_METERS, min_samples=MIN_SAMPLES) if hotspots else []\n",
    "\n",
    "    # Map\n",
    "    m = build_map(AOI_BBOX, hotspots, clusters)\n",
    "    os.makedirs(os.path.dirname(OUT_HTML), exist_ok=True)\n",
    "    m.save(OUT_HTML)\n",
    "    print(f\"✅ Saved UHI map to: {OUT_HTML}\\nOpen this file in your browser to explore hotspots.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
