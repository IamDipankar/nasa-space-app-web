{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70259f60-6b83-4ed9-85e6-3c99689d8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pin NumPy to < 2 and reinstall compatible wheels\n",
    "# %pip install -q \"numpy<2\"\n",
    "\n",
    "# # Force-reinstall all geo deps to match the NumPy ABI\n",
    "# %pip install -q --force-reinstall \\\n",
    "#   \"scipy==1.10.*\" \\\n",
    "#   \"networkx==2.8.8\" \\\n",
    "#   \"shapely==2.0.*\" \\\n",
    "#   \"pyproj==3.6.*\" \\\n",
    "#   \"rtree==1.2.*\" \\\n",
    "#   \"fiona==1.9.*\" \\\n",
    "#   \"geopandas==0.14.*\" \\\n",
    "#   \"osmnx==1.9.4\" \\\n",
    "#   folium\n",
    "\n",
    "# # (Optional) GEE API if you use the NDVI script\n",
    "# %pip install -q earthengine-api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e3d20-5ed2-4eb5-9663-999d63f5ffb3",
   "metadata": {},
   "source": [
    "GEEE toke: 4/1AVGzR1AS0MVg6BzSSkfBv0SS0xIVdGA7KB0veQckyspF7QvKqr5zTmdmOp8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85e8bc",
   "metadata": {},
   "source": [
    "## Location specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf3221-804e-45ab-ba1e-b6322cd6b87d",
   "metadata": {},
   "source": [
    "# Green Spaces Build \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215fe46-75ac-4391-9153-28a383acb708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geocoding AOI…\n",
      "Downloading pedestrian network…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_nominatim.py:65: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  return _nominatim_request(params=params, request_type=request_type)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:359: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:369: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting graph to local metric CRS…\n",
      "Downloading OSM green areas…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing NDVI green polygons (GEE)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\ee\\deprecation.py:209: DeprecationWarning: \n",
      "\n",
      "Attention required for COPERNICUS/S2_SR! You are using a deprecated asset.\n",
      "To make sure your code keeps working, please update it.\n",
      "Learn more: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n",
      "\n",
      "  warnings.warn(warning, category=DeprecationWarning)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\ee\\deprecation.py:209: DeprecationWarning: \n",
      "\n",
      "Attention required for COPERNICUS/S2! You are using a deprecated asset.\n",
      "To make sure your code keeps working, please update it.\n",
      "Learn more: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\n",
      "\n",
      "  warnings.warn(warning, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEE composite picked: S2_SR 2025-06-01..2025-09-25 cloud<80%\n",
      "Green polygons: OSM=25 | NDVI=700 | merged=725\n",
      "Computing destination nodes from green centroids…\n",
      "Assigning time costs to edges…\n",
      "Running multi-source shortest path (Dijkstra)…\n",
      "Classifying edges by coverage…\n",
      "Uncovered road segments >10 min: 32884\n",
      "Building isochrone polygons…\n",
      "Selecting candidate micro-park points…\n",
      "Downloading OSM context layers…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing batched metrics (EE)…\n",
      "Population raster not available; walkshed population will be 'n/a'.\n",
      "Computing local OSM metrics…\n",
      "\n",
      "Building Folium map…\n",
      "\n",
      "================= Candidate Site Context =================\n",
      "\n",
      "📍 Candidate #1  (Lat, Lon: 23.864477, 90.557852)\n",
      "  Water: nearest mapped water is ~262 m (~3.4 min walk). Near water (100–500 m). — ~262 m (~3.4 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 1.2826086956521743, max 2.0. Very rarely wet — area is usually dry.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.974218750000034°C. Heat: mild (~28.974218750000034°C).\n",
      "  Urban form: building cover ~n/a% & roads ~2.7 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #2  (Lat, Lon: 23.762769, 90.507250)\n",
      "  Water: nearest mapped water is ~45 m (~0.6 min walk). Very close to water (<100 m). — ~45 m (~0.6 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 62.556630971993435, max 74.0. Frequently/permanently wet — likely near river/pond or flood-prone.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown • historic water nearby\n",
      "  Heat (Apr–Jun): MODIS≈30.05643835616443°C. Heat: mild (~30.05643835616443°C).\n",
      "  Urban form: building cover ~1.6% & roads ~5.3 km/km² → very low building coverage; moderate road network\n",
      "\n",
      "📍 Candidate #3  (Lat, Lon: 23.724885, 90.673295)\n",
      "  Water: nearest mapped water is ~837 m (~10.7 min walk). Far from water (>500 m). — ~837 m (~10.7 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 5.761538461538461, max 9.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.635791139240542°C. Heat: mild (~28.635791139240542°C).\n",
      "  Urban form: building cover ~n/a% & roads ~4.3 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #4  (Lat, Lon: 23.734804, 90.650293)\n",
      "  Water: nearest mapped water is ~1,554 m (~19.9 min walk). Far from water (>500 m). — ~1,554 m (~19.9 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 7.3151515151515145, max 9.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.38299342105266°C. Heat: mild (~28.38299342105266°C).\n",
      "  Urban form: building cover ~n/a% & roads ~2.7 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #5  (Lat, Lon: 23.744468, 90.685705)\n",
      "  Water: nearest mapped water is ~456 m (~5.9 min walk). Near water (100–500 m). — ~456 m (~5.9 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 9.884120171673823, max 14.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.512724358974374°C. Heat: mild (~28.512724358974374°C).\n",
      "  Urban form: building cover ~0.0% & roads ~5.2 km/km² → very low building coverage; moderate road network\n",
      "\n",
      "📍 Candidate #6  (Lat, Lon: 23.727460, 90.554811)\n",
      "  Water: nearest mapped water is ~1,155 m (~14.8 min walk). Far from water (>500 m). — ~1,155 m (~14.8 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 0.6666666666666666, max 1.0. Very rarely wet — area is usually dry.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.676666666666733°C. Heat: mild (~28.676666666666733°C).\n",
      "  Urban form: building cover ~n/a% & roads ~4.3 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #7  (Lat, Lon: 23.854673, 90.547434)\n",
      "  Water: nearest mapped water is ~201 m (~2.6 min walk). Near water (100–500 m). — ~201 m (~2.6 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 0.21739130434782608, max 0.0. Very rarely wet — area is usually dry.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈29.75708675799093°C. Heat: mild (~29.75708675799093°C).\n",
      "  Urban form: building cover ~0.9% & roads ~3.9 km/km² → very low building coverage; sparse road network\n",
      "\n",
      "📍 Candidate #8  (Lat, Lon: 23.599064, 90.526469)\n",
      "  Water: nearest mapped water is ~182 m (~2.3 min walk). Near water (100–500 m). — ~182 m (~2.3 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean None, max None. No satellite evidence of open water nearby (or data unavailable).\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.836756680731376°C. Heat: mild (~28.836756680731376°C).\n",
      "  Urban form: building cover ~5.1% & roads ~9.5 km/km² → low building coverage; moderate road network\n",
      "\n",
      "📍 Candidate #9  (Lat, Lon: 23.879706, 90.594060)\n",
      "  Water: nearest mapped water is ~556 m (~7.1 min walk). Far from water (>500 m). — ~556 m (~7.1 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean None, max None. No satellite evidence of open water nearby (or data unavailable).\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈29.09538461538463°C. Heat: mild (~29.09538461538463°C).\n",
      "  Urban form: building cover ~n/a% & roads ~3.8 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #10  (Lat, Lon: 23.864498, 90.577473)\n",
      "  Water: nearest mapped water is ~1,108 m (~14.2 min walk). Far from water (>500 m). — ~1,108 m (~14.2 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 6.231350330500474, max 10.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈29.31578571428575°C. Heat: mild (~29.31578571428575°C).\n",
      "  Urban form: building cover ~n/a% & roads ~2.6 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #11  (Lat, Lon: 23.591594, 90.511009)\n",
      "  Water: nearest mapped water is ~82 m (~1.0 min walk). Very close to water (<100 m). — ~82 m (~1.0 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 52.24524564183834, max 80.0. Frequently/permanently wet — likely near river/pond or flood-prone.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown • historic water nearby\n",
      "  Heat (Apr–Jun): MODIS≈29.12262301587305°C. Heat: mild (~29.12262301587305°C).\n",
      "  Urban form: building cover ~8.6% & roads ~11.4 km/km² → low building coverage; moderate road network\n",
      "\n",
      "📍 Candidate #12  (Lat, Lon: 23.869369, 90.585840)\n",
      "  Water: nearest mapped water is ~979 m (~12.5 min walk). Far from water (>500 m). — ~979 m (~12.5 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean None, max None. No satellite evidence of open water nearby (or data unavailable).\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈29.127857142857184°C. Heat: mild (~29.127857142857184°C).\n",
      "  Urban form: building cover ~n/a% & roads ~4.2 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #13  (Lat, Lon: 23.618994, 90.564455)\n",
      "  Water: nearest mapped water is ~150 m (~1.9 min walk). Near water (100–500 m). — ~150 m (~1.9 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 2.3062015503875966, max 4.0. Very rarely wet — area is usually dry.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈27.95285714285717°C. Heat: mild (~27.95285714285717°C).\n",
      "  Urban form: building cover ~2.1% & roads ~3.2 km/km² → very low building coverage; sparse road network\n",
      "\n",
      "📍 Candidate #14  (Lat, Lon: 23.882651, 90.582902)\n",
      "  Water: nearest mapped water is ~186 m (~2.4 min walk). Near water (100–500 m). — ~186 m (~2.4 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 1.0, max 1.0. Very rarely wet — area is usually dry.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.78000000000003°C. Heat: mild (~28.78000000000003°C).\n",
      "  Urban form: building cover ~n/a% & roads ~4.7 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #15  (Lat, Lon: 23.698589, 90.511298)\n",
      "  Water: nearest mapped water is ~49 m (~0.6 min walk). Very close to water (<100 m). — ~49 m (~0.6 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 1.3571428571428572, max 2.0. Very rarely wet — area is usually dry.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈31.514962962963025°C. Heat: mild (~31.514962962963025°C).\n",
      "  Urban form: building cover ~22.7% & roads ~28.7 km/km² → moderate building coverage; very dense road network\n",
      "\n",
      "📍 Candidate #16  (Lat, Lon: 23.819471, 90.547608)\n",
      "  Water: nearest mapped water is ~95 m (~1.2 min walk). Very close to water (<100 m). — ~95 m (~1.2 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 61.341666666666654, max 77.0. Frequently/permanently wet — likely near river/pond or flood-prone.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown • historic water nearby\n",
      "  Heat (Apr–Jun): MODIS≈29.498024691358072°C. Heat: mild (~29.498024691358072°C).\n",
      "  Urban form: building cover ~1.7% & roads ~4.8 km/km² → very low building coverage; sparse road network\n",
      "\n",
      "📍 Candidate #17  (Lat, Lon: 23.840951, 90.599897)\n",
      "  Water: nearest mapped water is ~597 m (~7.7 min walk). Far from water (>500 m). — ~597 m (~7.7 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 8.710909090909093, max 29.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈30.009265822784847°C. Heat: mild (~30.009265822784847°C).\n",
      "  Urban form: building cover ~n/a% & roads ~1.7 km/km² → sparse road network\n",
      "\n",
      "📍 Candidate #18  (Lat, Lon: 23.619509, 90.557210)\n",
      "  Water: nearest mapped water is ~72 m (~0.9 min walk). Very close to water (<100 m). — ~72 m (~0.9 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 19.677567941040998, max 40.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.07130511463846°C. Heat: mild (~28.07130511463846°C).\n",
      "  Urban form: building cover ~2.8% & roads ~4.3 km/km² → very low building coverage; sparse road network\n",
      "\n",
      "📍 Candidate #19  (Lat, Lon: 23.796883, 90.529181)\n",
      "  Water: nearest mapped water is ~52 m (~0.7 min walk). Very close to water (<100 m). — ~52 m (~0.7 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 70.36315663228595, max 80.0. Frequently/permanently wet — likely near river/pond or flood-prone.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown • historic water nearby\n",
      "  Heat (Apr–Jun): MODIS≈29.47616108171665°C. Heat: mild (~29.47616108171665°C).\n",
      "  Urban form: building cover ~0.1% & roads ~9.4 km/km² → very low building coverage; moderate road network\n",
      "\n",
      "📍 Candidate #20  (Lat, Lon: 23.814329, 90.566801)\n",
      "  Water: nearest mapped water is ~1,374 m (~17.6 min walk). Far from water (>500 m). — ~1,374 m (~17.6 min walk).\n",
      "  Water presence (satellite history ≤150 m): mean 9.084269662921349, max 13.0. Occasionally wet — may pond during heavy rain.\n",
      "  Soil (0–5 cm): pH=None (src: None), clay%=None, sand%=None, SOC g/kg=None.\n",
      "  ↳ Soil pH unknown here.  |  Soil texture unknown.\n",
      "  Terrain: HAND-proxy None m; slope ~None°. Low-lying risk unknown\n",
      "  Heat (Apr–Jun): MODIS≈28.892968036529716°C. Heat: mild (~28.892968036529716°C).\n",
      "  Urban form: building cover ~0.1% & roads ~3.7 km/km² → very low building coverage; sparse road network\n",
      "\n",
      "✅ Saved map in current folder: narayanganj_green_access_ndvi_osm.html\n",
      "✅ Also saved to: C:\\Users\\Dipankar Mitra/Downloads\\narayanganj_green_access_ndvi_osm.html\n",
      "✅ Site context CSV saved to: C:\\Users\\Dipankar Mitra/Downloads\\narayanganj_site_context.csv\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# narayanganj_green_access_ndvi_osm.py\n",
    "# Green access + site candidates + planner-friendly context layers.\n",
    "# FAST version with batched Earth Engine calls and robustness fixes.\n",
    "#\n",
    "# Deps:\n",
    "#   pip install earthengine-api folium osmnx geopandas shapely networkx rtree\n",
    "#   # If you hit NumPy 2.x ABI issues with GeoPandas/Shapely wheels:\n",
    "#   # pip install \"numpy<2\" && pip install --force-reinstall geopandas shapely pyproj fiona rtree\n",
    "#\n",
    "# First run will prompt a browser for Earth Engine auth (ee.Authenticate()).\n",
    "\n",
    "import os, tempfile, base64\n",
    "import math\n",
    "import warnings\n",
    "from datetime import date\n",
    "from models.llms import groq_api\n",
    "\n",
    "try:\n",
    "    import ee\n",
    "    import folium\n",
    "    import networkx as nx\n",
    "    import osmnx as ox\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point, LineString, Polygon, MultiPolygon\n",
    "    from shapely.ops import unary_union\n",
    "except Exception as e:\n",
    "    raise SystemExit(\n",
    "        f\"\\nImport error: {e}\\n\\n\"\n",
    "        \"This often happens when GeoPandas/Shapely wheels were built for NumPy 1.x but you're on NumPy 2.x.\\n\"\n",
    "        \"Quick fix (in a clean venv):\\n\"\n",
    "        \"  pip install 'numpy<2'\\n\"\n",
    "        \"  pip install --force-reinstall geopandas shapely pyproj fiona rtree\\n\"\n",
    "        \"Or use a fresh 'conda create -n aoi python=3.11' env and install the deps.\\n\"\n",
    "    )\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ----------------------------\n",
    "# FEATURE FLAGS (toggle heavy layers quickly)\n",
    "# ----------------------------\n",
    "DO_POP   = True   # population in 10-min walkshed\n",
    "DO_HAND  = True   # DEM low-lying proxy + slope\n",
    "DO_SMAP  = True   # SMAP soil moisture\n",
    "DO_HEAT  = True   # MODIS/ECOSTRESS heat\n",
    "DO_SOIL  = True   # Soil properties\n",
    "DO_COUNTS= True   # Nearby counts (kept for popups/CSV; still not printed)\n",
    "\n",
    "# ----------------------------\n",
    "# SETTINGS\n",
    "# ----------------------------\n",
    "PLACE = \"Narayanganj, Dhaka Division, Bangladesh\"\n",
    "\n",
    "# NDVI\n",
    "NDVI_GREEN_MIN = 0.35\n",
    "\n",
    "# Walking thresholds\n",
    "T5 = 5 * 60\n",
    "T10 = 10 * 60\n",
    "WALK_MPS = 1.3\n",
    "\n",
    "# OSM green tags\n",
    "GREEN_TAGS = {\n",
    "    \"leisure\": [\"park\", \"garden\"],\n",
    "    \"landuse\": [\"recreation_ground\", \"grass\"],\n",
    "    \"natural\": [\"wood\"],\n",
    "}\n",
    "\n",
    "EDGE_BUFFER_M = 25\n",
    "TOP_N_CANDIDATES = 20\n",
    "\n",
    "# GEE composite tries\n",
    "DATE_TRIES = [\n",
    "    (\"2025-09-01\", \"2025-09-25\", 20),\n",
    "    (\"2025-08-01\", \"2025-09-25\", 40),\n",
    "    (\"2025-06-01\", \"2025-09-25\", 80),\n",
    "]\n",
    "\n",
    "# Context radii / scales (tuned for speed)\n",
    "SITE_BUFFER_M = 800\n",
    "SITE_BUFFER_M_FALLBACK = 1200\n",
    "WATER_STATS_RADIUS_M = 150\n",
    "\n",
    "CURRENT_YEAR = date.today().year\n",
    "HEAT_START = f\"{CURRENT_YEAR}-04-01\"\n",
    "HEAT_END   = f\"{CURRENT_YEAR}-06-30\"\n",
    "\n",
    "SMAP_DAYS = 30\n",
    "\n",
    "# EE scales\n",
    "POP_SCALE   = 200   # coarser than 100 m → faster population sums\n",
    "DEM_SCALE   = 30\n",
    "MODIS_SCALE = 1000\n",
    "ECOS_SCALE  = 100\n",
    "SOIL_SCALE  = 250\n",
    "JRC_SCALE   = 30\n",
    "SMAP_SCALE  = 9000\n",
    "\n",
    "# DEM neighborhood for 5th percentile (HAND proxy)\n",
    "HAND_RADIUS_M = 1500  # was 2000 → faster\n",
    "\n",
    "# Output\n",
    "DOWNLOADS = os.path.expanduser(\"~/Downloads\")\n",
    "OUT_HTML = os.path.join(DOWNLOADS, \"narayanganj_green_access_ndvi_osm.html\")\n",
    "OUT_CSV  = os.path.join(DOWNLOADS, \"narayanganj_site_context.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# EE INIT\n",
    "# ----------------------------\n",
    "def ee_init_headless():\n",
    "    sa = os.environ[\"EE_SERVICE_ACCOUNT\"]       # ee-runner@<project>.iam.gserviceaccount.com\n",
    "    key_b64 = os.environ[\"EE_KEY_B64\"]          # base64 of the JSON key\n",
    "\n",
    "    # Write key to a temp file\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "        f.write(base64.b64decode(key_b64).decode(\"utf-8\"))\n",
    "        key_path = f.name\n",
    "\n",
    "    creds = ee.ServiceAccountCredentials(sa, key_path)\n",
    "    ee.Initialize(credentials=creds)\n",
    "\n",
    "# ----------------------------\n",
    "# NDVI → green polygons\n",
    "# ----------------------------\n",
    "def choose_s2_composite(aoi_geom):\n",
    "    for (start, end, cloud) in DATE_TRIES:\n",
    "        s2sr = (ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "                .filterBounds(aoi_geom).filterDate(start, end)\n",
    "                .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", cloud)))\n",
    "        if s2sr.size().getInfo() > 0:\n",
    "            return s2sr.median(), f\"S2_SR {start}..{end} cloud<{cloud}%\"\n",
    "        s2l1c = (ee.ImageCollection(\"COPERNICUS/S2\")\n",
    "                 .filterBounds(aoi_geom).filterDate(start, end)\n",
    "                 .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", cloud)))\n",
    "        if s2l1c.size().getInfo() > 0:\n",
    "            return s2l1c.median(), f\"S2_L1C {start}..{end} cloud<{cloud}%\"\n",
    "    raise SystemExit(\"No recent Sentinel-2 scenes for AOI after fallbacks.\")\n",
    "\n",
    "def gee_green_polygons(aoi_geom, ndvi_min=NDVI_GREEN_MIN, scale=30, max_features=700):\n",
    "    composite, desc = choose_s2_composite(aoi_geom)\n",
    "    print(\"GEE composite picked:\", desc)\n",
    "    ndvi = composite.normalizedDifference([\"B8\", \"B4\"]).rename(\"NDVI\")\n",
    "    green_mask = ndvi.gte(ndvi_min).selfMask()\n",
    "    vectors = green_mask.reduceToVectors(\n",
    "        geometry=aoi_geom, scale=scale, geometryType=\"polygon\",\n",
    "        bestEffort=True, maxPixels=1e13\n",
    "    ).limit(max_features)\n",
    "    fc = vectors.getInfo()\n",
    "    feats = fc.get(\"features\", [])\n",
    "    if not feats:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    gdf = gpd.GeoDataFrame.from_features(feats, crs=\"EPSG:4326\")\n",
    "    return gdf[gdf.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])].copy()\n",
    "\n",
    "# ----------------------------\n",
    "# EE helpers (batched reducers)\n",
    "# ----------------------------\n",
    "def ee_geom_from_shapely(geom):\n",
    "    return ee.Geometry(geom.__geo_interface__)\n",
    "\n",
    "def fc_from_buffers(ids, lonlats, radius_m):\n",
    "    feats = []\n",
    "    for cid, (lon, lat) in zip(ids, lonlats):\n",
    "        feats.append(ee.Feature(ee.Geometry.Point([lon, lat]).buffer(radius_m), {\"cid\": int(cid)}))\n",
    "    return ee.FeatureCollection(feats)\n",
    "\n",
    "def fc_from_polys(ids, shapely_polys):\n",
    "    feats = []\n",
    "    for cid, shp in zip(ids, shapely_polys):\n",
    "        if shp is None: \n",
    "            continue\n",
    "        if isinstance(shp, (Polygon, MultiPolygon)):\n",
    "            feats.append(ee.Feature(ee_geom_from_shapely(shp), {\"cid\": int(cid)}))\n",
    "    return ee.FeatureCollection(feats)\n",
    "\n",
    "def reduce_regions_to_dict(image, fc, reducer, scale):\n",
    "    \"\"\"Run reduceRegions and return dict: cid -> properties dict (including band-named keys).\"\"\"\n",
    "    out = {}\n",
    "    try:\n",
    "        coll = image.reduceRegions(collection=fc, reducer=reducer, scale=scale)\n",
    "        data = coll.getInfo().get(\"features\", [])\n",
    "        for f in data:\n",
    "            props = f.get(\"properties\", {})\n",
    "            cid = int(props.get(\"cid\"))\n",
    "            out[cid] = props\n",
    "    except Exception:\n",
    "        pass\n",
    "    return out\n",
    "\n",
    "def first_number(props, preferred_keys=None):\n",
    "    \"\"\"Get a numeric value from a properties dict, preferring certain keys.\"\"\"\n",
    "    if not isinstance(props, dict):\n",
    "        return None\n",
    "    if preferred_keys:\n",
    "        for k in preferred_keys:\n",
    "            if k in props:\n",
    "                try:\n",
    "                    return float(props[k])\n",
    "                except Exception:\n",
    "                    pass\n",
    "    for k, v in props.items():\n",
    "        if k == \"cid\": \n",
    "            continue\n",
    "        try:\n",
    "            return float(v)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# ----------------------------\n",
    "# DATASETS (images)\n",
    "# ----------------------------\n",
    "def jrc_occurrence_img():\n",
    "    try:\n",
    "        return ee.Image(\"JRC/GSW1_4/GlobalSurfaceWater\").select(\"occurrence\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def soil_sources_images():\n",
    "    out = []\n",
    "    # SoilGrids 2020\n",
    "    try:\n",
    "        img = ee.Image(\"ISRIC/SoilGrids/2020\")\n",
    "        bands = img.bandNames().getInfo()\n",
    "        def pick(tokens):\n",
    "            for b in bands:\n",
    "                bl = b.lower()\n",
    "                if all(t in bl for t in tokens): return b\n",
    "            return None\n",
    "        bmap = {\n",
    "            \"soil_ph\":   pick((\"phh2o\",\"0-5\",\"mean\")) or pick((\"phh2o\",\"0-5cm\",\"mean\")),\n",
    "            \"soil_clay\": pick((\"clay\",\"0-5\",\"mean\"))  or pick((\"clay\",\"0-5cm\",\"mean\")),\n",
    "            \"soil_sand\": pick((\"sand\",\"0-5\",\"mean\"))  or pick((\"sand\",\"0-5cm\",\"mean\")),\n",
    "            \"soil_soc\":  pick((\"soc\",\"0-5\",\"mean\"))   or pick((\"soc\",\"0-5cm\",\"mean\")),\n",
    "        }\n",
    "        selects = [b for b in bmap.values() if b]\n",
    "        if selects:\n",
    "            out.append((\"SoilGrids2020\", img.select(selects)))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # SoilGrids 250m\n",
    "    try:\n",
    "        img = ee.Image(\"ISRIC/SoilGrids/250m\")\n",
    "        bands = img.bandNames().getInfo()\n",
    "        def pick(tokens):\n",
    "            for b in bands:\n",
    "                bl = b.lower()\n",
    "                if all(t in bl for t in tokens): return b\n",
    "            return None\n",
    "        bmap = {\n",
    "            \"soil_ph\":   pick((\"phh2o\",\"0-5\",\"mean\")) or pick((\"phh2o\",\"0-5cm\",\"mean\")),\n",
    "            \"soil_clay\": pick((\"clay\",\"0-5\",\"mean\"))  or pick((\"clay\",\"0-5cm\",\"mean\")),\n",
    "            \"soil_sand\": pick((\"sand\",\"0-5\",\"mean\"))  or pick((\"sand\",\"0-5cm\",\"mean\")),\n",
    "            \"soil_soc\":  pick((\"soc\",\"0-5\",\"mean\"))   or pick((\"soc\",\"0-5cm\",\"mean\")),\n",
    "        }\n",
    "        selects = [b for b in bmap.values() if b]\n",
    "        if selects:\n",
    "            out.append((\"SoilGrids250m\", img.select(selects)))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # OpenLandMap fallbacks\n",
    "    try:\n",
    "        ph   = ee.Image(\"OpenLandMap/SOL/SOL_PH-H2O_USDA-4C1A2A_M/v02\")\n",
    "        clay = ee.Image(\"OpenLandMap/SOL/SOL_TEXTURE-CLAY_USDA-3A1A1A_M/v02\")\n",
    "        sand = ee.Image(\"OpenLandMap/SOL/SOL_TEXTURE-SAND_USDA-3A1A1A_M/v02\")\n",
    "        soc  = ee.Image(\"OpenLandMap/SOL/SOL_ORGANIC-CARBON_USDA-6A1C_M/v02\")\n",
    "        out.append((\"OpenLandMap\", ph.addBands([clay, sand, soc])))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return out\n",
    "\n",
    "def population_image(aoi):\n",
    "    for yr in [2025, 2023, 2022, 2021, 2020, 2019]:\n",
    "        try:\n",
    "            col = ee.ImageCollection(\"WorldPop/GP/100m/pop\").filterBounds(aoi).filter(ee.Filter.eq('year', yr))\n",
    "            if col.size().getInfo() > 0:\n",
    "                img = col.mosaic()\n",
    "                bname = img.bandNames().getInfo()[0]\n",
    "                return img.select(bname, [\"pop\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        img = ee.Image(\"JRC/GHSL/P2019/POP_GLOBE_R2019A\")\n",
    "        bands = [b for b in img.bandNames().getInfo() if \"2020\" in b or \"2015\" in b]\n",
    "        if bands:\n",
    "            return img.select(bands[0], [\"pop\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        col = ee.ImageCollection(\"CIESIN/GPWv411/GPW_Population_Count\").filter(ee.Filter.eq(\"year\", 2020))\n",
    "        img = col.first()\n",
    "        if img:\n",
    "            b = img.bandNames().getInfo()[0]\n",
    "            return img.select(b, [\"pop\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def dem_and_slope():\n",
    "    try:\n",
    "        dem = ee.Image(\"COPERNICUS/DEM/GLO30\")\n",
    "    except Exception:\n",
    "        dem = ee.Image(\"USGS/SRTMGL1_003\")\n",
    "    slope = ee.Terrain.slope(dem).rename(\"slope\")\n",
    "    return dem.rename(\"elevation\"), slope\n",
    "\n",
    "def heat_images(aoi):\n",
    "    modis = None\n",
    "    eco = None\n",
    "    try:\n",
    "        col = (ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "               .filterBounds(aoi).filterDate(HEAT_START, HEAT_END).select(\"LST_Day_1km\"))\n",
    "        if col.size().getInfo() > 0:\n",
    "            modisK = col.mean()\n",
    "            modis = modisK.multiply(0.02).subtract(273.15).rename(\"LST_modis_C\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        col = (ee.ImageCollection(\"NASA/JPL/ECOSTRESS/L2_LSTE\")\n",
    "               .filterBounds(aoi).filterDate(HEAT_START, HEAT_END).select(\"LST\"))\n",
    "        if col.size().getInfo() > 0:\n",
    "            ecoK = col.mean()\n",
    "            eco = ecoK.subtract(273.15).rename(\"LST_eco_C\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return modis, eco\n",
    "\n",
    "def smap_image(aoi):\n",
    "    try:\n",
    "        end = ee.Date(date.today().isoformat())\n",
    "        start = end.advance(-SMAP_DAYS, 'day')\n",
    "        col = (ee.ImageCollection(\"NASA/SMAP/SPL3SMP_E\")\n",
    "               .filterBounds(aoi).filterDate(start, end).select(\"soil_moisture\"))\n",
    "        if col.size().getInfo() == 0:\n",
    "            return None\n",
    "        return col.mean().rename(\"soil_moisture\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# INTERPRETERS\n",
    "# ----------------------------\n",
    "def fmt_meters_and_walk(min_meters):\n",
    "    if min_meters is None:\n",
    "        return \"unknown distance\"\n",
    "    minutes = (min_meters / WALK_MPS) / 60.0\n",
    "    return f\"~{round(min_meters):,} m (~{round(minutes,1)} min walk)\"\n",
    "\n",
    "def interpret_water_occurrence(p):\n",
    "    if p is None:  return \"No satellite evidence of open water nearby (or data unavailable).\"\n",
    "    if p < 5:      return \"Very rarely wet — area is usually dry.\"\n",
    "    if p < 20:     return \"Occasionally wet — may pond during heavy rain.\"\n",
    "    if p < 50:     return \"Seasonally wet — expect water presence in some months.\"\n",
    "    return \"Frequently/permanently wet — likely near river/pond or flood-prone.\"\n",
    "\n",
    "def interpret_ph(ph):\n",
    "    if ph is None:       return \"Soil pH unknown here.\"\n",
    "    if ph < 5.5:         return f\"Acidic (pH {ph}) — choose tolerant species.\"\n",
    "    if ph <= 7.5:        return f\"Near neutral (pH {ph}) — good for most plants.\"\n",
    "    return f\"Alkaline (pH {ph}) — choose tolerant species.\"\n",
    "\n",
    "def interpret_texture(sand_pct, clay_pct):\n",
    "    if sand_pct is None or clay_pct is None:\n",
    "        return \"Soil texture unknown.\"\n",
    "    if sand_pct >= 60 and clay_pct < 20:\n",
    "        return f\"Sandy ({sand_pct}% sand) — drains fast; add organic matter.\"\n",
    "    if clay_pct >= 35:\n",
    "        return f\"Clayey ({clay_pct}% clay) — slow drainage; raised beds help.\"\n",
    "    return f\"Loamy mix (sand {sand_pct}%, clay {clay_pct}%) — generally good.\"\n",
    "\n",
    "def interpret_distance_to_water(d):\n",
    "    if d is None: return \"Distance to water unknown.\"\n",
    "    if d < 100:   return \"Very close to water (<100 m).\"\n",
    "    if d < 500:   return \"Near water (100–500 m).\"\n",
    "    return \"Far from water (>500 m).\"\n",
    "\n",
    "def interpret_density(building_pct, road_km_km2):\n",
    "    msgs = []\n",
    "    if building_pct is not None:\n",
    "        if building_pct < 5:   msgs.append(\"very low building coverage\")\n",
    "        elif building_pct < 20:msgs.append(\"low building coverage\")\n",
    "        elif building_pct < 40:msgs.append(\"moderate building coverage\")\n",
    "        else:                  msgs.append(\"dense built-up surroundings\")\n",
    "    if road_km_km2 is not None:\n",
    "        if road_km_km2 < 5:    msgs.append(\"sparse road network\")\n",
    "        elif road_km_km2 < 15: msgs.append(\"moderate road network\")\n",
    "        else:                  msgs.append(\"very dense road network\")\n",
    "    return \"; \".join(msgs) if msgs else \"Urban density unknown.\"\n",
    "\n",
    "def interpret_hand_proxy(hm, slope_deg, gsw_mean):\n",
    "    parts = []\n",
    "    if hm is None:\n",
    "        parts.append(\"Low-lying risk unknown\")\n",
    "    else:\n",
    "        if hm < 1:       parts.append(\"Very low ground (likely ponding)\")\n",
    "        elif hm < 3:     parts.append(\"Low ground\")\n",
    "        elif hm < 7:     parts.append(\"Moderate elevation\")\n",
    "        else:            parts.append(\"High relative elevation\")\n",
    "    if slope_deg is not None:\n",
    "        if slope_deg < 1: parts.append(\"very flat; slow drainage\")\n",
    "        elif slope_deg < 3:parts.append(\"gentle slope\")\n",
    "        else:              parts.append(\"noticeable slope\")\n",
    "    if gsw_mean is not None and gsw_mean >= 20:\n",
    "        parts.append(\"historic water nearby\")\n",
    "    return \" • \".join(parts)\n",
    "\n",
    "def interpret_heat(modis_c, eco_c):\n",
    "    val = eco_c if eco_c is not None else modis_c\n",
    "    if val is None: return \"Heat unknown.\"\n",
    "    if val >= 42:   return f\"Heat: very high (~{val}°C daytime LST).\"\n",
    "    if val >= 38:   return f\"Heat: high (~{val}°C).\"\n",
    "    if val >= 34:   return f\"Heat: moderate (~{val}°C).\"\n",
    "    return f\"Heat: mild (~{val}°C).\"\n",
    "\n",
    "# ----------------------------\n",
    "# OSM helpers\n",
    "# ----------------------------\n",
    "POI_CATEGORIES = {\n",
    "    \"schools\":      (\"amenity\", [\"school\"]),\n",
    "    \"colleges\":     (\"amenity\", [\"college\"]),\n",
    "    \"universities\": (\"amenity\", [\"university\"]),\n",
    "    \"hospitals\":    (\"amenity\", [\"hospital\"]),\n",
    "    \"clinics\":      (\"amenity\", [\"clinic\"]),\n",
    "    \"pharmacies\":   (\"amenity\", [\"pharmacy\"]),\n",
    "    \"markets\":      (\"amenity\", [\"marketplace\"]),\n",
    "    \"libraries\":    (\"amenity\", [\"library\"]),\n",
    "    \"community\":    (\"amenity\", [\"community_centre\"]),\n",
    "    \"police\":       (\"amenity\", [\"police\"]),\n",
    "    \"fire\":         (\"amenity\", [\"fire_station\"]),\n",
    "    \"worship\":      (\"amenity\", [\"place_of_worship\"]),\n",
    "    \"playgrounds\":  (\"leisure\", [\"playground\"]),\n",
    "    \"sports\":       (\"leisure\", [\"sports_centre\"]),\n",
    "    \"parks_gardens\":(\"leisure\", [\"park\", \"garden\"]),\n",
    "    \"supermarkets\": (\"shop\", [\"supermarket\"]),\n",
    "}\n",
    "\n",
    "OSM_CONTEXT_TAGS = {\n",
    "    \"amenity\": list({v for _, vs in [POI_CATEGORIES[k] for k in POI_CATEGORIES if POI_CATEGORIES[k][0] == \"amenity\"] for v in vs}),\n",
    "    \"leisure\": list({v for _, vs in [POI_CATEGORIES[k] for k in POI_CATEGORIES if POI_CATEGORIES[k][0] == \"leisure\"] for v in vs}),\n",
    "    \"shop\":    [\"supermarket\"],\n",
    "    \"building\": True,\n",
    "    \"natural\": [\"water\", \"wetland\", \"wood\"],\n",
    "    \"waterway\": True,\n",
    "    \"landuse\": [\"residential\", \"commercial\", \"industrial\", \"retail\", \"recreation_ground\", \"grass\"],\n",
    "}\n",
    "\n",
    "def fetch_osm_context(aoi_polygon):\n",
    "    layers = []\n",
    "    for k, v in OSM_CONTEXT_TAGS.items():\n",
    "        try:\n",
    "            g = osm_features_from_polygon(aoi_polygon, tags={k: v})\n",
    "            if g is not None and not g.empty:\n",
    "                layers.append(g)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not layers:\n",
    "        empty = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "        return empty, empty, empty\n",
    "\n",
    "    base_crs = getattr(layers[0], \"crs\", None) or \"EPSG:4326\"\n",
    "    all_feats = gpd.GeoDataFrame(gpd.pd.concat(layers, ignore_index=True), crs=base_crs)\n",
    "    all_feats = all_feats[all_feats.geometry.notna()].copy()\n",
    "\n",
    "    is_water = (\n",
    "        (all_feats.get(\"natural\").isin([\"water\", \"wetland\"])) |\n",
    "        (all_feats.get(\"waterway\").notna())\n",
    "    ).fillna(False)\n",
    "\n",
    "    is_building = all_feats.get(\"building\").notna().fillna(False)\n",
    "\n",
    "    water_gdf = all_feats[is_water].copy()\n",
    "    buildings_gdf = all_feats[is_building].copy()\n",
    "    pois_gdf = all_feats[~is_water].copy()\n",
    "    return pois_gdf.to_crs(epsg=4326), water_gdf.to_crs(epsg=4326), buildings_gdf.to_crs(epsg=4326)\n",
    "\n",
    "def count_features_in_buffer(pois_proj, buffer_geom, key, values):\n",
    "    if pois_proj is None or pois_proj.empty or key not in pois_proj.columns:\n",
    "        return 0\n",
    "    subset = pois_proj[pois_proj[key].isin(values)]\n",
    "    if subset.empty:\n",
    "        return 0\n",
    "    try:\n",
    "        idx = subset.sindex\n",
    "        cand_idx = list(idx.intersection(buffer_geom.bounds))\n",
    "        subset = subset.iloc[cand_idx]\n",
    "    except Exception:\n",
    "        minx, miny, maxx, maxy = buffer_geom.bounds\n",
    "        subset = subset[\n",
    "            (subset.geometry.bounds[\"maxx\"] >= minx) &\n",
    "            (subset.geometry.bounds[\"minx\"] <= maxx) &\n",
    "            (subset.geometry.bounds[\"maxy\"] >= miny) &\n",
    "            (subset.geometry.bounds[\"miny\"] <= maxy)\n",
    "        ]\n",
    "    if subset.empty:\n",
    "        return 0\n",
    "    return int(subset.intersects(buffer_geom).sum())\n",
    "\n",
    "def building_and_road_density(buildings_proj, edges_proj, buffer_geom):\n",
    "    try:\n",
    "        area_m2 = float(buffer_geom.area)\n",
    "        bldg_pct = None\n",
    "        road_density = None\n",
    "\n",
    "        if buildings_proj is not None and not buildings_proj.empty:\n",
    "            try:\n",
    "                idx = buildings_proj.sindex\n",
    "                cand_idx = list(idx.intersection(buffer_geom.bounds))\n",
    "                bsub = buildings_proj.iloc[cand_idx]\n",
    "            except Exception:\n",
    "                bsub = buildings_proj\n",
    "            bsub = bsub[bsub.geometry.intersects(buffer_geom)]\n",
    "            if not bsub.empty:\n",
    "                inter = bsub.geometry.intersection(buffer_geom)\n",
    "                built_area = float(inter.area.sum())\n",
    "                if area_m2 > 0:\n",
    "                    bldg_pct = round(100.0 * built_area / area_m2, 1)\n",
    "\n",
    "        if edges_proj is not None and not edges_proj.empty:\n",
    "            try:\n",
    "                idx = edges_proj.sindex\n",
    "                cand_idx = list(idx.intersection(buffer_geom.bounds))\n",
    "                esub = edges_proj.iloc[cand_idx]\n",
    "            except Exception:\n",
    "                esub = edges_proj\n",
    "            esub = esub[esub.geometry.intersects(buffer_geom)]\n",
    "            if not esub.empty:\n",
    "                ilen = esub.geometry.intersection(buffer_geom).length.sum()  # meters\n",
    "                km = float(ilen) / 1000.0\n",
    "                km2 = area_m2 / 1e6\n",
    "                if km2 > 0:\n",
    "                    road_density = round(km / km2, 1)\n",
    "        return bldg_pct, road_density\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "# ----------------------------\n",
    "# CORE LOGIC\n",
    "# ----------------------------\n",
    "def line_midpoint(geom: LineString):\n",
    "    try:\n",
    "        return geom.interpolate(0.5, normalized=True)\n",
    "    except Exception:\n",
    "        if geom.geom_type == \"LineString\" and len(geom.coords) >= 2:\n",
    "            (x1, y1), (x2, y2) = geom.coords[0], geom.coords[-1]\n",
    "            return Point((x1 + x2) / 2.0, (y1 + y2) / 2.0)\n",
    "        return geom.centroid\n",
    "\n",
    "def make_iso_polygon(edges_subset, buffer_m=EDGE_BUFFER_M):\n",
    "    if edges_subset is None or edges_subset.empty:\n",
    "        return None\n",
    "    buffered = edges_subset.geometry.buffer(buffer_m)\n",
    "    merged = unary_union(list(buffered.values))\n",
    "    return gpd.GeoSeries([merged], crs=edges_subset.crs)\n",
    "\n",
    "def edges_within_time(Gp, edges_gdf, source_node, cutoff_s):\n",
    "    times = nx.single_source_dijkstra_path_length(Gp, source=source_node, cutoff=cutoff_s, weight=\"time_s\")\n",
    "    nodes_in = set(times.keys())\n",
    "    mask = edges_gdf.apply(lambda r: (r[\"u\"] in nodes_in) or (r[\"v\"] in nodes_in), axis=1)\n",
    "    return edges_gdf[mask].copy(), times\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN\n",
    "# ----------------------------\n",
    "def main():\n",
    "    ee_init_headless()\n",
    "\n",
    "    # Soil sources & images\n",
    "    soil_imgs = soil_sources_images() if DO_SOIL else []\n",
    "    dem_img, slope_img = dem_and_slope() if DO_HAND else (None, None)\n",
    "\n",
    "    # OSMnx\n",
    "    ox.settings.log_console = True\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.timeout = 180\n",
    "\n",
    "    print(\"Geocoding AOI…\")\n",
    "    aoi = ox.geocode_to_gdf(PLACE)\n",
    "    if aoi.empty:\n",
    "        raise SystemExit(\"Could not geocode the AOI name.\")\n",
    "    aoi_polygon = aoi.geometry.iloc[0]\n",
    "    aoi_bounds = aoi.to_crs(epsg=4326).total_bounds\n",
    "    gee_aoi = ee.Geometry.Rectangle(list(aoi_bounds))\n",
    "\n",
    "    print(\"Downloading pedestrian network…\")\n",
    "    G = ox.graph_from_polygon(aoi_polygon, network_type=\"walk\", simplify=True)\n",
    "\n",
    "    print(\"Projecting graph to local metric CRS…\")\n",
    "    Gp = ox.project_graph(G)\n",
    "    nodes_gdf, edges_gdf = ox.graph_to_gdfs(Gp)\n",
    "    if \"u\" not in edges_gdf.columns or \"v\" not in edges_gdf.columns:\n",
    "        edges_gdf = edges_gdf.reset_index()\n",
    "    graph_crs = nodes_gdf.crs\n",
    "\n",
    "    # OSM green areas\n",
    "    print(\"Downloading OSM green areas…\")\n",
    "    green_layers = []\n",
    "    for k, v in GREEN_TAGS.items():\n",
    "        try:\n",
    "            g = osm_features_from_polygon(aoi_polygon, tags={k: v})\n",
    "            if g is not None and not g.empty:\n",
    "                green_layers.append(g)\n",
    "        except Exception:\n",
    "            pass\n",
    "    osm_greens = None\n",
    "    if green_layers:\n",
    "        base_crs = getattr(green_layers[0], \"crs\", None) or \"EPSG:4326\"\n",
    "        osm_greens = gpd.GeoDataFrame(gpd.pd.concat(green_layers, ignore_index=True), crs=base_crs)\n",
    "        osm_greens = osm_greens[osm_greens.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])].copy()\n",
    "\n",
    "    # NDVI greens\n",
    "    print(\"Vectorizing NDVI green polygons (GEE)…\")\n",
    "    ndvi_greens = gee_green_polygons(gee_aoi, ndvi_min=NDVI_GREEN_MIN, scale=30, max_features=700)\n",
    "\n",
    "    greens_list = []\n",
    "    if osm_greens is not None and not osm_greens.empty:\n",
    "        greens_list.append(osm_greens.to_crs(epsg=4326))\n",
    "    if ndvi_greens is not None and not ndvi_greens.empty:\n",
    "        greens_list.append(ndvi_greens.to_crs(epsg=4326))\n",
    "    if not greens_list:\n",
    "        raise SystemExit(\"No green polygons found from OSM or NDVI.\")\n",
    "\n",
    "    greens_all = gpd.GeoDataFrame(gpd.pd.concat(greens_list, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    print(f\"Green polygons: OSM={0 if osm_greens is None else len(osm_greens)} | NDVI={len(ndvi_greens)} | merged={len(greens_all)}\")\n",
    "\n",
    "    # Project greens\n",
    "    greens_poly_proj = greens_all.to_crs(graph_crs)\n",
    "\n",
    "    # Destination nodes from green centroids\n",
    "    print(\"Computing destination nodes from green centroids…\")\n",
    "    greens_poly_proj[\"centroid\"] = greens_poly_proj.geometry.centroid\n",
    "    dest_nodes = set()\n",
    "    for c in greens_poly_proj[\"centroid\"]:\n",
    "        try:\n",
    "            dest_nodes.add(ox.distance.nearest_nodes(Gp, X=c.x, Y=c.y))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not dest_nodes:\n",
    "        raise SystemExit(\"No destination nodes from green centroids.\")\n",
    "\n",
    "    # Edge costs\n",
    "    print(\"Assigning time costs to edges…\")\n",
    "    for u, v, k, data in Gp.edges(keys=True, data=True):\n",
    "        length_m = float(data.get(\"length\", 0.0)) or 0.0\n",
    "        data[\"time_s\"] = length_m / WALK_MPS\n",
    "\n",
    "    # Multi-source Dijkstra (reverse trick)\n",
    "    print(\"Running multi-source shortest path (Dijkstra)…\")\n",
    "    Gr = Gp.reverse()\n",
    "    min_time_s = nx.multi_source_dijkstra_path_length(Gr, sources=list(dest_nodes), weight=\"time_s\")\n",
    "\n",
    "    def covered_by_threshold(u, v, threshold_s):\n",
    "        tu = min_time_s.get(u, math.inf); tv = min_time_s.get(v, math.inf)\n",
    "        return (tu <= threshold_s) or (tv <= threshold_s)\n",
    "\n",
    "    def both_beyond_10(u, v):\n",
    "        return (min_time_s.get(u, math.inf) > T10) and (min_time_s.get(v, math.inf) > T10)\n",
    "\n",
    "    print(\"Classifying edges by coverage…\")\n",
    "    edges_gdf[\"covered_5min\"] = edges_gdf.apply(lambda r: covered_by_threshold(r[\"u\"], r[\"v\"], T5), axis=1)\n",
    "    edges_gdf[\"covered_10min\"] = edges_gdf.apply(lambda r: covered_by_threshold(r[\"u\"], r[\"v\"], T10), axis=1)\n",
    "    edges_gdf[\"uncovered_10min\"] = edges_gdf.apply(lambda r: both_beyond_10(r[\"u\"], r[\"v\"]), axis=1)\n",
    "    uncovered = edges_gdf[edges_gdf[\"uncovered_10min\"]].copy()\n",
    "    print(f\"Uncovered road segments >10 min: {len(uncovered)}\")\n",
    "\n",
    "    # Isochrones (for display)\n",
    "    print(\"Building isochrone polygons…\")\n",
    "    iso5_edges = edges_gdf[edges_gdf[\"covered_5min\"]]\n",
    "    iso10_edges = edges_gdf[edges_gdf[\"covered_10min\"]]\n",
    "    iso5_poly = make_iso_polygon(iso5_edges, buffer_m=EDGE_BUFFER_M)\n",
    "    iso10_poly = make_iso_polygon(iso10_edges, buffer_m=EDGE_BUFFER_M)\n",
    "\n",
    "    # Candidates: midpoints of longest uncovered segments (dedup)\n",
    "    print(\"Selecting candidate micro-park points…\")\n",
    "    uncovered[\"length_m\"] = uncovered.geometry.length\n",
    "    candidates = uncovered.sort_values(\"length_m\", ascending=False).head(3 * TOP_N_CANDIDATES).copy()\n",
    "    candidates[\"midpt\"] = candidates.geometry.apply(line_midpoint)\n",
    "    cand_proj = gpd.GeoDataFrame(geometry=candidates[\"midpt\"], crs=edges_gdf.crs)\n",
    "    cand_wgs84 = cand_proj.to_crs(epsg=4326)  # <-- FIX: transform the GeoDataFrame (not Points)\n",
    "    cand_wgs84[\"xy_round\"] = cand_wgs84.geometry.apply(lambda g: (round(g.x, 6), round(g.y, 6)))\n",
    "    cand_wgs84 = cand_wgs84.drop_duplicates(subset=\"xy_round\").head(TOP_N_CANDIDATES).copy()\n",
    "    cand_proj = cand_wgs84.to_crs(edges_gdf.crs)[[\"geometry\"]].copy()  # keep projected too\n",
    "\n",
    "    # OSM context\n",
    "    print(\"Downloading OSM context layers…\")\n",
    "    pois_wgs84, water_wgs84, buildings_wgs84 = fetch_osm_context(aoi_polygon)\n",
    "    pois_proj = pois_wgs84.to_crs(graph_crs) if not pois_wgs84.empty else pois_wgs84\n",
    "    water_proj = water_wgs84.to_crs(graph_crs) if not water_wgs84.empty else water_wgs84\n",
    "    buildings_proj = buildings_wgs84.to_crs(graph_crs) if not buildings_wgs84.empty else buildings_wgs84\n",
    "    water_union = unary_union(list(water_proj.geometry.values)) if (water_proj is not None and not water_proj.empty) else None\n",
    "\n",
    "    # Assemble candidate basics\n",
    "    ids = list(range(1, len(cand_proj) + 1))\n",
    "    # Use the already-transformed WGS84 points for lon/lat lists  <-- FIXED\n",
    "    lonlats = [(pt.x, pt.y) for pt in cand_wgs84.geometry]\n",
    "    nearest_nodes = [ox.distance.nearest_nodes(Gp, X=geom.x, Y=geom.y) for geom in cand_proj.geometry]\n",
    "\n",
    "    # Build 10-min isochrone polygons once (local; 20 sites → OK)\n",
    "    iso_polys = []\n",
    "    for nid in nearest_nodes:\n",
    "        edges_iso, _times = edges_within_time(Gp, edges_gdf, nid, T10)\n",
    "        iso_polys.append(make_iso_polygon(edges_iso, buffer_m=EDGE_BUFFER_M).iloc[0] if (edges_iso is not None and not edges_iso.empty) else None)\n",
    "\n",
    "    # ----------------------------\n",
    "    # BATCHED EE CALLS\n",
    "    # ----------------------------\n",
    "    print(\"\\nComputing batched metrics (EE)…\")\n",
    "\n",
    "    # Population (sum over isochrone polygons)\n",
    "    pop_results = {}\n",
    "    if DO_POP:\n",
    "        pop_img = population_image(gee_aoi)\n",
    "        if pop_img is not None:\n",
    "            fc_iso = fc_from_polys(ids, iso_polys)\n",
    "            pop_results = reduce_regions_to_dict(\n",
    "                image=pop_img, fc=fc_iso, reducer=ee.Reducer.sum(), scale=POP_SCALE\n",
    "            )\n",
    "        else:\n",
    "            print(\"Population raster not available; walkshed population will be 'n/a'.\")\n",
    "\n",
    "    # JRC water (mean and max in 150 m) — do as two simple batched calls (robust)\n",
    "    jrc_mean_results = {}\n",
    "    jrc_max_results = {}\n",
    "    occ = jrc_occurrence_img()\n",
    "    if occ is not None:\n",
    "        fc_water = fc_from_buffers(ids, lonlats, WATER_STATS_RADIUS_M)\n",
    "        jrc_mean_results = reduce_regions_to_dict(\n",
    "            image=occ, fc=fc_water, reducer=ee.Reducer.mean(), scale=JRC_SCALE\n",
    "        )\n",
    "        jrc_max_results = reduce_regions_to_dict(\n",
    "            image=occ, fc=fc_water, reducer=ee.Reducer.max(), scale=JRC_SCALE\n",
    "        )\n",
    "\n",
    "    # Soil (buffered mean 150 m) with fallbacks (run per source, but batched)\n",
    "    soil_results = {}\n",
    "    if DO_SOIL and soil_imgs:\n",
    "        fc_soil = fc_from_buffers(ids, lonlats, 150)\n",
    "        for label, img in soil_imgs:\n",
    "            tmp = reduce_regions_to_dict(\n",
    "                image=img, fc=fc_soil, reducer=ee.Reducer.mean(), scale=SOIL_SCALE\n",
    "            )\n",
    "            for cid in ids:\n",
    "                if cid in tmp and cid not in soil_results:\n",
    "                    # store label + properties dict\n",
    "                    soil_results[cid] = (label, tmp[cid])\n",
    "    for cid in ids:\n",
    "        if cid not in soil_results:\n",
    "            soil_results[cid] = (None, {})\n",
    "\n",
    "    # DEM low-lying proxy & slope (batched)\n",
    "    hand_results = {}\n",
    "    slope_results = {}\n",
    "    if DO_HAND and dem_img is not None and slope_img is not None:\n",
    "        kernel = ee.Kernel.circle(HAND_RADIUS_M, 'meters')\n",
    "        try:\n",
    "            p5 = dem_img.reduceNeighborhood(ee.Reducer.percentile([5]), kernel)\n",
    "            hand_img = dem_img.subtract(p5).rename(\"hand_proxy\")\n",
    "            fc_hand = fc_from_buffers(ids, lonlats, 30)   # small buffer\n",
    "            fc_slope = fc_from_buffers(ids, lonlats, 60)  # slope a bit larger\n",
    "            hand_results = reduce_regions_to_dict(\n",
    "                image=hand_img, fc=fc_hand, reducer=ee.Reducer.mean(), scale=DEM_SCALE\n",
    "            )\n",
    "            slope_results = reduce_regions_to_dict(\n",
    "                image=slope_img, fc=fc_slope, reducer=ee.Reducer.mean(), scale=DEM_SCALE\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Heat (batched)\n",
    "    heat_modis = {}\n",
    "    heat_eco = {}\n",
    "    if DO_HEAT:\n",
    "        modis_img, eco_img = heat_images(gee_aoi)\n",
    "        fc_heat = fc_from_buffers(ids, lonlats, 300)\n",
    "        if modis_img is not None:\n",
    "            heat_modis = reduce_regions_to_dict(\n",
    "                image=modis_img, fc=fc_heat, reducer=ee.Reducer.mean(), scale=MODIS_SCALE\n",
    "            )\n",
    "        if eco_img is not None:\n",
    "            heat_eco = reduce_regions_to_dict(\n",
    "                image=eco_img, fc=fc_heat, reducer=ee.Reducer.mean(), scale=ECOS_SCALE\n",
    "            )\n",
    "\n",
    "    # SMAP (batched)\n",
    "    smap_results = {}\n",
    "    if DO_SMAP:\n",
    "        smap_img = smap_image(gee_aoi)\n",
    "        if smap_img is not None:\n",
    "            fc_smap = fc_from_buffers(ids, lonlats, 800)  # trimmed buffer\n",
    "            smap_results = reduce_regions_to_dict(\n",
    "                image=smap_img, fc=fc_smap, reducer=ee.Reducer.mean(), scale=SMAP_SCALE\n",
    "            )\n",
    "\n",
    "    # ----------------------------\n",
    "    # Local OSM-derived metrics (fast w/ sindex)\n",
    "    # ----------------------------\n",
    "    print(\"Computing local OSM metrics…\")\n",
    "    all_counts = []\n",
    "    all_build_road = []\n",
    "    for cid, proj_geom in zip(ids, cand_proj.geometry):\n",
    "        radius_used = SITE_BUFFER_M\n",
    "        buf = proj_geom.buffer(radius_used)\n",
    "\n",
    "        def compute_counts(buffer_geom):\n",
    "            counts_local = {}\n",
    "            if not DO_COUNTS or pois_proj is None or pois_proj.empty:\n",
    "                for label in POI_CATEGORIES: counts_local[label] = 0\n",
    "                return counts_local\n",
    "            for label, (key, values) in POI_CATEGORIES.items():\n",
    "                counts_local[label] = count_features_in_buffer(pois_proj, buffer_geom, key, values)\n",
    "            return counts_local\n",
    "\n",
    "        counts = compute_counts(buf)\n",
    "        if DO_COUNTS and sum(counts.values()) == 0 and SITE_BUFFER_M_FALLBACK and SITE_BUFFER_M_FALLBACK > SITE_BUFFER_M:\n",
    "            radius_used = SITE_BUFFER_M_FALLBACK\n",
    "            buf = proj_geom.buffer(radius_used)\n",
    "            counts = compute_counts(buf)\n",
    "\n",
    "        bldg_pct, road_density = building_and_road_density(buildings_proj, edges_gdf, buf)\n",
    "        all_counts.append((radius_used, counts))\n",
    "        all_build_road.append((bldg_pct, road_density))\n",
    "\n",
    "    # ----------------------------\n",
    "    # Assemble per-candidate results\n",
    "    # ----------------------------\n",
    "    print(\"\\nBuilding Folium map…\")\n",
    "    aoi_latlon = aoi.to_crs(epsg=4326)\n",
    "    center = [aoi_latlon.geometry.iloc[0].centroid.y, aoi_latlon.geometry.iloc[0].centroid.x]\n",
    "\n",
    "    edges_latlon = edges_gdf.to_crs(epsg=4326)\n",
    "    uncovered_latlon = uncovered.to_crs(epsg=4326)\n",
    "    greens_latlon = greens_poly_proj.to_crs(epsg=4326)\n",
    "    cand_latlon_final = cand_proj.to_crs(epsg=4326)  # for plotting markers\n",
    "    iso5_latlon = iso5_poly.to_crs(epsg=4326) if iso5_poly is not None else None\n",
    "    iso10_latlon = iso10_poly.to_crs(epsg=4326) if iso10_poly is not None else None\n",
    "\n",
    "    m = folium.Map(location=center, zoom_start=12, control_scale=True, tiles=\"cartodbpositron\")\n",
    "    folium.GeoJson(\n",
    "        greens_latlon[[\"geometry\"]],\n",
    "        name=f\"Green areas (OSM + NDVI≥{NDVI_GREEN_MIN:.2f})\",\n",
    "        style_function=lambda _: {\"color\": \"#2e7d32\", \"weight\": 1, \"fillColor\": \"#66bb6a\", \"fillOpacity\": 0.35},\n",
    "    ).add_to(m)\n",
    "    if iso10_latlon is not None:\n",
    "        folium.GeoJson(iso10_latlon.__geo_interface__, name=\"Within 10 min of green\",\n",
    "                       style_function=lambda _: {\"color\": \"#ff9800\", \"weight\": 1, \"fillColor\": \"#ffcc80\", \"fillOpacity\": 0.25}).add_to(m)\n",
    "    if iso5_latlon is not None:\n",
    "        folium.GeoJson(iso5_latlon.__geo_interface__, name=\"Within 5 min of green\",\n",
    "                       style_function=lambda _: {\"color\": \"#1976d2\", \"weight\": 1, \"fillColor\": \"#90caf9\", \"fillOpacity\": 0.25}).add_to(m)\n",
    "    folium.GeoJson(\n",
    "        uncovered_latlon[[\"geometry\"]],\n",
    "        name=\"Road segments beyond 10 min (need green access)\",\n",
    "        style_function=lambda _: {\"color\": \"#e53935\", \"weight\": 2, \"opacity\": 0.9},\n",
    "    ).add_to(m)\n",
    "\n",
    "    description = \"\"\n",
    "\n",
    "    description += (\"\\n================= Candidate Site Context =================\\n\")\n",
    "    summary_rows = []\n",
    "\n",
    "    for idx, (cid, latlon_geom, proj_geom) in enumerate(zip(ids, cand_latlon_final.geometry, cand_proj.geometry), start=1):\n",
    "        lat, lon = latlon_geom.y, latlon_geom.x\n",
    "\n",
    "        # Lookups from batched dicts\n",
    "        pop_val = first_number(pop_results.get(cid, {}), [\"pop\", \"sum\"]) if DO_POP else None\n",
    "\n",
    "        gsw_mean = first_number(jrc_mean_results.get(cid, {}), [\"occurrence\", \"mean\"])\n",
    "        gsw_max  = first_number(jrc_max_results.get(cid, {}), [\"occurrence\", \"max\"])\n",
    "\n",
    "        soil_label, soil_props = soil_results.get(cid, (None, {}))\n",
    "        def _get(d, keys):\n",
    "            for k in d.keys():\n",
    "                lk = k.lower()\n",
    "                if all(t in lk for t in keys):\n",
    "                    try:\n",
    "                        return float(d[k])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            return None\n",
    "        soil_ph   = round(_get(soil_props, (\"ph\",))        , 2) if _get(soil_props, (\"ph\",))         is not None else None\n",
    "        soil_clay = round(_get(soil_props, (\"clay\",))      , 1) if _get(soil_props, (\"clay\",))       is not None else None\n",
    "        soil_sand = round(_get(soil_props, (\"sand\",))      , 1) if _get(soil_props, (\"sand\",))       is not None else None\n",
    "        soil_soc  = round(_get(soil_props, (\"org\",\"carb\")) , 1) if _get(soil_props, (\"org\",\"carb\"))  is not None else None\n",
    "        if soil_ph is None and soil_clay is None and soil_sand is None and soil_soc is None:\n",
    "            soil_label = None\n",
    "\n",
    "        hand_val  = first_number(hand_results.get(cid, {}), [\"hand_proxy\", \"mean\"]) if DO_HAND else None\n",
    "        slope_val = first_number(slope_results.get(cid, {}), [\"slope\", \"mean\"]) if DO_HAND else None\n",
    "        modis_c   = first_number(heat_modis.get(cid, {}), [\"LST_modis_C\", \"mean\"]) if DO_HEAT else None\n",
    "        eco_c     = first_number(heat_eco.get(cid, {}), [\"LST_eco_C\", \"mean\"]) if DO_HEAT else None\n",
    "        smap_sm   = first_number(smap_results.get(cid, {}), [\"soil_moisture\", \"mean\"]) if DO_SMAP else None\n",
    "\n",
    "        # Distance to OSM water\n",
    "        dist_to_water_m = None\n",
    "        if water_union is not None:\n",
    "            try:\n",
    "                dist_to_water_m = round(float(proj_geom.distance(water_union)), 1)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Counts & urban form (local)\n",
    "        radius_used, counts = all_counts[idx-1]\n",
    "        bldg_pct, road_density = all_build_road[idx-1]\n",
    "\n",
    "        # Interpretations\n",
    "        water_distance_msg = f\"{interpret_distance_to_water(dist_to_water_m)} — {fmt_meters_and_walk(dist_to_water_m)}.\"\n",
    "        water_occ_msg = interpret_water_occurrence(gsw_mean)\n",
    "        ph_msg = interpret_ph(soil_ph)\n",
    "        texture_msg = interpret_texture(soil_sand, soil_clay)\n",
    "        density_msg = interpret_density(bldg_pct, road_density)\n",
    "        heat_msg = interpret_heat(modis_c, eco_c)\n",
    "        hand_msg = interpret_hand_proxy(hand_val, slope_val, gsw_mean)\n",
    "\n",
    "        # ---- CLEAN CONSOLE OUTPUT (no nearby-counts line) ----\n",
    "        description += (f\"\\n📍 Candidate #{cid}  (Lat, Lon: {lat:.6f}, {lon:.6f})\\n\")\n",
    "        if DO_POP and pop_val is not None:\n",
    "            description += (f\"  People within a 10-min walk (estimated): ~{int(pop_val):,}\\n\")\n",
    "        description += (f\"  Water: nearest mapped water is {fmt_meters_and_walk(dist_to_water_m)}. {water_distance_msg}\\n\")\n",
    "        description += (f\"  Water presence (satellite history ≤{WATER_STATS_RADIUS_M} m): mean {gsw_mean}, max {gsw_max}. {water_occ_msg}\\n\")\n",
    "        description += (f\"  Soil (0–5 cm): pH={soil_ph} (src: {soil_label}), clay%={soil_clay}, sand%={soil_sand}, SOC g/kg={soil_soc}.\\n\")\n",
    "        description += (f\"  ↳ {ph_msg}  |  {texture_msg}\\n\")\n",
    "        if DO_HAND:\n",
    "            description += (f\"  Terrain: HAND-proxy {hand_val} m; slope ~{slope_val}°. {hand_msg}\\n\")\n",
    "        if DO_HEAT:\n",
    "            description += (f\"  Heat (Apr–Jun): MODIS≈{modis_c}°C\"\n",
    "                  f\"{' | ECOSTRESS≈'+str(eco_c)+'°C' if eco_c is not None else ''}. {heat_msg}\\n\")\n",
    "        if DO_SMAP and smap_sm is not None:\n",
    "            description += (f\"  Soil moisture (SMAP {SMAP_DAYS}-day mean): {smap_sm} m³/m³\\n\")\n",
    "        if bldg_pct is not None or road_density is not None:\n",
    "            description += (f\"  Urban form: building cover ~{bldg_pct if bldg_pct is not None else 'n/a'}% \"\n",
    "                  f\"& roads ~{road_density if road_density is not None else 'n/a'} km/km² → {density_msg}\\n\")\n",
    "\n",
    "        print(description.strip())\n",
    "\n",
    "        llm_res = groq_api.inference(description)\n",
    "        llm_res_dict = groq_api.parse_response(llm_res)\n",
    "        if not llm_res_dict:\n",
    "            print(\"  (Empty from parser.)\\n\")\n",
    "        # Map popup (keeps counts)\n",
    "        popup_html = f\"\"\"\n",
    "        <div style='font-size:12px;line-height:1.35'>\n",
    "          <i>Lat, Lon:</i> {lat:.6f}, {lon:.6f}<br>\n",
    "          <b>People within 10-min walk:</b> {('{:,}'.format(int(pop_val)) if (DO_POP and pop_val is not None) else 'n/a')}<br>\n",
    "          <b>Nearby (≤{radius_used} m)</b><br>\n",
    "          schools:{counts.get('schools',0)} · colleges:{counts.get('colleges',0)} · universities:{counts.get('universities',0)}<br>\n",
    "          hospitals:{counts.get('hospitals',0)} · clinics:{counts.get('clinics',0)} · pharmacies:{counts.get('pharmacies',0)}<br>\n",
    "          markets:{counts.get('markets',0)} · worship:{counts.get('worship',0)} · supermarkets:{counts.get('supermarkets',0)}<br>\n",
    "          playgrounds:{counts.get('playgrounds',0)} · sports:{counts.get('sports',0)} · parks/gardens:{counts.get('parks_gardens',0)}<br>\n",
    "          <b>Water</b><br>\n",
    "          nearest: {fmt_meters_and_walk(dist_to_water_m)}<br>\n",
    "          JRC occurrence (≤{WATER_STATS_RADIUS_M} m, mean/max): {gsw_mean} / {gsw_max}<br>\n",
    "          <i>{water_occ_msg}</i><br>\n",
    "          <b>Soil (0–5 cm)</b><br>\n",
    "          pH: {soil_ph} (src: {soil_label}) — <i>{ph_msg}</i><br>\n",
    "          texture: sand {soil_sand}% / clay {soil_clay}% — <i>{texture_msg}</i><br>\n",
    "          SOC: {soil_soc} g/kg<br>\n",
    "          <b>Terrain</b><br>\n",
    "          HAND-proxy: {hand_val} m · slope: {slope_val}°<br>\n",
    "          <i>{hand_msg}</i><br>\n",
    "          <b>Heat (Apr–Jun)</b><br>\n",
    "          MODIS: {modis_c}°C{(' · ECOSTRESS: '+str(eco_c)+'°C') if eco_c is not None else ''}<br>\n",
    "          <i>{heat_msg}</i><br>\n",
    "          <b>Soil moisture</b><br>\n",
    "          SMAP {SMAP_DAYS}-day mean: {smap_sm} m³/m³<br>\n",
    "          <b>Urban form</b><br>\n",
    "          buildings ~{bldg_pct if bldg_pct is not None else 'n/a'}% · roads ~{road_density if road_density is not None else 'n/a'} km/km²<br>\n",
    "          <i>{density_msg}</i>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        folium.CircleMarker(\n",
    "            location=(lat, lon), radius=6, color=\"#2962FF\",\n",
    "            fill=True, fill_color=\"#2962FF\", fill_opacity=0.95,\n",
    "            popup=folium.Popup(popup_html, max_width=380),\n",
    "        ).add_to(m)\n",
    "\n",
    "        # CSV row\n",
    "        row = {\n",
    "            \"candidate_id\": cid,\n",
    "            \"lat\": lat, \"lon\": lon,\n",
    "            \"radius_used_m\": radius_used,\n",
    "            \"people_walk10\": int(pop_val) if (DO_POP and pop_val is not None) else None,\n",
    "            \"dist_to_osm_water_m\": dist_to_water_m,\n",
    "            \"gsw_occ_mean\": gsw_mean, \"gsw_occ_max\": gsw_max,\n",
    "            \"soil_ph_0_5cm\": soil_ph, \"soil_clay_pct_0_5cm\": soil_clay,\n",
    "            \"soil_sand_pct_0_5cm\": soil_sand, \"soil_soc_gkg_0_5cm\": soil_soc,\n",
    "            \"soil_source\": soil_label,\n",
    "            \"hand_proxy_m\": hand_val, \"slope_deg\": slope_val,\n",
    "            \"modis_lst_C\": modis_c, \"ecostress_lst_C\": eco_c,\n",
    "            \"smap_sm_m3m3\": smap_sm,\n",
    "            \"building_cover_pct\": bldg_pct, \"road_km_per_km2\": road_density,\n",
    "        }\n",
    "        for k in POI_CATEGORIES.keys():\n",
    "            row[f\"cnt_{k}__{radius_used}m\"] = counts.get(k, 0)\n",
    "        summary_rows.append(row)\n",
    "\n",
    "    # Legend & controls\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"position: fixed; bottom: 18px; left: 18px; z-index:9999; background: white;\n",
    "                padding: 10px 12px; border: 1px solid #ccc; border-radius: 6px; font-size: 13px;\">\n",
    "      <b>Legend</b><br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#66bb6a;border:1px solid #2e7d32;\"></span>\n",
    "      Green areas (OSM + NDVI≥{NDVI_GREEN_MIN:.2f})<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#ffcc80;border:1px solid #ff9800;\"></span>\n",
    "      ≤ 10 min walk<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#90caf9;border:1px solid #1976d2;\"></span>\n",
    "      ≤ 5 min walk<br>\n",
    "      <span style=\"display:inline-block;width:18px;height:2px;background:#e53935;vertical-align:middle;display:inline-block;\"></span>\n",
    "      Uncovered roads (> 10 min)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#2962FF;border:1px solid #2962FF;\"></span>\n",
    "      Candidate micro-park\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    # Save map\n",
    "    out_cwd = \"narayanganj_green_access_ndvi_osm.html\"\n",
    "    m.save(out_cwd)\n",
    "    print(f\"\\n✅ Saved map in current folder: {out_cwd}\")\n",
    "    try:\n",
    "        os.makedirs(DOWNLOADS, exist_ok=True)\n",
    "        m.save(OUT_HTML)\n",
    "        print(f\"✅ Also saved to: {OUT_HTML}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save to ~/Downloads:\", e)\n",
    "\n",
    "    # Save CSV\n",
    "    try:\n",
    "        df = gpd.pd.DataFrame(summary_rows)\n",
    "        df.to_csv(OUT_CSV, index=False)\n",
    "        print(f\"✅ Site context CSV saved to: {OUT_CSV}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not write CSV:\", e)\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "# ----------------------------\n",
    "# OSMNX COMPAT HELPERS IMPORT\n",
    "# ----------------------------\n",
    "try:\n",
    "    from osmnx.features import features_from_polygon as osm_features_from_polygon\n",
    "except Exception:\n",
    "    try:\n",
    "        from osmnx import geometries_from_polygon as osm_features_from_polygon\n",
    "    except Exception:\n",
    "        raise SystemExit(\"Your osmnx version is missing polygon geometries. Please: pip install --upgrade osmnx.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411507a-32cd-4e3e-aaf4-f918bb2b7877",
   "metadata": {},
   "source": [
    "## Data Sources \n",
    "\n",
    "* **Greenery (NDVI)**\n",
    "  From **Sentinel-2** (Copernicus/ESA). The MSI sensor has **13 bands** at 10–60 m; NDVI is computed from the **red** (`B4`) and **NIR** (`B8`) bands.\n",
    "  *Source: European Space Agency.*\n",
    "\n",
    "* **Water presence (“JRC water occurrence”)**\n",
    "  From the **JRC Global Surface Water** dataset, derived from ~30 m **Landsat** imagery (1984 → present). The “occurrence” score is the **% of years a pixel appeared as water**.\n",
    "  *Source: Google for Developers (JRC GSW).*\n",
    "\n",
    "* **Soil properties (pH, sand/clay, SOC)**\n",
    "  From **ISRIC SoilGrids**. These are **machine-learning predictions** built from ~230k soil profiles plus many covariates (including remote sensing); it’s not a single satellite sensor. We sample the **0–5 cm** layer.\n",
    "  *Source: ISRIC.*\n",
    "\n",
    "* **“Traffic” vs what we really compute**\n",
    "  The code reports **road network density (km/km²)** from **OpenStreetMap** geometry near each site. That’s a **built-environment proxy**, **not live traffic**. (Live traffic requires other data sources/APIs.)\n",
    "\n",
    "* **Population exposure**\n",
    "  **WorldPop (~100 m)** and/or **GHSL POP** to estimate **how many people** benefit within a walk-shed. Both are **gridded population surfaces**.\n",
    "\n",
    "* **DEM-based indices (e.g., HAND)**\n",
    "  Using **Copernicus DEM GLO-30** or **MERIT DEM** to flag **low-lying / flood-prone** spots; combine with **JRC water history**.\n",
    "\n",
    "* **Soil moisture**\n",
    "  **SMAP** for **surface wetness background**.\n",
    "\n",
    "* **Heat (MODIS/ECOSTRESS)**\n",
    "  Compute **average summer daytime LST** around each candidate and add a **“heat score.”**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20142c39-688b-4d1e-86fc-71342e5a664c",
   "metadata": {},
   "source": [
    "# Air Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de505cdb-e1e9-49d0-bc56-1f3fa451d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narayanganj_aq_hotspots_readable.py\n",
    "# Hotspots → Top-3 area-wise clusters with concave envelopes + summaries\n",
    "# (population, plain-language AQ severity + seasonality, sensitive sites inside,\n",
    "# named industries/point sources inside). Speed-optimized.\n",
    "\n",
    "import markdown\n",
    "from models.llms import groq_api\n",
    "\n",
    "import os, tempfile, base64\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import ee\n",
    "import folium\n",
    "from folium.plugins import MiniMap, Fullscreen, MousePosition, MeasureControl\n",
    "from shapely.geometry import Point, MultiPoint, box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import re\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# OSM / Geo deps\n",
    "try:\n",
    "    import osmnx as ox\n",
    "    import geopandas as gpd\n",
    "except Exception as e:\n",
    "    raise SystemExit(\n",
    "        f\"Import error: {e}\\nInstall: pip install osmnx geopandas rtree\\n\"\n",
    "        \"If NumPy 2.x issues: pip install 'numpy<2' && reinstall geopandas shapely pyproj fiona rtree\"\n",
    "    )\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "AOI_BBOX = [90.32, 23.70, 90.52, 23.86]  # (W,S,E,N)\n",
    "\n",
    "DAYS_BACK = 60\n",
    "END = date.today()\n",
    "START = END - timedelta(days=DAYS_BACK)\n",
    "\n",
    "# EE sampling scale + limits (tuned for speed)\n",
    "SCALE_M = 1200\n",
    "MAX_POINTS = 3000\n",
    "MAX_HOTSPOTS = 120\n",
    "EE_TILE_SCALE = 4\n",
    "\n",
    "# Weights for combined AQ index (z-space)\n",
    "W_NO2 = 0.6\n",
    "W_PM25 = 0.6\n",
    "W_CO  = 0.3\n",
    "\n",
    "# Hotspot selection\n",
    "Z_THRESHOLD = 1.0\n",
    "PCTL_THRESHOLD = 85.0\n",
    "\n",
    "# Clustering\n",
    "EPS_METERS = 1500.0\n",
    "MIN_SAMPLES = 6\n",
    "\n",
    "# Concave envelope controls\n",
    "ALPHA_M = 1200            # “tightness” (m)\n",
    "MIN_ENVELOPE_POINTS = 5   # min pts to build polygon\n",
    "MIN_POLY_AREA_M2 = 2000   # drop tiny artifacts (~0.002 km²)\n",
    "\n",
    "# Severity buckets\n",
    "SEVERE_Z = 2.0\n",
    "HIGH_Z   = 1.0\n",
    "ELEV_Z   = 0.5\n",
    "\n",
    "COLORS = {\n",
    "    \"severe\": \"#d32f2f\",\n",
    "    \"high\":   \"#fb8c00\",\n",
    "    \"elev\":   \"#ffd54f\",\n",
    "    \"envelope\": \"#673ab7\"\n",
    "}\n",
    "\n",
    "USER = os.getenv(\"USER\") or os.getenv(\"USERNAME\") or \"user\"\n",
    "OUT_HTML = f\"/Users/{USER}/Downloads/narayanganj_aq_hotspots_readable.html\"\n",
    "\n",
    "# ------------------ EE INIT ------------------\n",
    "def ee_init_headless():\n",
    "    sa = os.environ[\"EE_SERVICE_ACCOUNT\"]       # ee-runner@<project>.iam.gserviceaccount.com\n",
    "    key_b64 = os.environ[\"EE_KEY_B64\"]          # base64 of the JSON key\n",
    "\n",
    "    # Write key to a temp file\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "        f.write(base64.b64decode(key_b64).decode(\"utf-8\"))\n",
    "        key_path = f.name\n",
    "\n",
    "    creds = ee.ServiceAccountCredentials(sa, key_path)\n",
    "    ee.Initialize(credentials=creds)\n",
    "\n",
    "# ------------------ UTIL ------------------\n",
    "def season_windows(today: date):\n",
    "    y = today.year\n",
    "    if today.month >= 4:\n",
    "        dry_start = date(y - 1, 12, 1); dry_end = date(y, 3, 31)\n",
    "    else:\n",
    "        dry_start = date(y - 2, 12, 1); dry_end = date(y - 1, 3, 31)\n",
    "    if (today.month, today.day) >= (9, 15):\n",
    "        mon_start = date(y, 6, 1); mon_end = date(y, 9, 15)\n",
    "    else:\n",
    "        mon_start = date(y - 1, 6, 1); mon_end = date(y - 1, 9, 15)\n",
    "    return dry_start, dry_end, mon_start, mon_end\n",
    "\n",
    "def utm_crs_from_bbox(bbox):\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    lon_c = (minx + maxx) / 2.0\n",
    "    lat_c = (miny + maxy) / 2.0\n",
    "    zone = int((lon_c + 180) // 6) + 1\n",
    "    epsg = 32600 + zone if lat_c >= 0 else 32700 + zone\n",
    "    return f\"EPSG:{epsg}\"\n",
    "\n",
    "# Plain-language helpers\n",
    "def z_to_level_text(z):\n",
    "    if z is None:\n",
    "        return \"n/a\"\n",
    "    if z >= 2.0: return \"Very high (well above typical)\"\n",
    "    if z >= 1.0: return \"High (above typical)\"\n",
    "    if z >= 0.5: return \"Slightly elevated\"\n",
    "    if z > -0.5: return \"Around typical\"\n",
    "    return \"Below typical\"\n",
    "\n",
    "def seasonality_plain(zd, zm):\n",
    "    \"\"\"Return a readable sentence comparing monsoon vs dry.\"\"\"\n",
    "    if zd is None or zm is None:\n",
    "        return \"not enough data\"\n",
    "    diff = zm - zd  # monsoon minus dry\n",
    "    if diff > 0.25:\n",
    "        trend = \"worse in the monsoon than the dry season\"\n",
    "    elif diff < -0.25:\n",
    "        trend = \"worse in the dry season than the monsoon\"\n",
    "    else:\n",
    "        trend = \"similar between seasons\"\n",
    "    return f\"{trend} (monsoon {zm:.2f}, dry {zd:.2f} in standardized units; Δ={diff:+.2f})\"\n",
    "\n",
    "# ------------------ EE IMAGES ------------------\n",
    "def build_mean_images(aoi, start_iso, end_iso):\n",
    "    no2 = (ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_NO2\")\n",
    "           .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "           .select(\"tropospheric_NO2_column_number_density\")\n",
    "           .mean().rename(\"no2\").unmask(0)).clip(aoi)\n",
    "    co = (ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_CO\")\n",
    "          .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "          .select(\"CO_column_number_density\")\n",
    "          .mean().rename(\"co\").unmask(0)).clip(aoi)\n",
    "    aod = (ee.ImageCollection(\"MODIS/061/MCD19A2_GRANULES\")\n",
    "           .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "           .select(\"Optical_Depth_047\")\n",
    "           .mean().rename(\"aod\").unmask(0)).clip(aoi)\n",
    "    pm25 = aod.multiply(60.0).rename(\"pm25\")\n",
    "    return no2, pm25, co\n",
    "\n",
    "def image_to_z(img, aoi, band_name):\n",
    "    stats_mean = img.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(), geometry=aoi, scale=SCALE_M,\n",
    "        maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE\n",
    "    )\n",
    "    stats_std = img.reduceRegion(\n",
    "        reducer=ee.Reducer.stdDev(), geometry=aoi, scale=SCALE_M,\n",
    "        maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE\n",
    "    )\n",
    "    mean_val = stats_mean.get(band_name)\n",
    "    std_val  = stats_std.get(band_name)\n",
    "    mean_num = ee.Number(ee.Algorithms.If(mean_val, mean_val, 0))\n",
    "    std_num  = ee.Number(ee.Algorithms.If(std_val,  std_val,  1)).max(1e-6)\n",
    "    return img.subtract(mean_num).divide(std_num).rename(f\"{band_name}_z\")\n",
    "\n",
    "def combined_z_image(aoi, start_iso, end_iso):\n",
    "    no2, pm25, co = build_mean_images(aoi, start_iso, end_iso)\n",
    "    no2z = image_to_z(no2, aoi, \"no2\")\n",
    "    pmz  = image_to_z(pm25, aoi, \"pm25\")\n",
    "    coz  = image_to_z(co, aoi, \"co\")\n",
    "    comb = (no2z.multiply(W_NO2).add(pmz.multiply(W_PM25)).add(coz.multiply(W_CO))).rename(\"aq_index_z\")\n",
    "    return no2z, pmz, coz, comb\n",
    "\n",
    "# ------------------ POPULATION ------------------\n",
    "def population_image(aoi):\n",
    "    for yr in [2025, 2023, 2022, 2021, 2020, 2019]:\n",
    "        try:\n",
    "            col = ee.ImageCollection(\"WorldPop/GP/100m/pop\").filterBounds(aoi).filter(ee.Filter.eq('year', yr))\n",
    "            if col.size().getInfo() > 0:\n",
    "                img = col.mosaic()\n",
    "                bname = img.bandNames().getInfo()[0]\n",
    "                return img.select(bname, [\"pop\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        img = ee.Image(\"JRC/GHSL/P2019/POP_GLOBE_R2019A\")\n",
    "        bands = [b for b in img.bandNames().getInfo() if \"2020\" in b or \"2015\" in b]\n",
    "        if bands:\n",
    "            return img.select(bands[0], [\"pop\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        col = ee.ImageCollection(\"CIESIN/GPWv411/GPW_Population_Count\").filter(ee.Filter.eq(\"year\", 2020))\n",
    "        img = col.first()\n",
    "        if img:\n",
    "            b = img.bandNames().getInfo()[0]\n",
    "            return img.select(b, [\"pop\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def reduce_region_sum(image, region, scale):\n",
    "    try:\n",
    "        val = image.reduceRegion(\n",
    "            reducer=ee.Reducer.sum(), geometry=region, scale=scale,\n",
    "            maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE\n",
    "        ).get(\"pop\")\n",
    "        return float(ee.Number(ee.Algorithms.If(val, val, 0)).getInfo())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def ee_means_in_poly(img_dict, poly):\n",
    "    geom = ee.Geometry(poly.__geo_interface__)\n",
    "    bands = []\n",
    "    for name, im in img_dict.items():\n",
    "        bands.append(im.rename(name))\n",
    "    stack = bands[0]\n",
    "    for i in range(1, len(bands)):\n",
    "        stack = stack.addBands(bands[i])\n",
    "    try:\n",
    "        vals = stack.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=geom, scale=SCALE_M,\n",
    "            maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE\n",
    "        )\n",
    "        out = {}\n",
    "        for name in img_dict.keys():\n",
    "            v = vals.get(name)\n",
    "            out[name] = float(ee.Number(ee.Algorithms.If(v, v, 0)).getInfo())\n",
    "        return out\n",
    "    except Exception:\n",
    "        return {name: None for name in img_dict.keys()}\n",
    "\n",
    "# ------------------ SAMPLING & STATS ------------------\n",
    "def sample_grid(aoi, img_stack, scale_m=SCALE_M, max_points=MAX_POINTS):\n",
    "    fc = img_stack.sample(region=aoi, scale=scale_m, geometries=True)\n",
    "    feats = fc.limit(max_points).getInfo().get(\"features\", [])\n",
    "    rows = []\n",
    "    for f in feats:\n",
    "        geom = f.get(\"geometry\", {})\n",
    "        if geom.get(\"type\") != \"Point\": continue\n",
    "        lon, lat = geom[\"coordinates\"]\n",
    "        p = f.get(\"properties\", {})\n",
    "        no2, pm25, co = p.get(\"no2\"), p.get(\"pm25\"), p.get(\"co\")\n",
    "        if None in (no2, pm25, co): continue\n",
    "        rows.append({\"lat\": float(lat), \"lon\": float(lon),\n",
    "                     \"no2\": float(no2), \"pm25\": float(pm25), \"co\": float(co)})\n",
    "    return rows\n",
    "\n",
    "def zscores(vals):\n",
    "    good = [v for v in vals if v is not None and math.isfinite(v)]\n",
    "    if len(good) < 2: return [0.0 for _ in vals]\n",
    "    mean = sum(good)/len(good)\n",
    "    var  = sum((v-mean)**2 for v in good)/len(good)\n",
    "    std  = math.sqrt(max(var, 1e-12))\n",
    "    return [0.0 if (v is None or not math.isfinite(v)) else (v-mean)/std for v in vals]\n",
    "\n",
    "def p_rank(all_vals, v):\n",
    "    s = sorted(all_vals)\n",
    "    if not s: return 0.0\n",
    "    cnt = sum(1 for x in s if x <= v)\n",
    "    return 100.0 * cnt / len(s)\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = p2 - p1\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "def cluster_dbscan(points, eps_m=EPS_METERS, min_samples=MIN_SAMPLES):\n",
    "    n = len(points)\n",
    "    if n == 0: return []\n",
    "    buckets = {}\n",
    "    for i, p in enumerate(points):\n",
    "        key = (int(p[\"lat\"]/0.01), int(p[\"lon\"]/0.01))  # ~1.1 km cells\n",
    "        buckets.setdefault(key, []).append(i)\n",
    "    visited = [False]*n\n",
    "    clusters = [-1]*n\n",
    "    nbrs = [[] for _ in range(n)]\n",
    "    for key, idxs in buckets.items():\n",
    "        kx, ky = key\n",
    "        cand = []\n",
    "        for dx in (-1,0,1):\n",
    "            for dy in (-1,0,1):\n",
    "                cand += buckets.get((kx+dx, ky+dy), [])\n",
    "        for i in idxs:\n",
    "            for j in cand:\n",
    "                if j <= i: continue\n",
    "                if haversine_m(points[i][\"lat\"], points[i][\"lon\"], points[j][\"lat\"], points[j][\"lon\"]) <= eps_m:\n",
    "                    nbrs[i].append(j); nbrs[j].append(i)\n",
    "    cid = 0\n",
    "    for i in range(n):\n",
    "        if visited[i]: continue\n",
    "        visited[i] = True\n",
    "        if len(nbrs[i]) + 1 < min_samples:\n",
    "            clusters[i] = -1; continue\n",
    "        clusters[i] = cid\n",
    "        seeds = list(nbrs[i]); k = 0\n",
    "        while k < len(seeds):\n",
    "            j = seeds[k]\n",
    "            if not visited[j]:\n",
    "                visited[j] = True\n",
    "                if len(nbrs[j]) + 1 >= min_samples:\n",
    "                    for q in nbrs[j]:\n",
    "                        if q not in seeds: seeds.append(q)\n",
    "            if clusters[j] < 0: clusters[j] = cid\n",
    "            k += 1\n",
    "        cid += 1\n",
    "    return clusters\n",
    "\n",
    "def ensure_clusters(hotspots):\n",
    "    clusters = cluster_dbscan(hotspots, eps_m=EPS_METERS, min_samples=MIN_SAMPLES)\n",
    "    if not any(c >= 0 for c in clusters):\n",
    "        clusters = cluster_dbscan(hotspots, eps_m=EPS_METERS*1.6, min_samples=max(3, MIN_SAMPLES-2))\n",
    "    if not any(c >= 0 for c in clusters):\n",
    "        clusters = [0 for _ in hotspots]\n",
    "    return clusters\n",
    "\n",
    "# ------------------ OSM HELPERS ------------------\n",
    "def aoi_polygon_wgs84():\n",
    "    minx, miny, maxx, maxy = AOI_BBOX\n",
    "    return box(minx, miny, maxx, maxy)\n",
    "\n",
    "def osm_geoms_from_polygon(aoi_poly_wgs84, tags_dict):\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.timeout = 180\n",
    "    try:\n",
    "        from osmnx.features import features_from_polygon as osm_features_from_polygon\n",
    "    except Exception:\n",
    "        try:\n",
    "            from osmnx import geometries_from_polygon as osm_features_from_polygon\n",
    "        except Exception:\n",
    "            raise SystemExit(\"OSMnx missing polygon geometries. pip install --upgrade osmnx\")\n",
    "    layers = []\n",
    "    for k, v in tags_dict.items():\n",
    "        try:\n",
    "            g = osm_features_from_polygon(aoi_poly_wgs84, tags={k: v})\n",
    "            if g is not None and not g.empty:\n",
    "                layers.append(g)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not layers:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    base_crs = layers[0].crs or \"EPSG:4326\"\n",
    "    all_feats = gpd.GeoDataFrame(gpd.pd.concat(layers, ignore_index=True), crs=base_crs)\n",
    "    all_feats = all_feats[all_feats.geometry.notna()].copy()\n",
    "    return all_feats.to_crs(epsg=4326)\n",
    "\n",
    "def count_sensitive_inside(sens_gdf, polygon):\n",
    "    if sens_gdf is None or sens_gdf.empty:\n",
    "        return dict(schools=0, clinics=0, hospitals=0, elder_homes=0)\n",
    "    try:\n",
    "        idx = sens_gdf.sindex\n",
    "        sub = sens_gdf.iloc[list(idx.intersection(polygon.bounds))]\n",
    "        inside = sub[sub.geometry.intersects(polygon)]\n",
    "    except Exception:\n",
    "        inside = sens_gdf[sens_gdf.geometry.intersects(polygon)]\n",
    "    res = dict(schools=0, clinics=0, hospitals=0, elder_homes=0)\n",
    "    if inside.empty:\n",
    "        return res\n",
    "    if \"amenity\" in inside.columns:\n",
    "        res[\"schools\"] = int((inside[\"amenity\"]==\"school\").sum())\n",
    "        res[\"clinics\"] = int(((inside[\"amenity\"]==\"clinic\") | (inside[\"amenity\"]==\"doctors\")).sum())\n",
    "        res[\"hospitals\"] = int((inside[\"amenity\"]==\"hospital\").sum())\n",
    "    if \"social_facility\" in inside.columns:\n",
    "        res[\"elder_homes\"] = int(inside[\"social_facility\"].isin([\"nursing_home\",\"assisted_living\"]).sum())\n",
    "    return res\n",
    "\n",
    "def friendly_unnamed(row):\n",
    "    \"\"\"Produce a readable label when OSM has no name.\"\"\"\n",
    "    # Try a few informative tags to hint the type\n",
    "    for key in (\"industrial\",\"power\",\"man_made\",\"landuse\",\"waterway\",\"harbour\",\"amenity\"):\n",
    "        val = row.get(key)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            if key == \"power\" and val == \"plant\":\n",
    "                return \"Unnamed facility (power plant)\"\n",
    "            if key == \"industrial\":\n",
    "                return \"Unnamed facility (industrial)\"\n",
    "            if key == \"man_made\":\n",
    "                return f\"Unnamed facility (man_made={val})\"\n",
    "            if key == \"waterway\":\n",
    "                return f\"Unnamed riverside/port feature ({val})\"\n",
    "            if key == \"harbour\":\n",
    "                return \"Unnamed harbour/jetty\"\n",
    "            if key == \"landuse\" and val == \"industrial\":\n",
    "                return \"Unnamed facility (industrial landuse)\"\n",
    "            if key == \"amenity\":\n",
    "                return f\"Unnamed amenity ({val})\"\n",
    "            return f\"Unnamed facility ({key}={val})\"\n",
    "    return \"Unnamed facility (OSM)\"\n",
    "\n",
    "def list_osm_names_in_poly(gdf, polygon, max_show=40):\n",
    "    if gdf is None or gdf.empty:\n",
    "        return [], 0\n",
    "    try:\n",
    "        idx = gdf.sindex\n",
    "        cand = gdf.iloc[list(idx.intersection(polygon.bounds))]\n",
    "        inside = cand[cand.geometry.intersects(polygon)]\n",
    "    except Exception:\n",
    "        inside = gdf[gdf.geometry.intersects(polygon)]\n",
    "    count = len(inside)\n",
    "    if count == 0:\n",
    "        return [], 0\n",
    "    name_cols = [c for c in [\"name\", \"name:en\", \"operator\", \"brand\"] if c in inside.columns]\n",
    "    names = []\n",
    "    for _, r in inside.iterrows():\n",
    "        nm = None\n",
    "        for c in name_cols:\n",
    "            val = r.get(c)\n",
    "            if isinstance(val, str) and val.strip():\n",
    "                nm = val.strip(); break\n",
    "        if nm is None:\n",
    "            nm = friendly_unnamed(r)\n",
    "        names.append(nm)\n",
    "    names = sorted(set(names))\n",
    "    if len(names) > max_show:\n",
    "        names = names[:max_show] + [f\"... (+{len(set(names))-max_show} more)\"]\n",
    "    return names, count\n",
    "\n",
    "# ------------------ ENVELOPES (concave polygons) ------------------\n",
    "def build_concave_envelopes(hotspots, clusters, metric_crs, alpha_m=ALPHA_M, min_pts=MIN_ENVELOPE_POINTS):\n",
    "    \"\"\"Returns dict cid -> list[Polygon in WGS84], with tiny/degenerate parts removed.\"\"\"\n",
    "    by_cluster = {}\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        if cid < 0: continue\n",
    "        by_cluster.setdefault(cid, []).append(hp)\n",
    "\n",
    "    out = {}\n",
    "    for cid, pts in by_cluster.items():\n",
    "        if len(pts) < min_pts:\n",
    "            continue\n",
    "        pts_wgs = gpd.GeoSeries([Point(p[\"lon\"], p[\"lat\"]) for p in pts], crs=\"EPSG:4326\").to_crs(metric_crs)\n",
    "        buf = pts_wgs.buffer(alpha_m)\n",
    "        merged = unary_union(list(buf.values))\n",
    "        shell = merged.buffer(-alpha_m)\n",
    "        geom = shell if not shell.is_empty else merged.convex_hull\n",
    "        polys = []\n",
    "        if geom.geom_type == \"Polygon\":\n",
    "            polys = [geom]\n",
    "        elif geom.geom_type == \"MultiPolygon\":\n",
    "            polys = list(geom.geoms)\n",
    "        kept = [g for g in polys if float(g.area) >= MIN_POLY_AREA_M2]\n",
    "        if not kept:\n",
    "            continue\n",
    "        kept_wgs = gpd.GeoSeries(kept, crs=metric_crs).to_crs(epsg=4326).tolist()\n",
    "        out[cid] = kept_wgs\n",
    "    return out\n",
    "\n",
    "# ------------------ MAP ------------------\n",
    "def build_map(aoi_bbox, hotspots, selected_cluster_polys, result):\n",
    "    lat_c = (aoi_bbox[1] + aoi_bbox[3]) / 2.0\n",
    "    lon_c = (aoi_bbox[0] + aoi_bbox[2]) / 2.0\n",
    "    m = folium.Map(location=[lat_c, lon_c], zoom_start=12,\n",
    "                   tiles=\"cartodbpositron\", control_scale=True)\n",
    "\n",
    "    # Cluster polygons (Top-3)\n",
    "    for rank, (cid, poly) in enumerate(selected_cluster_polys, start=1):\n",
    "        area_marking = folium.GeoJson(\n",
    "            data=poly.__geo_interface__,\n",
    "            name=f\"Top cluster #{rank} (cluster {cid})\",\n",
    "            style_function=lambda _ : {\"color\": COLORS[\"envelope\"], \"weight\": 3, \"fillColor\": COLORS[\"envelope\"], \"fillOpacity\": 0.10},\n",
    "            tooltip=f\"Top cluster #{rank} (cluster {cid})\",\n",
    "            popup=f\"Test popup for cluster {cid}\"\n",
    "        )\n",
    "\n",
    "        tags_html = f\"\"\"\n",
    "            <div style=\"margin-bottom: 0.5em;\">\n",
    "            <span style=\"background:#007bff;color:white;padding:3px 7px;border-radius:5px;margin-right:5px;\">\n",
    "                Cluster ID: {cid}\n",
    "            </span>\n",
    "            <span style=\"background:#28a745;color:white;padding:3px 7px;border-radius:5px;\">\n",
    "                Rank: {rank}\n",
    "            </span>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "        description = result[cid]\n",
    "        description = markdown.markdown(description, extensions=['extra', 'toc', 'tables'])\n",
    "        description = tags_html + description\n",
    "\n",
    "        folium.Popup(f\"{description}\", max_width=700, max_height = 500).add_to(area_marking)\n",
    "\n",
    "        area_marking.add_to(m)\n",
    "\n",
    "    # Hotspots belonging to selected clusters only\n",
    "    kept_cids = {cid for cid, _ in selected_cluster_polys}\n",
    "    for hp in hotspots:\n",
    "        cid = hp.get(\"_cid\")\n",
    "        if cid not in kept_cids:\n",
    "            continue\n",
    "        sev = 'severe' if hp[\"aq_index_z\"] >= SEVERE_Z else ('high' if hp[\"aq_index_z\"] >= HIGH_Z else ('elev' if hp[\"aq_index_z\"] >= ELEV_Z else None))\n",
    "        if sev is None: \n",
    "            continue\n",
    "        color = COLORS[sev]\n",
    "        radius = 6 if sev == \"elev\" else (8 if sev == \"high\" else 10)\n",
    "        z_dry = hp.get(\"aq_z_dry\"); z_mon = hp.get(\"aq_z_monsoon\")\n",
    "        season_txt = seasonality_plain(z_dry, z_mon)\n",
    "        hint = hp.get(\"driver_hint\",\"Mixed drivers\")\n",
    "        popup_html = (\n",
    "            f\"<b>{sev.upper()} hotspot</b><br>\"\n",
    "            f\"Current level: {z_to_level_text(hp['aq_index_z'])} (z≈{hp['aq_index_z']:.2f}; 0≈typical)<br>\"\n",
    "            f\"NO₂ z: {hp['no2_z']:.2f} | PM₂.₅ z: {hp['pm25_z']:.2f} | CO z: {hp['co_z']:.2f}<br>\"\n",
    "            f\"<b>Likely driver:</b> {hint}<br>\"\n",
    "            f\"<b>Seasonality:</b> {season_txt}\"\n",
    "        )\n",
    "        folium.CircleMarker(\n",
    "            location=(hp[\"lat\"], hp[\"lon\"]),\n",
    "            radius=radius,\n",
    "            color=color, fill=True, fill_color=color, fill_opacity=0.95,\n",
    "            tooltip=f\"{sev.upper()} hotspot\", popup=popup_html\n",
    "        ).add_to(m)\n",
    "\n",
    "    MiniMap(toggle_display=True, position=\"bottomright\").add_to(m)\n",
    "    Fullscreen().add_to(m)\n",
    "    MousePosition(position=\"topright\", separator=\" | \", prefix=\"Lat/Lon:\").add_to(m)\n",
    "    MeasureControl(position=\"topright\", primary_length_unit='kilometers').add_to(m)\n",
    "\n",
    "    legend = \"\"\"\n",
    "    <div style=\"position: fixed; bottom: 18px; left: 18px; z-index:9999; background: white;\n",
    "                padding: 10px 12px; border: 1px solid #ccc; border-radius: 6px; font-size: 13px;\">\n",
    "      <b>Top hotspot clusters (area-wise)</b><br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#d32f2f;border:1px solid #d32f2f;\"></span>\n",
    "      Severe (≥ 2σ above city typical)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#fb8c00;border:1px solid #fb8c00;\"></span>\n",
    "      High (1–2σ)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#ffd54f;border:1px solid #ffd54f;\"></span>\n",
    "      Elevated (0.5–1σ)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:#673ab7;border:1px solid #673ab7;\"></span>\n",
    "      Cluster polygon(s)\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend))\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "def main():\n",
    "    print(\"Initializing Earth Engine…\")\n",
    "    ee_init_headless()\n",
    "\n",
    "    aoi = ee.Geometry.Rectangle(AOI_BBOX)\n",
    "    start_iso, end_iso = str(START), str(END)\n",
    "    print(f\"AOI: {AOI_BBOX} | Window: {start_iso} → {end_iso}\")\n",
    "\n",
    "    # Current-window images & z stacks\n",
    "    no2_img, pm25_img, co_img = build_mean_images(aoi, start_iso, end_iso)\n",
    "    stack = no2_img.addBands(pm25_img).addBands(co_img)\n",
    "    no2z_now, pmz_now, coz_now, aqz_now_img = combined_z_image(aoi, start_iso, end_iso)\n",
    "\n",
    "    # Sample grid (capped)\n",
    "    rows = sample_grid(aoi, stack, scale_m=SCALE_M, max_points=MAX_POINTS)\n",
    "    if not rows:\n",
    "        raise SystemExit(\"No samples. Try expanding AOI or increasing DAYS_BACK.\")\n",
    "\n",
    "    # Z-scores (current window)\n",
    "    no2_z = zscores([r[\"no2\"] for r in rows])\n",
    "    pm25_z = zscores([r[\"pm25\"] for r in rows])\n",
    "    co_z   = zscores([r[\"co\"] for r in rows])\n",
    "    aq_raw = [W_NO2*n + W_PM25*p + W_CO*c for n, p, c in zip(no2_z, pm25_z, co_z)]\n",
    "    aq_index_z = zscores(aq_raw)\n",
    "\n",
    "    # Hotspot selection (cap)\n",
    "    def prc(vs, v): return p_rank(vs, v)\n",
    "    pcts = [prc(aq_index_z, v) for v in aq_index_z]\n",
    "    candidates = []\n",
    "    for r, nz, pz, cz, az, pr in zip(rows, no2_z, pm25_z, co_z, aq_index_z, pcts):\n",
    "        if (az >= Z_THRESHOLD) or (pr >= PCTL_THRESHOLD):\n",
    "            if (nz >= 1.0) and (cz >= 1.0):\n",
    "                driver = \"Traffic / combustion (high NO₂ + CO)\"\n",
    "            elif (pz >= 1.0) and (nz < 0.5):\n",
    "                driver = \"Dust / construction / open burning (high PM proxy, low NO₂)\"\n",
    "            elif (nz >= 1.0) and (cz < 0.5):\n",
    "                driver = \"Point sources / industry (high NO₂, low CO)\"\n",
    "            else:\n",
    "                driver = \"Mixed drivers\"\n",
    "            candidates.append({\n",
    "                \"lat\": r[\"lat\"], \"lon\": r[\"lon\"],\n",
    "                \"no2_z\": nz, \"pm25_z\": pz, \"co_z\": cz,\n",
    "                \"aq_index_z\": az, \"percentile\": pr,\n",
    "                \"driver_hint\": driver\n",
    "            })\n",
    "    if not candidates:\n",
    "        raise SystemExit(\"No hotspots met the threshold; relax Z_THRESHOLD/PCTL_THRESHOLD.\")\n",
    "\n",
    "    candidates.sort(key=lambda x: x[\"aq_index_z\"], reverse=True)\n",
    "    hotspots = candidates[:MAX_HOTSPOTS]\n",
    "\n",
    "    # Cluster (with fallback)\n",
    "    clusters = ensure_clusters(hotspots)\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        hp[\"_cid\"] = cid\n",
    "\n",
    "    # Seasonality quick-look (batched)\n",
    "    dry_start, dry_end, mon_start, mon_end = season_windows(date.today())\n",
    "    _, _, _, aqz_dry_img = combined_z_image(aoi, str(dry_start), str(dry_end))\n",
    "    _, _, _, aqz_mon_img = combined_z_image(aoi, str(mon_start), str(mon_end))\n",
    "\n",
    "    def fc_from_points(hps):\n",
    "        feats = [ee.Feature(ee.Geometry.Point([hp[\"lon\"], hp[\"lat\"]]), {\"idx\": i})\n",
    "                 for i, hp in enumerate(hps)]\n",
    "        return ee.FeatureCollection(feats)\n",
    "\n",
    "    pts_fc = fc_from_points(hotspots)\n",
    "    aq_dry_coll = aqz_dry_img.sampleRegions(collection=pts_fc, scale=SCALE_M, geometries=False, tileScale=EE_TILE_SCALE)\n",
    "    aq_mon_coll = aqz_mon_img.sampleRegions(collection=pts_fc, scale=SCALE_M, geometries=False, tileScale=EE_TILE_SCALE)\n",
    "    aq_dry = aq_dry_coll.getInfo().get(\"features\", [])\n",
    "    aq_mon = aq_mon_coll.getInfo().get(\"features\", [])\n",
    "    for feat in aq_dry:\n",
    "        i = int(feat[\"properties\"][\"idx\"])\n",
    "        val = feat[\"properties\"].get(\"aq_index_z\")\n",
    "        hotspots[i][\"aq_z_dry\"] = float(val) if val is not None else None\n",
    "    for feat in aq_mon:\n",
    "        i = int(feat[\"properties\"][\"idx\"])\n",
    "        val = feat[\"properties\"].get(\"aq_index_z\")\n",
    "        hotspots[i][\"aq_z_monsoon\"] = float(val) if val is not None else None\n",
    "\n",
    "    # OSM context\n",
    "    aoi_poly = aoi_polygon_wgs84()\n",
    "    try:\n",
    "        sens_all = osm_geoms_from_polygon(aoi_poly, {\"amenity\": [\"school\",\"clinic\",\"hospital\",\"doctors\"],\n",
    "                                                     \"social_facility\": [\"nursing_home\",\"assisted_living\"]})\n",
    "    except Exception:\n",
    "        sens_all = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try:\n",
    "        ind_all  = osm_geoms_from_polygon(aoi_poly, {\n",
    "            \"landuse\": [\"industrial\"], \"industrial\": True, \"man_made\": [\"works\",\"chimney\"],\n",
    "            \"power\": [\"plant\",\"generator\"], \"harbour\": [\"yes\"], \"waterway\": [\"dock\"]\n",
    "        })\n",
    "        extra_port = osm_geoms_from_polygon(aoi_poly, {\"man_made\": [\"pier\"], \"landuse\": [\"port\"],\n",
    "                                                       \"harbour\": [\"yes\"], \"waterway\": [\"dock\"]})\n",
    "        if ind_all is not None and not ind_all.empty and extra_port is not None and not extra_port.empty:\n",
    "            ind_all = gpd.GeoDataFrame(gpd.pd.concat([ind_all, extra_port], ignore_index=True), crs=ind_all.crs or \"EPSG:4326\")\n",
    "        elif (ind_all is None or ind_all.empty) and extra_port is not None and not extra_port.empty:\n",
    "            ind_all = extra_port\n",
    "    except Exception:\n",
    "        ind_all = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "\n",
    "    # Build concave envelopes per cluster (filter tiny/degenerate)\n",
    "    metric_crs = utm_crs_from_bbox(AOI_BBOX)\n",
    "    envelopes_by_cid = build_concave_envelopes(hotspots, clusters, metric_crs, alpha_m=ALPHA_M, min_pts=MIN_ENVELOPE_POINTS)\n",
    "    if not envelopes_by_cid:\n",
    "        envelopes_by_cid = build_concave_envelopes(hotspots, [0]*len(hotspots), metric_crs, alpha_m=ALPHA_M, min_pts=3)\n",
    "\n",
    "    # Union to single polygon per cluster & compute area\n",
    "    cluster_union = {}\n",
    "    cluster_area_km2 = {}\n",
    "    for cid, polys in envelopes_by_cid.items():\n",
    "        if not polys: \n",
    "            continue\n",
    "        polys_proj = gpd.GeoSeries(polys, crs=\"EPSG:4326\").to_crs(metric_crs)\n",
    "        union_geom = unary_union(list(polys_proj.values))\n",
    "        area_km2 = float(union_geom.area / 1e6)\n",
    "        if area_km2 <= 0:\n",
    "            continue\n",
    "        union_wgs = gpd.GeoSeries([union_geom], crs=metric_crs).to_crs(epsg=4326).iloc[0]\n",
    "        cluster_union[cid] = union_wgs\n",
    "        cluster_area_km2[cid] = area_km2\n",
    "\n",
    "    # Pick Top-3 clusters by area\n",
    "    top_cids = sorted(cluster_area_km2.keys(), key=lambda c: cluster_area_km2[c], reverse=True)[:3]\n",
    "    selected = [(cid, cluster_union[cid]) for cid in top_cids]\n",
    "\n",
    "    # ---------- Print summaries for Top-3 (plain language) ----------\n",
    "    description_string = \"\"\n",
    "\n",
    "    description_string += (\"\\n================= Top bad air quality hotspot clusters (area-wise) =================\\n\")\n",
    "    description_string += (\"(Note: z (σ) = standardized units; 0 means ‘typical’ for the city in the last 60 days.)\\n\")\n",
    "    pop_img = population_image(aoi)\n",
    "    z_imgs_now = {\"no2_z\": no2z_now, \"pm25_z\": pmz_now, \"co_z\": coz_now, \"aq_index_z\": aqz_now_img}\n",
    "\n",
    "    for rank, (cid, poly) in enumerate(selected, start=1):\n",
    "        area_km2 = cluster_area_km2[cid]\n",
    "        pop_sum = reduce_region_sum(pop_img, ee.Geometry(poly.__geo_interface__), scale=200) if pop_img is not None else None\n",
    "        means_now = ee_means_in_poly(z_imgs_now, poly)\n",
    "        zn = means_now.get(\"aq_index_z\")\n",
    "        zd = ee_means_in_poly({\"aq_index_z\": aqz_dry_img}, poly).get(\"aq_index_z\")\n",
    "        zm = ee_means_in_poly({\"aq_index_z\": aqz_mon_img}, poly).get(\"aq_index_z\")\n",
    "        sens_inside = count_sensitive_inside(sens_all, poly)\n",
    "        ind_names, ind_count = list_osm_names_in_poly(ind_all, poly, max_show=60)\n",
    "\n",
    "        description_string += (f\"\\nTop cluster #{rank} (cluster {cid})\\n\")\n",
    "        description_string += (f\"• Area: ~{area_km2:.2f} km²\\n\")\n",
    "        description_string += (f\"• People living inside: {(f'{int(pop_sum):,}' if pop_sum is not None else 'n/a')}\\n\")\n",
    "        if zn is not None:\n",
    "            description_string += (f\"• Current level: {z_to_level_text(zn)} (z≈{zn:.2f}; 0≈typical)\\n\")\n",
    "        else:\n",
    "            description_string += (\"• Current level: n/a\\n\")\n",
    "        description_string += (f\"• Seasonality: {seasonality_plain(zd, zm)}\\n\")\n",
    "        description_string += (f\"• Sensitive sites inside: schools:{sens_inside.get('schools',0)}, \"\n",
    "              f\"clinics:{sens_inside.get('clinics',0)}, hospitals:{sens_inside.get('hospitals',0)}, \"\n",
    "              f\"elder homes:{sens_inside.get('elder_homes',0)}\\n\")\n",
    "        description_string += (f\"• Industrial/port/point-source features inside: {ind_count}\\n\")\n",
    "        if ind_count > 0:\n",
    "            description_string += (\"  Names / tags:\\n\")\n",
    "            for nm in ind_names:\n",
    "                description_string += (f\"   - {nm}\\n\")\n",
    "\n",
    "    print(description_string)\n",
    "    result = groq_api.inference(description_string)\n",
    "    result = groq_api.parse_llm_response(result[0])\n",
    "\n",
    "\n",
    "    # ---------- Map with Top-3 only ----------\n",
    "    m = build_map(AOI_BBOX, hotspots, selected, result)\n",
    "    os.makedirs(os.path.dirname(OUT_HTML), exist_ok=True)\n",
    "    m.save(OUT_HTML)\n",
    "    print(f\"\\n✅ Saved: {OUT_HTML}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda5843",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8184cb56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea34074",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c764e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Earth Engine…\n",
      "AOI: [90.32, 23.7, 90.52, 23.86] | Window: 2025-07-31 → 2025-09-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Top bad air quality hotspot clusters (area-wise) =================\n",
      "(Note: z (σ) = standardized units; 0 means ‘typical’ for the city in the last 60 days.)\n",
      "\n",
      "Top cluster #1 (cluster 1)\n",
      "• Area: ~4.50 km²\n",
      "• People living inside: n/a\n",
      "• Current level: High (above typical) (z≈1.27; 0≈typical)\n",
      "• Seasonality: worse in the monsoon than the dry season (monsoon 0.94, dry -0.74 in standardized units; Δ=+1.68)\n",
      "• Sensitive sites inside: schools:61, clinics:7, hospitals:13, elder homes:0\n",
      "• Industrial/port/point-source features inside: 2\n",
      "  Names / tags:\n",
      "   - Luna plastic\n",
      "   - k tex indco ltd\n",
      "\n",
      "Top cluster #2 (cluster 0)\n",
      "• Area: ~2.96 km²\n",
      "• People living inside: n/a\n",
      "• Current level: High (above typical) (z≈1.72; 0≈typical)\n",
      "• Seasonality: worse in the monsoon than the dry season (monsoon 0.86, dry -1.71 in standardized units; Δ=+2.57)\n",
      "• Sensitive sites inside: schools:2, clinics:0, hospitals:0, elder homes:0\n",
      "• Industrial/port/point-source features inside: 2\n",
      "  Names / tags:\n",
      "   - Unnamed facility (industrial landuse)\n",
      "   - আমিনবাজার ঘাট\n",
      "\n",
      "Top cluster #3 (cluster 2)\n",
      "• Area: ~0.57 km²\n",
      "• People living inside: n/a\n",
      "• Current level: High (above typical) (z≈1.30; 0≈typical)\n",
      "• Seasonality: worse in the monsoon than the dry season (monsoon 1.19, dry -0.57 in standardized units; Δ=+1.76)\n",
      "• Sensitive sites inside: schools:4, clinics:4, hospitals:1, elder homes:0\n",
      "• Industrial/port/point-source features inside: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Earth Engine…\")\n",
    "ee_init_headless()\n",
    "\n",
    "aoi = ee.Geometry.Rectangle(AOI_BBOX)\n",
    "start_iso, end_iso = str(START), str(END)\n",
    "print(f\"AOI: {AOI_BBOX} | Window: {start_iso} → {end_iso}\")\n",
    "\n",
    "# Current-window images & z stacks\n",
    "no2_img, pm25_img, co_img = build_mean_images(aoi, start_iso, end_iso)\n",
    "stack = no2_img.addBands(pm25_img).addBands(co_img)\n",
    "no2z_now, pmz_now, coz_now, aqz_now_img = combined_z_image(aoi, start_iso, end_iso)\n",
    "\n",
    "# Sample grid (capped)\n",
    "rows = sample_grid(aoi, stack, scale_m=SCALE_M, max_points=MAX_POINTS)\n",
    "if not rows:\n",
    "    raise SystemExit(\"No samples. Try expanding AOI or increasing DAYS_BACK.\")\n",
    "\n",
    "# Z-scores (current window)\n",
    "no2_z = zscores([r[\"no2\"] for r in rows])\n",
    "pm25_z = zscores([r[\"pm25\"] for r in rows])\n",
    "co_z   = zscores([r[\"co\"] for r in rows])\n",
    "aq_raw = [W_NO2*n + W_PM25*p + W_CO*c for n, p, c in zip(no2_z, pm25_z, co_z)]\n",
    "aq_index_z = zscores(aq_raw)\n",
    "\n",
    "# Hotspot selection (cap)\n",
    "def prc(vs, v): return p_rank(vs, v)\n",
    "pcts = [prc(aq_index_z, v) for v in aq_index_z]\n",
    "candidates = []\n",
    "for r, nz, pz, cz, az, pr in zip(rows, no2_z, pm25_z, co_z, aq_index_z, pcts):\n",
    "    if (az >= Z_THRESHOLD) or (pr >= PCTL_THRESHOLD):\n",
    "        if (nz >= 1.0) and (cz >= 1.0):\n",
    "            driver = \"Traffic / combustion (high NO₂ + CO)\"\n",
    "        elif (pz >= 1.0) and (nz < 0.5):\n",
    "            driver = \"Dust / construction / open burning (high PM proxy, low NO₂)\"\n",
    "        elif (nz >= 1.0) and (cz < 0.5):\n",
    "            driver = \"Point sources / industry (high NO₂, low CO)\"\n",
    "        else:\n",
    "            driver = \"Mixed drivers\"\n",
    "        candidates.append({\n",
    "            \"lat\": r[\"lat\"], \"lon\": r[\"lon\"],\n",
    "            \"no2_z\": nz, \"pm25_z\": pz, \"co_z\": cz,\n",
    "            \"aq_index_z\": az, \"percentile\": pr,\n",
    "            \"driver_hint\": driver\n",
    "        })\n",
    "if not candidates:\n",
    "    raise SystemExit(\"No hotspots met the threshold; relax Z_THRESHOLD/PCTL_THRESHOLD.\")\n",
    "\n",
    "candidates.sort(key=lambda x: x[\"aq_index_z\"], reverse=True)\n",
    "hotspots = candidates[:MAX_HOTSPOTS]\n",
    "\n",
    "# Cluster (with fallback)\n",
    "clusters = ensure_clusters(hotspots)\n",
    "for hp, cid in zip(hotspots, clusters):\n",
    "    hp[\"_cid\"] = cid\n",
    "\n",
    "# Seasonality quick-look (batched)\n",
    "dry_start, dry_end, mon_start, mon_end = season_windows(date.today())\n",
    "_, _, _, aqz_dry_img = combined_z_image(aoi, str(dry_start), str(dry_end))\n",
    "_, _, _, aqz_mon_img = combined_z_image(aoi, str(mon_start), str(mon_end))\n",
    "\n",
    "def fc_from_points(hps):\n",
    "    feats = [ee.Feature(ee.Geometry.Point([hp[\"lon\"], hp[\"lat\"]]), {\"idx\": i})\n",
    "                for i, hp in enumerate(hps)]\n",
    "    return ee.FeatureCollection(feats)\n",
    "\n",
    "pts_fc = fc_from_points(hotspots)\n",
    "aq_dry_coll = aqz_dry_img.sampleRegions(collection=pts_fc, scale=SCALE_M, geometries=False, tileScale=EE_TILE_SCALE)\n",
    "aq_mon_coll = aqz_mon_img.sampleRegions(collection=pts_fc, scale=SCALE_M, geometries=False, tileScale=EE_TILE_SCALE)\n",
    "aq_dry = aq_dry_coll.getInfo().get(\"features\", [])\n",
    "aq_mon = aq_mon_coll.getInfo().get(\"features\", [])\n",
    "for feat in aq_dry:\n",
    "    i = int(feat[\"properties\"][\"idx\"])\n",
    "    val = feat[\"properties\"].get(\"aq_index_z\")\n",
    "    hotspots[i][\"aq_z_dry\"] = float(val) if val is not None else None\n",
    "for feat in aq_mon:\n",
    "    i = int(feat[\"properties\"][\"idx\"])\n",
    "    val = feat[\"properties\"].get(\"aq_index_z\")\n",
    "    hotspots[i][\"aq_z_monsoon\"] = float(val) if val is not None else None\n",
    "\n",
    "# OSM context\n",
    "aoi_poly = aoi_polygon_wgs84()\n",
    "try:\n",
    "    sens_all = osm_geoms_from_polygon(aoi_poly, {\"amenity\": [\"school\",\"clinic\",\"hospital\",\"doctors\"],\n",
    "                                                    \"social_facility\": [\"nursing_home\",\"assisted_living\"]})\n",
    "except Exception:\n",
    "    sens_all = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "try:\n",
    "    ind_all  = osm_geoms_from_polygon(aoi_poly, {\n",
    "        \"landuse\": [\"industrial\"], \"industrial\": True, \"man_made\": [\"works\",\"chimney\"],\n",
    "        \"power\": [\"plant\",\"generator\"], \"harbour\": [\"yes\"], \"waterway\": [\"dock\"]\n",
    "    })\n",
    "    extra_port = osm_geoms_from_polygon(aoi_poly, {\"man_made\": [\"pier\"], \"landuse\": [\"port\"],\n",
    "                                                    \"harbour\": [\"yes\"], \"waterway\": [\"dock\"]})\n",
    "    if ind_all is not None and not ind_all.empty and extra_port is not None and not extra_port.empty:\n",
    "        ind_all = gpd.GeoDataFrame(gpd.pd.concat([ind_all, extra_port], ignore_index=True), crs=ind_all.crs or \"EPSG:4326\")\n",
    "    elif (ind_all is None or ind_all.empty) and extra_port is not None and not extra_port.empty:\n",
    "        ind_all = extra_port\n",
    "except Exception:\n",
    "    ind_all = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "\n",
    "# Build concave envelopes per cluster (filter tiny/degenerate)\n",
    "metric_crs = utm_crs_from_bbox(AOI_BBOX)\n",
    "envelopes_by_cid = build_concave_envelopes(hotspots, clusters, metric_crs, alpha_m=ALPHA_M, min_pts=MIN_ENVELOPE_POINTS)\n",
    "if not envelopes_by_cid:\n",
    "    envelopes_by_cid = build_concave_envelopes(hotspots, [0]*len(hotspots), metric_crs, alpha_m=ALPHA_M, min_pts=3)\n",
    "\n",
    "# Union to single polygon per cluster & compute area\n",
    "cluster_union = {}\n",
    "cluster_area_km2 = {}\n",
    "for cid, polys in envelopes_by_cid.items():\n",
    "    if not polys: \n",
    "        continue\n",
    "    polys_proj = gpd.GeoSeries(polys, crs=\"EPSG:4326\").to_crs(metric_crs)\n",
    "    union_geom = unary_union(list(polys_proj.values))\n",
    "    area_km2 = float(union_geom.area / 1e6)\n",
    "    if area_km2 <= 0:\n",
    "        continue\n",
    "    union_wgs = gpd.GeoSeries([union_geom], crs=metric_crs).to_crs(epsg=4326).iloc[0]\n",
    "    cluster_union[cid] = union_wgs\n",
    "    cluster_area_km2[cid] = area_km2\n",
    "\n",
    "# Pick Top-3 clusters by area\n",
    "top_cids = sorted(cluster_area_km2.keys(), key=lambda c: cluster_area_km2[c], reverse=True)[:3]\n",
    "selected = [(cid, cluster_union[cid]) for cid in top_cids]\n",
    "\n",
    "# ---------- Print summaries for Top-3 (plain language) ----------\n",
    "description_string = \"\"\n",
    "\n",
    "description_string += (\"\\n================= Top bad air quality hotspot clusters (area-wise) =================\\n\")\n",
    "description_string += (\"(Note: z (σ) = standardized units; 0 means ‘typical’ for the city in the last 60 days.)\\n\")\n",
    "pop_img = population_image(aoi)\n",
    "z_imgs_now = {\"no2_z\": no2z_now, \"pm25_z\": pmz_now, \"co_z\": coz_now, \"aq_index_z\": aqz_now_img}\n",
    "\n",
    "for rank, (cid, poly) in enumerate(selected, start=1):\n",
    "    area_km2 = cluster_area_km2[cid]\n",
    "    pop_sum = reduce_region_sum(pop_img, ee.Geometry(poly.__geo_interface__), scale=200) if pop_img is not None else None\n",
    "    means_now = ee_means_in_poly(z_imgs_now, poly)\n",
    "    zn = means_now.get(\"aq_index_z\")\n",
    "    zd = ee_means_in_poly({\"aq_index_z\": aqz_dry_img}, poly).get(\"aq_index_z\")\n",
    "    zm = ee_means_in_poly({\"aq_index_z\": aqz_mon_img}, poly).get(\"aq_index_z\")\n",
    "    sens_inside = count_sensitive_inside(sens_all, poly)\n",
    "    ind_names, ind_count = list_osm_names_in_poly(ind_all, poly, max_show=60)\n",
    "\n",
    "    description_string += (f\"\\nTop cluster #{rank} (cluster {cid})\\n\")\n",
    "    description_string += (f\"• Area: ~{area_km2:.2f} km²\\n\")\n",
    "    description_string += (f\"• People living inside: {(f'{int(pop_sum):,}' if pop_sum is not None else 'n/a')}\\n\")\n",
    "    if zn is not None:\n",
    "        description_string += (f\"• Current level: {z_to_level_text(zn)} (z≈{zn:.2f}; 0≈typical)\\n\")\n",
    "    else:\n",
    "        description_string += (\"• Current level: n/a\\n\")\n",
    "    description_string += (f\"• Seasonality: {seasonality_plain(zd, zm)}\\n\")\n",
    "    description_string += (f\"• Sensitive sites inside: schools:{sens_inside.get('schools',0)}, \"\n",
    "            f\"clinics:{sens_inside.get('clinics',0)}, hospitals:{sens_inside.get('hospitals',0)}, \"\n",
    "            f\"elder homes:{sens_inside.get('elder_homes',0)}\\n\")\n",
    "    description_string += (f\"• Industrial/port/point-source features inside: {ind_count}\\n\")\n",
    "    if ind_count > 0:\n",
    "        description_string += (\"  Names / tags:\\n\")\n",
    "        for nm in ind_names:\n",
    "            description_string += (f\"   - {nm}\\n\")\n",
    "\n",
    "print(description_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41202534",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = groq_api.inference(description_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88531af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Top bad air quality hotspot clusters (area-wise) =================\n",
      "(Note: z (σ) = standardized units; 0 means ‘typical’ for the city in the last 60 days.)\n",
      "\n",
      "Top cluster #1 (cluster 1)\n",
      "• Area: ~4.50 km²\n",
      "• People living inside: n/a\n",
      "• Current level: High (above typical) (z≈1.27; 0≈typical)\n",
      "• Seasonality: worse in the monsoon than the dry season (monsoon 0.94, dry -0.74 in standardized units; Δ=+1.68)\n",
      "• Sensitive sites inside: schools:61, clinics:7, hospitals:13, elder homes:0\n",
      "• Industrial/port/point-source features inside: 2\n",
      "  Names / tags:\n",
      "   - Luna plastic\n",
      "   - k tex indco ltd\n",
      "\n",
      "Top cluster #2 (cluster 0)\n",
      "• Area: ~2.96 km²\n",
      "• People living inside: n/a\n",
      "• Current level: High (above typical) (z≈1.72; 0≈typical)\n",
      "• Seasonality: worse in the monsoon than the dry season (monsoon 0.86, dry -1.71 in standardized units; Δ=+2.57)\n",
      "• Sensitive sites inside: schools:2, clinics:0, hospitals:0, elder homes:0\n",
      "• Industrial/port/point-source features inside: 2\n",
      "  Names / tags:\n",
      "   - Unnamed facility (industrial landuse)\n",
      "   - আমিনবাজার ঘাট\n",
      "\n",
      "Top cluster #3 (cluster 2)\n",
      "• Area: ~0.57 km²\n",
      "• People living inside: n/a\n",
      "• Current level: High (above typical) (z≈1.30; 0≈typical)\n",
      "• Seasonality: worse in the monsoon than the dry season (monsoon 1.19, dry -0.57 in standardized units; Δ=+1.76)\n",
      "• Sensitive sites inside: schools:4, clinics:4, hospitals:1, elder homes:0\n",
      "• Industrial/port/point-source features inside: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(description_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb8cb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<| Decision for cluster/node 1 |>\\n• **Area:** ~4.50\\u202fkm²  \\n• **People living inside:** Data unavailable  \\n• **Current level:** High (z\\u202f≈\\u202f1.27) – above city average  \\n• **Seasonality:** Worse during monsoon (monsoon\\u202f=\\u202f0.94 vs dry\\u202f=\\u202f‑0.74, Δ\\u202f=\\u202f+1.68)  \\n• **Sensitive sites inside:** 61 schools, 7 clinics, 13 hospitals, 0 elder homes  \\n• **Industrial/port/point‑source features inside:** 2 (Luna plastic, K Tex Indco Ltd)  \\n\\n#### AI interpretations :\\n\\n**1. Suitability Assessment**  \\n- **Strengths**  \\n  - Large area allows for diversified interventions (e.g., green belt, low‑impact development).  \\n  - Presence of many health & education facilities implies existing community hubs that can be leveraged for outreach.  \\n  - Industrial sources are limited to two; potential for targeted source‑control measures.  \\n\\n- **Weaknesses**  \\n  - High pollutant concentrations and monsoon‑driven exacerbation indicate persistent exposure risk.  \\n  - Lack of data on residential density hampers precise risk mapping.  \\n  - Proximity of schools and hospitals makes the cluster highly vulnerable; any development must prioritize safety.  \\n\\n- **Key environmental & social concerns**  \\n  - Chronic respiratory health risks for children and patients.  \\n  - Monsoon runoff may carry pollutants into water bodies, aggravating secondary pollution.  \\n\\n**2. Urban Planning Recommendations**  \\n- **Land‑use**  \\n  - Designate priority zones for **blue‑green corridors** (wetlands, rain gardens) to intercept runoff and filter air.  \\n  - Convert low‑density patches into **micro‑parks** with high‑canopy trees (≥\\u202f30\\u202fm) to reduce localized heat and absorb particulates.  \\n  - Restrict high‑pollution‑intensity development; consider **industrial relocation** or strict emission controls for the two identified facilities.  \\n\\n- **Infrastructure**  \\n  - Construct **stormwater detention basins** (≥\\u202f0.2\\u202fha each) to manage monsoon inflows.  \\n  - Upgrade road drainage to prevent stagnant water that could worsen air quality via vehicle idling.  \\n  - Install **air‑quality monitoring stations** at school and hospital entrances for real‑time data.  \\n\\n- **Heat & Pollution Mitigation**  \\n  - Implement **cool roofs** (white/green roof coverage ≥\\u202f70\\u202f%) on all public buildings.  \\n  - Promote **tree planting** along road medians and near schools (target canopy cover ≥\\u202f50\\u202f%).  \\n  - Deploy **portable air‑purification units** in schools during peak monsoon periods.  \\n\\n- **Social considerations**  \\n  - Conduct health‑impact assessments (HIA) for schools and hospitals.  \\n  - Establish community education programs on pollution‑related health risks.  \\n  - Provide temporary shelters or ventilation upgrades in clinics during high‑pollution episodes.  \\n\\n**3. Decision Guidelines**  \\n- **Recommendation:** **Monitoring & targeted mitigation** (no new high‑pollution industrial development).  \\n- **Priority level:** **High** – immediate interventions required to protect vulnerable populations.  \\n- **Trade‑offs:**  \\n  - **Flood risk** during monsoon vs. need for green infrastructure; balance by designing dual‑function stormwater‑green spaces.  \\n  - **Economic activity** from existing factories vs. public health; enforce stricter emission limits or relocate.  \\n\\n<| End of decision for cluster/node 1 |>\\n\\n<| Decision for cluster/node 0 |>\\n• **Area:** ~2.96\\u202fkm²  \\n• **People living inside:** Data unavailable  \\n• **Current level:** High (z\\u202f≈\\u202f1.72) – well above city average  \\n• **Seasonality:** Worse during monsoon (monsoon\\u202f=\\u202f0.86 vs dry\\u202f=\\u202f‑1.71, Δ\\u202f=\\u202f+2.57)  \\n• **Sensitive sites inside:** 2 schools, 0 clinics, 0 hospitals, 0 elder homes  \\n• **Industrial/port/point‑source features inside:** 2 (Unnamed industrial land‑use, আমিনবাজার ঘাট)  \\n\\n#### AI interpretations :\\n\\n**1. Suitability Assessment**  \\n- **Strengths**  \\n  - Moderate area can support **compact, low‑impact green projects** (e.g., pocket parks).  \\n  - Limited number of sensitive facilities (only 2 schools) simplifies risk prioritization.  \\n\\n- **Weaknesses**  \\n  - Very high pollution z‑score and large seasonal swing indicate acute exposure risk, especially during monsoon.  \\n  - Presence of two unnamed industrial sources suggests potentially unknown or poorly regulated emissions.  \\n  - Absence of data on residential density may mask hidden exposure risks.  \\n\\n- **Key concerns**  \\n  - Children’s health due to school proximity.  \\n  - Potential for **monsoon‑driven pollutant transport** into adjacent neighborhoods.  \\n\\n**2. Urban Planning Recommendations**  \\n- **Land‑use**  \\n  - Convert non‑industrial peripheral zones into **low‑impact parks** with high‑canopy trees to shield schools.  \\n  - Enforce **industrial zoning strictures**: require emission‑control devices or relocation for the unnamed facility.  \\n\\n- **Infrastructure**  \\n  - Build **stormwater infiltration trenches** to reduce pollutant runoff.  \\n  - Upgrade nearby road surfaces to improve drainage and reduce vehicle‑related pollutant buildup.  \\n\\n- **Heat & Pollution Mitigation**  \\n  - Install **green wall** systems on building facades near schools.  \\n  - Apply **cool‑roof technologies** on school rooftops.  \\n  - Deploy **real‑time air‑quality alert systems** linked to school schedules.  \\n\\n- **Social considerations**  \\n  - Conduct community awareness programs on pollution risks for children.  \\n  - Provide **portable air purifiers** at schools during monsoon peaks.  \\n\\n**3. Decision Guidelines**  \\n- **Recommendation:** **Conservation & intensive monitoring** (no new industrial activity; active remediation).  \\n- **Priority level:** **High** – urgent action to mitigate monsoon‑driven health risks.  \\n- **Trade‑offs:**  \\n  - **Industrial activity** vs. **public health** – enforce stricter controls or relocation of the unnamed facility.  \\n  - **Land‑use flexibility** limited by existing industrial footprints; focus on green buffers around schools.  \\n\\n<| End of decision for cluster/node 0 |>\\n\\n<| Decision for cluster/node 2 |>\\n• **Area:** ~0.57\\u202fkm²  \\n• **People living inside:** Data unavailable  \\n• **Current level:** High (z\\u202f≈\\u202f1.30) – above city average  \\n• **Seasonality:** Worse during monsoon (monsoon\\u202f=\\u202f1.19 vs dry\\u202f=\\u202f‑0.57, Δ\\u202f=\\u202f+1.76)  \\n• **Sensitive sites inside:** 4 schools, 4 clinics, 1 hospital, 0 elder homes  \\n• **Industrial/port/point‑source features inside:** 0  \\n\\n#### AI interpretations :\\n\\n**1. Suitability Assessment**  \\n- **Strengths**  \\n  - Small area allows for **intensive, high‑impact interventions** (e.g., micro‑green corridors).  \\n  - No direct industrial sources; pollution likely due to traffic or regional background.  \\n  - Presence of multiple health facilities provides existing infrastructure for outreach and monitoring.  \\n\\n- **Weaknesses**  \\n  - High pollutant concentration with a significant monsoon increase indicates vulnerability.  \\n  - Lack of residential density data; possible under‑reported exposure.  \\n\\n- **Key concerns**  \\n  - Elevated risk for children and patients in schools and clinics during monsoon.  \\n  - Potential for stagnant water during monsoon to exacerbate pollutant dispersion.  \\n\\n**2. Urban Planning Recommendations**  \\n- **Land‑use**  \\n  - Create **compact green spaces** (e.g., pocket parks, vertical gardens) adjacent to schools and clinics.  \\n  - Encourage **mixed‑use developments** that combine low‑impact housing with green buffers.  \\n\\n- **Infrastructure**  \\n  - Install **high‑efficiency stormwater infiltration systems** (e.g., permeable pavements, bioswales).  \\n  - Upgrade traffic management to reduce idling and vehicular emissions near sensitive sites.  \\n\\n- **Heat & Pollution Mitigation**  \\n  - Deploy **cool roofs** and **high‑reflective pavement** on all public buildings.  \\n  - Plant **dense canopy trees** along roadways to intercept particulate matter.  \\n  - Provide **air‑purifier units** in clinics and schools during high‑pollution periods.  \\n\\n- **Social considerations**  \\n  - Conduct **health impact assessments** for children and patients.  \\n  - Set up a **community health watch** to monitor and report pollution spikes.  \\n\\n**3. Decision Guidelines**  \\n- **Recommendation:** **Targeted remediation & green infrastructure development** (no new high‑pollution projects).  \\n- **Priority level:** **High** – urgent interventions needed to protect sensitive facilities.  \\n- **Trade‑offs:**  \\n  - **Space constraints** vs. **green‑buffer effectiveness** – maximize vertical greening and compact layouts.  \\n  - **Traffic flow** vs. **emission reduction** – consider implementing low‑speed zones near schools/clinics.  \\n\\n<| End of decision for cluster/node 2 |>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486b88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parse_llm_response(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca4492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '• **Area:** ~4.50\\u202fkm²  \\n• **People living inside:** Data unavailable  \\n• **Current level:** High (z\\u202f≈\\u202f1.27) – above city average  \\n• **Seasonality:** Worse during monsoon (monsoon\\u202f=\\u202f0.94 vs dry\\u202f=\\u202f‑0.74, Δ\\u202f=\\u202f+1.68)  \\n• **Sensitive sites inside:** 61 schools, 7 clinics, 13 hospitals, 0 elder homes  \\n• **Industrial/port/point‑source features inside:** 2 (Luna plastic, K Tex Indco Ltd)  \\n\\n#### AI interpretations :\\n\\n**1. Suitability Assessment**  \\n- **Strengths**  \\n  - Large area allows for diversified interventions (e.g., green belt, low‑impact development).  \\n  - Presence of many health & education facilities implies existing community hubs that can be leveraged for outreach.  \\n  - Industrial sources are limited to two; potential for targeted source‑control measures.  \\n\\n- **Weaknesses**  \\n  - High pollutant concentrations and monsoon‑driven exacerbation indicate persistent exposure risk.  \\n  - Lack of data on residential density hampers precise risk mapping.  \\n  - Proximity of schools and hospitals makes the cluster highly vulnerable; any development must prioritize safety.  \\n\\n- **Key environmental & social concerns**  \\n  - Chronic respiratory health risks for children and patients.  \\n  - Monsoon runoff may carry pollutants into water bodies, aggravating secondary pollution.  \\n\\n**2. Urban Planning Recommendations**  \\n- **Land‑use**  \\n  - Designate priority zones for **blue‑green corridors** (wetlands, rain gardens) to intercept runoff and filter air.  \\n  - Convert low‑density patches into **micro‑parks** with high‑canopy trees (≥\\u202f30\\u202fm) to reduce localized heat and absorb particulates.  \\n  - Restrict high‑pollution‑intensity development; consider **industrial relocation** or strict emission controls for the two identified facilities.  \\n\\n- **Infrastructure**  \\n  - Construct **stormwater detention basins** (≥\\u202f0.2\\u202fha each) to manage monsoon inflows.  \\n  - Upgrade road drainage to prevent stagnant water that could worsen air quality via vehicle idling.  \\n  - Install **air‑quality monitoring stations** at school and hospital entrances for real‑time data.  \\n\\n- **Heat & Pollution Mitigation**  \\n  - Implement **cool roofs** (white/green roof coverage ≥\\u202f70\\u202f%) on all public buildings.  \\n  - Promote **tree planting** along road medians and near schools (target canopy cover ≥\\u202f50\\u202f%).  \\n  - Deploy **portable air‑purification units** in schools during peak monsoon periods.  \\n\\n- **Social considerations**  \\n  - Conduct health‑impact assessments (HIA) for schools and hospitals.  \\n  - Establish community education programs on pollution‑related health risks.  \\n  - Provide temporary shelters or ventilation upgrades in clinics during high‑pollution episodes.  \\n\\n**3. Decision Guidelines**  \\n- **Recommendation:** **Monitoring & targeted mitigation** (no new high‑pollution industrial development).  \\n- **Priority level:** **High** – immediate interventions required to protect vulnerable populations.  \\n- **Trade‑offs:**  \\n  - **Flood risk** during monsoon vs. need for green infrastructure; balance by designing dual‑function stormwater‑green spaces.  \\n  - **Economic activity** from existing factories vs. public health; enforce stricter emission limits or relocate.',\n",
       " 0: '• **Area:** ~2.96\\u202fkm²  \\n• **People living inside:** Data unavailable  \\n• **Current level:** High (z\\u202f≈\\u202f1.72) – well above city average  \\n• **Seasonality:** Worse during monsoon (monsoon\\u202f=\\u202f0.86 vs dry\\u202f=\\u202f‑1.71, Δ\\u202f=\\u202f+2.57)  \\n• **Sensitive sites inside:** 2 schools, 0 clinics, 0 hospitals, 0 elder homes  \\n• **Industrial/port/point‑source features inside:** 2 (Unnamed industrial land‑use, আমিনবাজার ঘাট)  \\n\\n#### AI interpretations :\\n\\n**1. Suitability Assessment**  \\n- **Strengths**  \\n  - Moderate area can support **compact, low‑impact green projects** (e.g., pocket parks).  \\n  - Limited number of sensitive facilities (only 2 schools) simplifies risk prioritization.  \\n\\n- **Weaknesses**  \\n  - Very high pollution z‑score and large seasonal swing indicate acute exposure risk, especially during monsoon.  \\n  - Presence of two unnamed industrial sources suggests potentially unknown or poorly regulated emissions.  \\n  - Absence of data on residential density may mask hidden exposure risks.  \\n\\n- **Key concerns**  \\n  - Children’s health due to school proximity.  \\n  - Potential for **monsoon‑driven pollutant transport** into adjacent neighborhoods.  \\n\\n**2. Urban Planning Recommendations**  \\n- **Land‑use**  \\n  - Convert non‑industrial peripheral zones into **low‑impact parks** with high‑canopy trees to shield schools.  \\n  - Enforce **industrial zoning strictures**: require emission‑control devices or relocation for the unnamed facility.  \\n\\n- **Infrastructure**  \\n  - Build **stormwater infiltration trenches** to reduce pollutant runoff.  \\n  - Upgrade nearby road surfaces to improve drainage and reduce vehicle‑related pollutant buildup.  \\n\\n- **Heat & Pollution Mitigation**  \\n  - Install **green wall** systems on building facades near schools.  \\n  - Apply **cool‑roof technologies** on school rooftops.  \\n  - Deploy **real‑time air‑quality alert systems** linked to school schedules.  \\n\\n- **Social considerations**  \\n  - Conduct community awareness programs on pollution risks for children.  \\n  - Provide **portable air purifiers** at schools during monsoon peaks.  \\n\\n**3. Decision Guidelines**  \\n- **Recommendation:** **Conservation & intensive monitoring** (no new industrial activity; active remediation).  \\n- **Priority level:** **High** – urgent action to mitigate monsoon‑driven health risks.  \\n- **Trade‑offs:**  \\n  - **Industrial activity** vs. **public health** – enforce stricter controls or relocation of the unnamed facility.  \\n  - **Land‑use flexibility** limited by existing industrial footprints; focus on green buffers around schools.',\n",
       " 2: '• **Area:** ~0.57\\u202fkm²  \\n• **People living inside:** Data unavailable  \\n• **Current level:** High (z\\u202f≈\\u202f1.30) – above city average  \\n• **Seasonality:** Worse during monsoon (monsoon\\u202f=\\u202f1.19 vs dry\\u202f=\\u202f‑0.57, Δ\\u202f=\\u202f+1.76)  \\n• **Sensitive sites inside:** 4 schools, 4 clinics, 1 hospital, 0 elder homes  \\n• **Industrial/port/point‑source features inside:** 0  \\n\\n#### AI interpretations :\\n\\n**1. Suitability Assessment**  \\n- **Strengths**  \\n  - Small area allows for **intensive, high‑impact interventions** (e.g., micro‑green corridors).  \\n  - No direct industrial sources; pollution likely due to traffic or regional background.  \\n  - Presence of multiple health facilities provides existing infrastructure for outreach and monitoring.  \\n\\n- **Weaknesses**  \\n  - High pollutant concentration with a significant monsoon increase indicates vulnerability.  \\n  - Lack of residential density data; possible under‑reported exposure.  \\n\\n- **Key concerns**  \\n  - Elevated risk for children and patients in schools and clinics during monsoon.  \\n  - Potential for stagnant water during monsoon to exacerbate pollutant dispersion.  \\n\\n**2. Urban Planning Recommendations**  \\n- **Land‑use**  \\n  - Create **compact green spaces** (e.g., pocket parks, vertical gardens) adjacent to schools and clinics.  \\n  - Encourage **mixed‑use developments** that combine low‑impact housing with green buffers.  \\n\\n- **Infrastructure**  \\n  - Install **high‑efficiency stormwater infiltration systems** (e.g., permeable pavements, bioswales).  \\n  - Upgrade traffic management to reduce idling and vehicular emissions near sensitive sites.  \\n\\n- **Heat & Pollution Mitigation**  \\n  - Deploy **cool roofs** and **high‑reflective pavement** on all public buildings.  \\n  - Plant **dense canopy trees** along roadways to intercept particulate matter.  \\n  - Provide **air‑purifier units** in clinics and schools during high‑pollution periods.  \\n\\n- **Social considerations**  \\n  - Conduct **health impact assessments** for children and patients.  \\n  - Set up a **community health watch** to monitor and report pollution spikes.  \\n\\n**3. Decision Guidelines**  \\n- **Recommendation:** **Targeted remediation & green infrastructure development** (no new high‑pollution projects).  \\n- **Priority level:** **High** – urgent interventions needed to protect sensitive facilities.  \\n- **Trade‑offs:**  \\n  - **Space constraints** vs. **green‑buffer effectiveness** – maximize vertical greening and compact layouts.  \\n  - **Traffic flow** vs. **emission reduction** – consider implementing low‑speed zones near schools/clinics.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce38a794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved: /Users/Dipankar Mitra/Downloads/narayanganj_aq_hotspots_readable.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------- Map with Top-3 only ----------\n",
    "m = build_map(AOI_BBOX, hotspots, selected, result)\n",
    "os.makedirs(os.path.dirname(OUT_HTML), exist_ok=True)\n",
    "m.save(OUT_HTML)\n",
    "print(f\"\\n✅ Saved: {OUT_HTML}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df67d7-022c-48c8-b64a-90a7af5805c7",
   "metadata": {},
   "source": [
    "## Satellite data this script uses (and what for)\n",
    "\n",
    "* **Sentinel-5P / TROPOMI – NO₂ (L3)**\n",
    "  **ID:** `COPERNICUS/S5P/OFFL/L3_NO2` → **Mean tropospheric NO₂ column** over the last `DAYS_BACK` days.\n",
    "  **Used for:** NO₂ **z-score** and the **combined AQ hotspot index**; also **seasonality** (dry vs monsoon).\n",
    "\n",
    "* **Sentinel-5P / TROPOMI – CO (L3)**\n",
    "  **ID:** `COPERNICUS/S5P/OFFL/L3_CO` → **Mean CO column** over the last `DAYS_BACK` days.\n",
    "  **Used for:** CO **z-score** and the **combined AQ hotspot index**; also **seasonality**.\n",
    "\n",
    "* **MODIS MAIAC – Aerosol Optical Depth (AOD, 0.47 µm)**\n",
    "  **ID:** `MODIS/061/MCD19A2_GRANULES` (band `Optical_Depth_047`) → **Mean AOD** (~1 km).\n",
    "  **Used for:** Rough **PM₂.₅ proxy** (`PM₂.₅ ≈ AOD × 60`), its **z-score**, and contribution to the **combined AQ index**; also **seasonality**.\n",
    "\n",
    "* **Population exposure (gridded, satellite-derived products)**\n",
    "  **Preferred:** `WorldPop/GP/100m/pop` (year closest to present).\n",
    "  **Fallbacks:** `JRC/GHSL/P2019/POP_GLOBE_R2019A`, `CIESIN/GPWv411/GPW_Population_Count`.\n",
    "  **Used for:** **Sum of residents** inside each hotspot polygon (exposure). *(These are modelled/gridded layers informed by multiple sources, not a single sensor.)*\n",
    "\n",
    "> Non-satellite layers: **OpenStreetMap** for sensitive sites and industrial/port features (counts & names); clustering/envelopes are geometric operations on hotspot points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308777d-eea5-4606-b818-77570ac7c62c",
   "metadata": {},
   "source": [
    "# heat Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048dd655-1a6e-4917-b140-710ce1880cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Earth Engine…\n",
      "AOI: [90.32, 23.7, 90.52, 23.86] | Window: 2025-07-30 → 2025-09-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:285: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  overpass_settings = _make_overpass_settings()\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:395: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  yield _overpass_request(data={\"data\": query_str})\n",
      "f:\\nasa sace app\\venv\\Lib\\site-packages\\osmnx\\_overpass.py:451: FutureWarning: `settings.timeout` is deprecated and will be removed in the v2.0.0 release: use `settings.requests_timeout` instead. See the OSMnx v2 migration guide: https://github.com/gboeing/osmnx/issues/1123\n",
      "  this_pause = _get_overpass_pause(overpass_endpoint)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Top UHI clusters (area-wise) =================\n",
      "(z (σ): standardized vs city typical; 0 ≈ typical)\n",
      "\n",
      "Hot zone #1 (cluster 1)\n",
      "• Area: ~31.10 km²\n",
      "• People living inside: n/a\n",
      "• Vulnerable groups: children 23.3%, elderly 1.4%\n",
      "• Density / informal proxy: n/a\n",
      "• Surfaces: impervious n/a | tree canopy n/a | mean NDVI n/a\n",
      "• Roof area total: 0 m² | large roofs: 0 bldgs / 0 m² (cool-roof potential)\n",
      "• Building height/density: n/a\n",
      "• Nearest water: ~0 m → blue-corridor greening potential\n",
      "• Day vs Night: day 33.1 °C | night n/a | Δ n/a\n",
      "• Seasonality: pre-monsoon 31.9 °C | monsoon 33.1 °C | post-monsoon n/a\n",
      "• Extreme hot periods (8-day composites above local 90th pct): 1\n",
      "• Heat index: n/a\n",
      "• Sensitive sites: schools:319, clinics:78, hospitals:95, elder homes:1\n",
      "\n",
      "Hot zone #2 (cluster 0)\n",
      "• Area: ~4.83 km²\n",
      "• People living inside: n/a\n",
      "• Vulnerable groups: children 23.1%, elderly 1.6%\n",
      "• Density / informal proxy: n/a\n",
      "• Surfaces: impervious n/a | tree canopy n/a | mean NDVI n/a\n",
      "• Roof area total: 0 m² | large roofs: 0 bldgs / 0 m² (cool-roof potential)\n",
      "• Building height/density: n/a\n",
      "• Nearest water: ~0 m → blue-corridor greening potential\n",
      "• Day vs Night: day 33.6 °C | night n/a | Δ n/a\n",
      "• Seasonality: pre-monsoon 31.0 °C | monsoon 33.6 °C | post-monsoon n/a\n",
      "• Extreme hot periods (8-day composites above local 90th pct): 2\n",
      "• Heat index: n/a\n",
      "• Sensitive sites: schools:1, clinics:0, hospitals:0, elder homes:0\n",
      "\n",
      "✅ Saved UHI map to: /Users/Dipankar Mitra/Downloads/narayanganj_uhi_hotspots.html\n",
      "Open in your browser to explore.\n"
     ]
    }
   ],
   "source": [
    "# narayanganj_uhi_hotspots.py\n",
    "# Urban Heat Island (UHI) hotspots → Top-3 area-wise clusters with concave envelopes.\n",
    "# Per-cluster metrics printed in plain language + Folium map.\n",
    "#\n",
    "# Metrics:\n",
    "# - Population inside\n",
    "# - Sensitive sites (schools, clinics, hospitals, elder homes)\n",
    "# - Vulnerability: children %, elderly % (WorldPop ages if available); \"informal housing\" proxy (roof m²/person)\n",
    "# - Impervious % (ESA WorldCover)\n",
    "# - Tree canopy % (WorldCover) & mean NDVI (Sentinel-2)\n",
    "# - Roof area & cool-roof potential (large roofs)\n",
    "# - Building height/density proxy (OSM)\n",
    "# - Distance to water & \"blue corridor\" hint (OSM water)\n",
    "# - Night LST & Day–Night delta (MODIS)\n",
    "# - Seasonality (pre/monsoon/post; MODIS)\n",
    "# - Extreme hot periods count (8-day MODIS above local 90th percentile)\n",
    "# - Apparent temperature / heat index proxy (ERA5 air temp + RH)\n",
    "#\n",
    "# Speed notes:\n",
    "# - Uses coarse reduceRegion stats (tileScale=4, bestEffort) per polygon\n",
    "# - Keeps sampling grid capped; clustering in pure Python with neighborhood bucketing\n",
    "# - Uses ESA WorldCover & MODIS/ERA5 instead of very high-res rasters for heavy stats\n",
    "\n",
    "import os\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import ee\n",
    "import folium\n",
    "from folium.plugins import MiniMap, Fullscreen, MousePosition, MeasureControl\n",
    "from shapely.geometry import Point, box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Geo / OSM\n",
    "try:\n",
    "    import osmnx as ox\n",
    "    import geopandas as gpd\n",
    "except Exception as e:\n",
    "    raise SystemExit(\n",
    "        f\"Import error: {e}\\nInstall: pip install osmnx geopandas rtree\\n\"\n",
    "        \"If NumPy 2.x issues: pip install 'numpy<2' && reinstall geopandas shapely pyproj fiona rtree\"\n",
    "    )\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "AOI_BBOX = [90.32, 23.70, 90.52, 23.86]  # (W,S,E,N) — Narayanganj\n",
    "DAYS_BACK = 60\n",
    "END = date.today()\n",
    "START = END - timedelta(days=DAYS_BACK)\n",
    "\n",
    "# Sampling / EE\n",
    "SCALE_M = 1000        # for LST sampling grid (MODIS native ~1 km)\n",
    "MAX_POINTS = 5000\n",
    "EE_TILE_SCALE = 4\n",
    "\n",
    "# Hotspot selection\n",
    "Z_THRESHOLD = 1.0\n",
    "PCTL_THRESHOLD = 85.0\n",
    "\n",
    "# Clustering\n",
    "EPS_METERS = 1500.0\n",
    "MIN_SAMPLES = 6\n",
    "\n",
    "# Concave envelope (morphological alpha-shape)\n",
    "ALPHA_M = 1200\n",
    "MIN_ENVELOPE_POINTS = 5\n",
    "MIN_POLY_AREA_M2 = 2000  # drop tiny artifacts\n",
    "\n",
    "# Severity buckets by LST z-score\n",
    "SEVERE_Z = 2.0\n",
    "HIGH_Z   = 1.5\n",
    "ELEV_Z   = 1.0\n",
    "\n",
    "COLORS = {\n",
    "    \"severe\": \"#b71c1c\",  # dark red\n",
    "    \"high\":   \"#e53935\",  # red\n",
    "    \"elev\":   \"#fb8c00\",  # orange\n",
    "    \"envelope\": \"#6a1b9a\",# purple\n",
    "}\n",
    "\n",
    "USER = os.getenv(\"USER\") or os.getenv(\"USERNAME\") or \"user\"\n",
    "OUT_HTML = f\"/Users/{USER}/Downloads/narayanganj_uhi_hotspots.html\"\n",
    "\n",
    "# ------------------ EE INIT ------------------\n",
    "def ee_init_headless():\n",
    "    sa = os.environ[\"EE_SERVICE_ACCOUNT\"]       # ee-runner@<project>.iam.gserviceaccount.com\n",
    "    key_b64 = os.environ[\"EE_KEY_B64\"]          # base64 of the JSON key\n",
    "\n",
    "    # Write key to a temp file\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "        f.write(base64.b64decode(key_b64).decode(\"utf-8\"))\n",
    "        key_path = f.name\n",
    "\n",
    "    creds = ee.ServiceAccountCredentials(sa, key_path)\n",
    "    ee.Initialize(credentials=creds)\n",
    "\n",
    "# ------------------ UTILITIES ------------------\n",
    "def utm_crs_from_bbox(bbox):\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    lon_c = (minx + maxx) / 2.0\n",
    "    lat_c = (miny + maxy) / 2.0\n",
    "    zone = int((lon_c + 180) // 6) + 1\n",
    "    epsg = 32600 + zone if lat_c >= 0 else 32700 + zone\n",
    "    return f\"EPSG:{epsg}\"\n",
    "\n",
    "def aoi_polygon_wgs84():\n",
    "    minx, miny, maxx, maxy = AOI_BBOX\n",
    "    return box(minx, miny, maxx, maxy)\n",
    "\n",
    "def zscores(vals):\n",
    "    good = [v for v in vals if v is not None and math.isfinite(v)]\n",
    "    if len(good) < 2: return [0.0 for _ in vals]\n",
    "    mean = sum(good)/len(good)\n",
    "    var  = sum((v-mean)**2 for v in good)/len(good)\n",
    "    std  = math.sqrt(max(var, 1e-12))\n",
    "    return [0.0 if (v is None or not math.isfinite(v)) else (v-mean)/std for v in vals]\n",
    "\n",
    "def p_rank(all_vals, v):\n",
    "    s = sorted(all_vals)\n",
    "    if not s: return 0.0\n",
    "    cnt = sum(1 for x in s if x <= v)\n",
    "    return 100.0 * cnt / len(s)\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = p2 - p1\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "def cluster_dbscan(points, eps_m=EPS_METERS, min_samples=MIN_SAMPLES):\n",
    "    n = len(points)\n",
    "    if n == 0: return []\n",
    "    # light spatial bucketing (~1.1km) to prune distance calcs\n",
    "    buckets = {}\n",
    "    for i, p in enumerate(points):\n",
    "        key = (int(p[\"lat\"]/0.01), int(p[\"lon\"]/0.01))\n",
    "        buckets.setdefault(key, []).append(i)\n",
    "    visited = [False]*n\n",
    "    clusters = [-1]*n\n",
    "    nbrs = [[] for _ in range(n)]\n",
    "    for key, idxs in buckets.items():\n",
    "        kx, ky = key\n",
    "        cand = []\n",
    "        for dx in (-1,0,1):\n",
    "            for dy in (-1,0,1):\n",
    "                cand += buckets.get((kx+dx, ky+dy), [])\n",
    "        for i in idxs:\n",
    "            for j in cand:\n",
    "                if j <= i: continue\n",
    "                if haversine_m(points[i][\"lat\"], points[i][\"lon\"], points[j][\"lat\"], points[j][\"lon\"]) <= eps_m:\n",
    "                    nbrs[i].append(j); nbrs[j].append(i)\n",
    "    cid = 0\n",
    "    for i in range(n):\n",
    "        if visited[i]: continue\n",
    "        visited[i] = True\n",
    "        if len(nbrs[i]) + 1 < min_samples:\n",
    "            clusters[i] = -1; continue\n",
    "        clusters[i] = cid\n",
    "        seeds = list(nbrs[i]); k = 0\n",
    "        while k < len(seeds):\n",
    "            j = seeds[k]\n",
    "            if not visited[j]:\n",
    "                visited[j] = True\n",
    "                if len(nbrs[j]) + 1 >= min_samples:\n",
    "                    for q in nbrs[j]:\n",
    "                        if q not in seeds: seeds.append(q)\n",
    "            if clusters[j] < 0: clusters[j] = cid\n",
    "            k += 1\n",
    "        cid += 1\n",
    "    return clusters\n",
    "\n",
    "def ensure_clusters(hotspots):\n",
    "    clusters = cluster_dbscan(hotspots, eps_m=EPS_METERS, min_samples=MIN_SAMPLES)\n",
    "    if not any(c >= 0 for c in clusters):\n",
    "        clusters = cluster_dbscan(hotspots, eps_m=EPS_METERS*1.6, min_samples=max(3, MIN_SAMPLES-2))\n",
    "    if not any(c >= 0 for c in clusters):\n",
    "        clusters = [0 for _ in hotspots]\n",
    "    return clusters\n",
    "\n",
    "def build_concave_envelopes(hotspots, clusters, metric_crs, alpha_m=ALPHA_M, min_pts=MIN_ENVELOPE_POINTS):\n",
    "    \"\"\"Returns dict cid -> list[Polygon in WGS84], tiny parts removed.\"\"\"\n",
    "    by_cluster = {}\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        if cid < 0: continue\n",
    "        by_cluster.setdefault(cid, []).append(hp)\n",
    "    out = {}\n",
    "    for cid, pts in by_cluster.items():\n",
    "        if len(pts) < min_pts: continue\n",
    "        pts_wgs = gpd.GeoSeries([Point(p[\"lon\"], p[\"lat\"]) for p in pts], crs=\"EPSG:4326\").to_crs(metric_crs)\n",
    "        buf = pts_wgs.buffer(alpha_m)\n",
    "        merged = unary_union(list(buf.values))\n",
    "        shell = merged.buffer(-alpha_m)\n",
    "        geom = shell if not shell.is_empty else merged.convex_hull\n",
    "        polys = []\n",
    "        if geom.geom_type == \"Polygon\": polys=[geom]\n",
    "        elif geom.geom_type == \"MultiPolygon\": polys=list(geom.geoms)\n",
    "        kept = [g for g in polys if float(g.area) >= MIN_POLY_AREA_M2]\n",
    "        if not kept: continue\n",
    "        kept_wgs = gpd.GeoSeries(kept, crs=metric_crs).to_crs(epsg=4326).tolist()\n",
    "        out[cid] = kept_wgs\n",
    "    return out\n",
    "\n",
    "def severity_from_z(z):\n",
    "    if z >= SEVERE_Z: return \"severe\"\n",
    "    if z >= HIGH_Z:   return \"high\"\n",
    "    if z >= ELEV_Z:   return \"elev\"\n",
    "    return None\n",
    "\n",
    "def z_to_level_text(z):\n",
    "    if z is None: return \"n/a\"\n",
    "    if z >= 2.0: return \"Very high (well above typical)\"\n",
    "    if z >= 1.0: return \"High (above typical)\"\n",
    "    if z >= 0.5: return \"Slightly elevated\"\n",
    "    if z > -0.5: return \"Around typical\"\n",
    "    return \"Below typical\"\n",
    "\n",
    "def season_bands_today():\n",
    "    \"\"\"Return (pre_monsoon, monsoon, post_monsoon) windows as (start_iso,end_iso).\"\"\"\n",
    "    y = date.today().year\n",
    "    pre = (date(y,3,1),  date(y,5,31))\n",
    "    mon = (date(y,6,1),  date(y,9,15))\n",
    "    post= (date(y,9,16), date(y,11,30))\n",
    "    # convert to string ISO\n",
    "    return [tuple(map(str, w)) for w in (pre, mon, post)]\n",
    "\n",
    "# ------------------ EARTH ENGINE IMAGES ------------------\n",
    "def lst_day_mean(aoi, start_iso, end_iso):\n",
    "    coll = (ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "            .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "            .select(\"LST_Day_1km\").map(lambda img: img.updateMask(img.gt(0))))\n",
    "    lst_c = coll.mean().multiply(0.02).subtract(273.15).rename(\"lst_day_c\").clip(aoi)\n",
    "    return lst_c\n",
    "\n",
    "def lst_night_mean(aoi, start_iso, end_iso):\n",
    "    coll = (ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "            .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "            .select(\"LST_Night_1km\").map(lambda img: img.updateMask(img.gt(0))))\n",
    "    lst_c = coll.mean().multiply(0.02).subtract(273.15).rename(\"lst_night_c\").clip(aoi)\n",
    "    return lst_c\n",
    "\n",
    "def lst_day_daily_collection(aoi, start_iso, end_iso):\n",
    "    coll = (ee.ImageCollection(\"MODIS/061/MOD11A1\")\n",
    "            .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "            .select(\"LST_Day_1km\").map(lambda img: img.updateMask(img.gt(0))))\n",
    "    return coll\n",
    "\n",
    "def sentinel2_ndvi_recent(aoi, months_back=6):\n",
    "    start = date.today() - timedelta(days=months_back*30)\n",
    "    end   = date.today()\n",
    "    # S2 SR (surface reflectance), simple cloud mask via QA60\n",
    "    def mask_s2_sr(img):\n",
    "        qa = img.select('QA60')\n",
    "        cloud = qa.bitwiseAnd(1<<10).Or(qa.bitwiseAnd(1<<11))\n",
    "        return img.updateMask(cloud.eq(0))\n",
    "    coll = (ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "            .filterBounds(aoi).filterDate(str(start), str(end))\n",
    "            .map(mask_s2_sr))\n",
    "    med = coll.median()\n",
    "    ndvi = med.normalizedDifference(['B8','B4']).rename('ndvi').clip(aoi)\n",
    "    return ndvi\n",
    "\n",
    "def worldcover_map(year=2021):\n",
    "    # ESA WorldCover v200 (2021/2020). Built-up class = 50, Tree cover = 10\n",
    "    try:\n",
    "        img = ee.Image(\"ESA/WorldCover/v200\").select('Map')\n",
    "        return img\n",
    "    except Exception:\n",
    "        try:\n",
    "            return ee.Image(\"ESA/WorldCover/v100\").select('Map')\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def population_image(aoi):\n",
    "    # Prefer WorldPop; fall back to GHSL/GPW if needed\n",
    "    for yr in [2025, 2023, 2022, 2021, 2020, 2019]:\n",
    "        try:\n",
    "            col = (ee.ImageCollection(\"WorldPop/GP/100m/pop\")\n",
    "                   .filterBounds(aoi).filter(ee.Filter.eq('year', yr)))\n",
    "            if col.size().getInfo() > 0:\n",
    "                img = col.mosaic()\n",
    "                bname = img.bandNames().getInfo()[0]\n",
    "                return img.select(bname, [\"pop\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        img = ee.Image(\"JRC/GHSL/P2019/POP_GLOBE_R2019A\")\n",
    "        bands = [b for b in img.bandNames().getInfo() if \"2020\" in b or \"2015\" in b]\n",
    "        if bands: return img.select(bands[0], [\"pop\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        col = ee.ImageCollection(\"CIESIN/GPWv411/GPW_Population_Count\").filter(ee.Filter.eq(\"year\", 2020))\n",
    "        img = col.first()\n",
    "        if img:\n",
    "            b = img.bandNames().getInfo()[0]\n",
    "            return img.select(b, [\"pop\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def worldpop_children_elderly(aoi):\n",
    "    \"\"\"Try to assemble children% and elderly% rasters (defensive). Returns (child_img, elder_img) as fractions 0..1 or (None,None).\"\"\"\n",
    "    # WorldPop has age-sex layers by country; availability varies.\n",
    "    candidates = [\n",
    "        \"WorldPop/GP/100m/pop_age_sex\",  # generic\n",
    "        \"WorldPop/GP/100m/pop_age_sex_cons_unadj\",\n",
    "        \"WorldPop/GP/100m/pop_age_sex_unadj\"\n",
    "    ]\n",
    "    for ds in candidates:\n",
    "        try:\n",
    "            col = ee.ImageCollection(ds).filterBounds(aoi)\n",
    "            if col.size().getInfo() == 0: continue\n",
    "            # Heuristic: sum young (0-4, 5-9) and elderly (65+). Band names differ; try common patterns.\n",
    "            first = col.first()\n",
    "            bands = first.bandNames().getInfo()\n",
    "            # guess bands\n",
    "            young_bands = [b for b in bands if any(k in b.lower() for k in [\"0\",\"1-4\",\"0-4\",\"5-9\"])]\n",
    "            elder_bands = [b for b in bands if any(k in b.lower() for k in [\"65\",\"65-69\",\"70\",\"75\",\"80\",\"85\"])]\n",
    "            total = first.reduce(ee.Reducer.sum())\n",
    "            young = first.select(young_bands).reduce(ee.Reducer.sum())\n",
    "            elder = first.select(elder_bands).reduce(ee.Reducer.sum())\n",
    "            child_frac = young.divide(total).rename(\"child_frac\")\n",
    "            elder_frac = elder.divide(total).rename(\"elder_frac\")\n",
    "            return child_frac, elder_frac\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None, None\n",
    "\n",
    "# ------------------ REDUCERS ------------------\n",
    "def reduce_mean(image, geom, scale):\n",
    "    try:\n",
    "        val = image.reduceRegion(ee.Reducer.mean(), geom, scale=scale,\n",
    "                                 maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE)\n",
    "        b = image.bandNames().getInfo()[0]\n",
    "        v = val.get(b)\n",
    "        return float(ee.Number(ee.Algorithms.If(v, v, None)).getInfo())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def reduce_sum(image, geom, scale):\n",
    "    try:\n",
    "        val = image.reduceRegion(ee.Reducer.sum(), geom, scale=scale,\n",
    "                                 maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE)\n",
    "        v = val.get(image.bandNames().get(0))\n",
    "        return float(ee.Number(ee.Algorithms.If(v, v, 0)).getInfo())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fraction_of_mask(mask_img, geom, scale):\n",
    "    \"\"\"mask_img: 1 where class present, else 0. Returns fraction 0..1.\"\"\"\n",
    "    try:\n",
    "        stats = mask_img.reduceRegion(ee.Reducer.mean(), geom, scale=scale,\n",
    "                                      maxPixels=1e13, bestEffort=True, tileScale=EE_TILE_SCALE)\n",
    "        v = stats.get(mask_img.bandNames().get(0))\n",
    "        return float(ee.Number(ee.Algorithms.If(v, v, 0)).getInfo())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ------------------ OSM ------------------\n",
    "def osm_geoms_from_polygon(aoi_poly_wgs84, tags_dict):\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.timeout = 180\n",
    "    try:\n",
    "        from osmnx.features import features_from_polygon as osm_features_from_polygon\n",
    "    except Exception:\n",
    "        try:\n",
    "            from osmnx import geometries_from_polygon as osm_features_from_polygon\n",
    "        except Exception:\n",
    "            raise SystemExit(\"OSMnx missing polygon geometries. pip install --upgrade osmnx\")\n",
    "    layers = []\n",
    "    for k, v in tags_dict.items():\n",
    "        try:\n",
    "            g = osm_features_from_polygon(aoi_poly_wgs84, tags={k: v})\n",
    "            if g is not None and not g.empty:\n",
    "                layers.append(g)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not layers:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    base_crs = layers[0].crs or \"EPSG:4326\"\n",
    "    all_feats = gpd.GeoDataFrame(gpd.pd.concat(layers, ignore_index=True), crs=base_crs)\n",
    "    all_feats = all_feats[all_feats.geometry.notna()].copy()\n",
    "    return all_feats.to_crs(epsg=4326)\n",
    "\n",
    "def count_sensitive_inside(sens_gdf, polygon):\n",
    "    if sens_gdf is None or sens_gdf.empty:\n",
    "        return dict(schools=0, clinics=0, hospitals=0, elder_homes=0)\n",
    "    try:\n",
    "        idx = sens_gdf.sindex\n",
    "        sub = sens_gdf.iloc[list(idx.intersection(polygon.bounds))]\n",
    "        inside = sub[sub.geometry.intersects(polygon)]\n",
    "    except Exception:\n",
    "        inside = sens_gdf[sens_gdf.geometry.intersects(polygon)]\n",
    "    res = dict(schools=0, clinics=0, hospitals=0, elder_homes=0)\n",
    "    if inside.empty:\n",
    "        return res\n",
    "    if \"amenity\" in inside.columns:\n",
    "        res[\"schools\"] = int((inside[\"amenity\"]==\"school\").sum())\n",
    "        res[\"clinics\"] = int(((inside[\"amenity\"]==\"clinic\") | (inside[\"amenity\"]==\"doctors\")).sum())\n",
    "        res[\"hospitals\"] = int((inside[\"amenity\"]==\"hospital\").sum())\n",
    "    if \"social_facility\" in inside.columns:\n",
    "        res[\"elder_homes\"] = int(inside[\"social_facility\"].isin([\"nursing_home\",\"assisted_living\"]).sum())\n",
    "    return res\n",
    "\n",
    "# ------------------ HEAT INDEX ------------------\n",
    "def heat_index_c_from_t_rh(t_air_c, rh_pct):\n",
    "    \"\"\"NOAA HI formula (approx). Inputs: air T in °C, RH in %.\"\"\"\n",
    "    if (t_air_c is None) or (rh_pct is None): return None\n",
    "    # Convert to F\n",
    "    T = t_air_c * 9/5 + 32.0\n",
    "    R = max(0.0, min(100.0, rh_pct))\n",
    "    HI = (-42.379 + 2.04901523*T + 10.14333127*R\n",
    "          - 0.22475541*T*R - 0.00683783*T*T - 0.05481717*R*R\n",
    "          + 0.00122874*T*T*R + 0.00085282*T*R*R - 0.00000199*T*T*R*R)\n",
    "    # adjustments (ignored for brevity)\n",
    "    hi_c = (HI - 32.0) * 5/9\n",
    "    return hi_c\n",
    "\n",
    "# ------------------ MAP ------------------\n",
    "def build_map(aoi_bbox, hotspots, selected_cluster_polys):\n",
    "    lat_c = (aoi_bbox[1] + aoi_bbox[3]) / 2.0\n",
    "    lon_c = (aoi_bbox[0] + aoi_bbox[2]) / 2.0\n",
    "    m = folium.Map(location=[lat_c, lon_c], zoom_start=12,\n",
    "                   tiles=\"cartodbpositron\", control_scale=True)\n",
    "\n",
    "    # Cluster polygons (Top-3)\n",
    "    for rank, (cid, poly) in enumerate(selected_cluster_polys, start=1):\n",
    "        folium.GeoJson(\n",
    "            data=poly.__geo_interface__,\n",
    "            name=f\"Hot zone #{rank} (cluster {cid})\",\n",
    "            style_function=lambda _ : {\"color\": COLORS[\"envelope\"], \"weight\": 3, \"fillColor\": COLORS[\"envelope\"], \"fillOpacity\": 0.10},\n",
    "            tooltip=f\"Hot zone #{rank} (cluster {cid})\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Hotspot markers only for selected clusters\n",
    "    kept_cids = {cid for cid, _ in selected_cluster_polys}\n",
    "    for hp in hotspots:\n",
    "        if hp.get(\"_cid\") not in kept_cids: continue\n",
    "        sev = severity_from_z(hp[\"lst_z\"])\n",
    "        if sev is None: continue\n",
    "        color = COLORS[sev]\n",
    "        radius = 6 if sev == \"elev\" else (8 if sev == \"high\" else 10)\n",
    "        folium.CircleMarker(\n",
    "            location=(hp[\"lat\"], hp[\"lon\"]),\n",
    "            radius=radius,\n",
    "            color=color, fill=True, fill_color=color, fill_opacity=0.95,\n",
    "            tooltip=f\"{sev.upper()} UHI hotspot\",\n",
    "            popup=(f\"<b>{sev.upper()} UHI hotspot</b><br>\"\n",
    "                   f\"Surface temp (day): {hp['lst_c']:.1f} °C<br>\"\n",
    "                   f\"Vs city typical: {z_to_level_text(hp['lst_z'])} (z≈{hp['lst_z']:.2f})\")\n",
    "        ).add_to(m)\n",
    "\n",
    "    MiniMap(toggle_display=True, position=\"bottomright\").add_to(m)\n",
    "    Fullscreen().add_to(m)\n",
    "    MousePosition(position=\"topright\", separator=\" | \", prefix=\"Lat/Lon:\").add_to(m)\n",
    "    MeasureControl(position=\"topright\", primary_length_unit='kilometers').add_to(m)\n",
    "\n",
    "    legend = f\"\"\"\n",
    "    <div style=\"position: fixed; bottom: 18px; left: 18px; z-index:9999; background: white;\n",
    "                padding: 10px 12px; border: 1px solid #ccc; border-radius: 6px; font-size: 13px;\">\n",
    "      <b>Urban Heat Island Hotspots</b> (last {DAYS_BACK} days)<br>\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:{COLORS['severe']};border:1px solid {COLORS['severe']};\"></span>\n",
    "      Severe (≥{SEVERE_Z}σ) &nbsp;\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:{COLORS['high']};border:1px solid {COLORS['high']};\"></span>\n",
    "      High ({HIGH_Z}–{SEVERE_Z}σ) &nbsp;\n",
    "      <span style=\"display:inline-block;width:12px;height:12px;background:{COLORS['elev']};border:1px solid {COLORS['elev']};\"></span>\n",
    "      Elevated ({ELEV_Z}–{HIGH_Z}σ)\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend))\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "def main():\n",
    "    print(\"Initializing Earth Engine…\")\n",
    "    ee_init_headless()\n",
    "    aoi = ee.Geometry.Rectangle(AOI_BBOX)\n",
    "    start_iso, end_iso = str(START), str(END)\n",
    "    print(f\"AOI: {AOI_BBOX} | Window: {start_iso} → {end_iso}\")\n",
    "\n",
    "    # Day & night LST means\n",
    "    lst_day_img   = lst_day_mean(aoi, start_iso, end_iso)\n",
    "    lst_night_img = lst_night_mean(aoi, start_iso, end_iso)\n",
    "\n",
    "    # Sample grid for clustering\n",
    "    fc = lst_day_img.sample(region=aoi, scale=SCALE_M, geometries=True)\n",
    "    feats = fc.limit(MAX_POINTS).getInfo().get(\"features\", [])\n",
    "    rows = []\n",
    "    for f in feats:\n",
    "        geom = f.get(\"geometry\", {})\n",
    "        if geom.get(\"type\") != \"Point\": continue\n",
    "        lon, lat = geom[\"coordinates\"]\n",
    "        v = f.get(\"properties\", {}).get(\"lst_day_c\", None)\n",
    "        if v is None or not math.isfinite(v): continue\n",
    "        rows.append({\"lat\": float(lat), \"lon\": float(lon), \"lst_c\": float(v)})\n",
    "\n",
    "    if not rows:\n",
    "        raise SystemExit(\"No samples. Try increasing DAYS_BACK or MAX_POINTS.\")\n",
    "\n",
    "    # z-scores & pick hotspots\n",
    "    lst_vals = [r[\"lst_c\"] for r in rows]\n",
    "    lst_z = zscores(lst_vals)\n",
    "    pcts  = [p_rank(lst_z, v) for v in lst_z]\n",
    "    hotspots = []\n",
    "    for r, z, pr in zip(rows, lst_z, pcts):\n",
    "        if (z >= Z_THRESHOLD) or (pr >= PCTL_THRESHOLD):\n",
    "            hotspots.append({\"lat\": r[\"lat\"], \"lon\": r[\"lon\"], \"lst_c\": r[\"lst_c\"], \"lst_z\": z, \"percentile\": pr})\n",
    "    hotspots.sort(key=lambda x: x[\"lst_z\"], reverse=True)\n",
    "\n",
    "    # Cluster & envelopes\n",
    "    clusters = ensure_clusters(hotspots)\n",
    "    for hp, cid in zip(hotspots, clusters):\n",
    "        hp[\"_cid\"] = cid\n",
    "    metric_crs = utm_crs_from_bbox(AOI_BBOX)\n",
    "    envelopes_by_cid = build_concave_envelopes(hotspots, clusters, metric_crs, alpha_m=ALPHA_M, min_pts=MIN_ENVELOPE_POINTS)\n",
    "    if not envelopes_by_cid:\n",
    "        envelopes_by_cid = build_concave_envelopes(hotspots, [0]*len(hotspots), metric_crs, alpha_m=ALPHA_M, min_pts=3)\n",
    "\n",
    "    # Union per cluster & areas\n",
    "    cluster_union = {}\n",
    "    cluster_area_km2 = {}\n",
    "    for cid, polys in envelopes_by_cid.items():\n",
    "        if not polys: continue\n",
    "        polys_proj = gpd.GeoSeries(polys, crs=\"EPSG:4326\").to_crs(metric_crs)\n",
    "        union_geom = unary_union(list(polys_proj.values))\n",
    "        area_km2 = float(union_geom.area / 1e6)\n",
    "        if area_km2 <= 0: continue\n",
    "        union_wgs = gpd.GeoSeries([union_geom], crs=metric_crs).to_crs(epsg=4326).iloc[0]\n",
    "        cluster_union[cid] = union_wgs\n",
    "        cluster_area_km2[cid] = area_km2\n",
    "\n",
    "    # Top-3 by area\n",
    "    top_cids = sorted(cluster_area_km2.keys(), key=lambda c: cluster_area_km2[c], reverse=True)[:3]\n",
    "    selected = [(cid, cluster_union[cid]) for cid in top_cids]\n",
    "\n",
    "    # ---- Ancillary datasets ----\n",
    "    wc = worldcover_map(year=2021)\n",
    "    ndvi_img = sentinel2_ndvi_recent(aoi, months_back=6)\n",
    "    pop_img  = population_image(aoi)\n",
    "    child_img, elder_img = worldpop_children_elderly(aoi)  # may be None\n",
    "\n",
    "    # ERA5 (air temp & dewpoint for heat index proxy)\n",
    "    try:\n",
    "        era5 = ee.ImageCollection(\"ECMWF/ERA5/DAILY\").filterDate(start_iso, end_iso).filterBounds(aoi)\n",
    "        t2m = era5.select(\"mean_2m_air_temperature\").mean().subtract(273.15).rename(\"t2m_c\").clip(aoi)\n",
    "        td2m = era5.select(\"mean_2m_dewpoint_temperature\").mean().subtract(273.15).rename(\"td2m_c\").clip(aoi)\n",
    "    except Exception:\n",
    "        t2m = None; td2m = None\n",
    "\n",
    "    # Season windows\n",
    "    (pre_s, pre_e), (mon_s, mon_e), (post_s, post_e) = season_bands_today()\n",
    "    lst_pre  = lst_day_mean(aoi, pre_s,  pre_e)\n",
    "    lst_mon  = lst_day_mean(aoi, mon_s,  mon_e)\n",
    "    lst_post = lst_day_mean(aoi, post_s, post_e)\n",
    "\n",
    "    # Extreme hot periods (use 8-day MOD11A2; count # composites above 90th pct over AOI)\n",
    "    coll_8d = (ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "               .filterBounds(aoi).filterDate(start_iso, end_iso)\n",
    "               .select(\"LST_Day_1km\").map(lambda img: img.updateMask(img.gt(0))))\n",
    "    # 90th percentile over AOI\n",
    "    try:\n",
    "        pct90 = coll_8d.reduce(ee.Reducer.percentile([90])).multiply(0.02).subtract(273.15).rename(\"p90\")\n",
    "    except Exception:\n",
    "        pct90 = None\n",
    "\n",
    "    # OSM: buildings, sensitive sites, water\n",
    "    aoi_poly = aoi_polygon_wgs84()\n",
    "    try:\n",
    "        buildings = osm_geoms_from_polygon(aoi_poly, {\"building\": True})\n",
    "    except Exception:\n",
    "        buildings = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try:\n",
    "        sensitive = osm_geoms_from_polygon(aoi_poly, {\"amenity\": [\"school\",\"clinic\",\"hospital\",\"doctors\"],\n",
    "                                                      \"social_facility\": [\"nursing_home\",\"assisted_living\"]})\n",
    "    except Exception:\n",
    "        sensitive = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try:\n",
    "        water = osm_geoms_from_polygon(aoi_poly, {\"natural\": [\"water\"], \"waterway\": [\"river\",\"canal\"], \"landuse\": [\"reservoir\"]})\n",
    "    except Exception:\n",
    "        water = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "\n",
    "    # Print summaries\n",
    "    print(\"\\n================= Top UHI clusters (area-wise) =================\")\n",
    "    print(\"(z (σ): standardized vs city typical; 0 ≈ typical)\")\n",
    "\n",
    "    # Helpers for class fractions\n",
    "    def frac_worldcover(mask_vals, poly):\n",
    "        if wc is None: return None\n",
    "        geom = ee.Geometry(poly.__geo_interface__)\n",
    "        # allow list or int\n",
    "        mask = None\n",
    "        if isinstance(mask_vals, (list, tuple)):\n",
    "            mask = wc.remap(mask_vals, [1]*len(mask_vals), 0).rename(\"m\")\n",
    "        else:\n",
    "            mask = wc.eq(mask_vals).rename(\"m\")\n",
    "        return fraction_of_mask(mask, geom, scale=20)\n",
    "\n",
    "    # Loop over selected clusters\n",
    "    for rank, (cid, poly) in enumerate(selected, start=1):\n",
    "        # Geometry conversions\n",
    "        poly_series = gpd.GeoSeries([poly], crs=\"EPSG:4326\").to_crs(utm_crs_from_bbox(AOI_BBOX))\n",
    "        area_km2 = float(poly_series.area.iloc[0] / 1e6)\n",
    "        geom = ee.Geometry(poly.__geo_interface__)\n",
    "\n",
    "        # Population & vulnerability\n",
    "        pop_sum = reduce_sum(pop_img, geom, scale=100) if pop_img is not None else None\n",
    "        child_pct = None; elder_pct = None\n",
    "        if (child_img is not None) and (elder_img is not None):\n",
    "            child_mean = reduce_mean(child_img, geom, scale=100)\n",
    "            elder_mean = reduce_mean(elder_img, geom, scale=100)\n",
    "            child_pct = None if child_mean is None else (100.0*child_mean)\n",
    "            elder_pct = None if elder_mean is None else (100.0*elder_mean)\n",
    "\n",
    "        # Impervious & canopy; NDVI mean\n",
    "        imperv_pct = None\n",
    "        tree_pct = None\n",
    "        if wc is not None:\n",
    "            imperv_pct = None if (frac_worldcover(50, poly) is None) else (100.0 * frac_worldcover(50, poly))\n",
    "            tree_pct   = None if (frac_worldcover(10, poly) is None) else (100.0 * frac_worldcover(10, poly))\n",
    "        ndvi_mean = reduce_mean(ndvi_img, geom, scale=20) if ndvi_img is not None else None\n",
    "\n",
    "        # Buildings: roof area, cool-roof potential, height/density proxy\n",
    "        large_roof_threshold_m2 = 500.0\n",
    "        b_in = gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "        try:\n",
    "            if buildings is not None and not buildings.empty:\n",
    "                try:\n",
    "                    idx = buildings.sindex\n",
    "                    cand = buildings.iloc[list(idx.intersection(poly.bounds))]\n",
    "                    b_in = cand[cand.geometry.intersects(poly)].copy()\n",
    "                except Exception:\n",
    "                    b_in = buildings[buildings.geometry.intersects(poly)].copy()\n",
    "        except Exception:\n",
    "            pass\n",
    "        roof_area_m2 = 0.0\n",
    "        large_roofs_m2 = 0.0\n",
    "        large_roofs_n  = 0\n",
    "        mean_levels = None\n",
    "        if b_in is not None and not b_in.empty:\n",
    "            b_proj = b_in.to_crs(utm_crs_from_bbox(AOI_BBOX))\n",
    "            areas = b_proj.geometry.area.fillna(0.0)\n",
    "            roof_area_m2 = float(areas.sum())\n",
    "            large_mask = areas >= large_roof_threshold_m2\n",
    "            large_roofs_m2 = float(areas[large_mask].sum())\n",
    "            large_roofs_n  = int(large_mask.sum())\n",
    "            # height/levels proxy\n",
    "            lvl = []\n",
    "            for _, r in b_in.iterrows():\n",
    "                lv = r.get(\"building:levels\") or r.get(\"levels\") or r.get(\"height\")\n",
    "                try:\n",
    "                    if isinstance(lv, str) and \"m\" in lv: lv = lv.replace(\"m\",\"\").strip()\n",
    "                    lvf = float(lv)\n",
    "                    # if height in meters, roughly convert to levels (3 m/level)\n",
    "                    if lvf > 40: lvf = lvf / 3.0\n",
    "                    lvl.append(lvf)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if lvl: mean_levels = sum(lvl)/len(lvl)\n",
    "\n",
    "        # Informal housing proxy: roof m² per person (lower → denser/informal)\n",
    "        informal_proxy = None\n",
    "        if (pop_sum is not None) and pop_sum > 0 and roof_area_m2 > 0:\n",
    "            m2_per_person = roof_area_m2 / pop_sum\n",
    "            informal_proxy = (\"likely informal/very dense\" if m2_per_person < 8.0\n",
    "                              else \"medium density\" if m2_per_person < 20.0\n",
    "                              else \"lower density\")\n",
    "        # Sensitive sites inside\n",
    "        sens = count_sensitive_inside(sensitive, poly)\n",
    "\n",
    "        # Water distance\n",
    "        dist_water_m = None\n",
    "        if water is not None and not water.empty:\n",
    "            try:\n",
    "                w_proj = water.to_crs(utm_crs_from_bbox(AOI_BBOX))\n",
    "                p_proj = poly_series.iloc[0]\n",
    "                dist_water_m = float(w_proj.distance(p_proj).min())\n",
    "            except Exception:\n",
    "                dist_water_m = None\n",
    "\n",
    "        # Day/Night means & delta\n",
    "        day_c   = reduce_mean(lst_day_img,   geom, scale=1000)\n",
    "        night_c = reduce_mean(lst_night_img, geom, scale=1000)\n",
    "        dn_delta = None if (day_c is None or night_c is None) else (day_c - night_c)\n",
    "\n",
    "        # Seasonality (pre/monsoon/post)\n",
    "        pre_c  = reduce_mean(lst_pre,  geom, scale=1000)\n",
    "        mon_c  = reduce_mean(lst_mon,  geom, scale=1000)\n",
    "        post_c = reduce_mean(lst_post, geom, scale=1000)\n",
    "\n",
    "        # Extreme hot periods (8-day composites above AOI 90th pct)\n",
    "        extreme_cnt = None\n",
    "        if pct90 is not None:\n",
    "            try:\n",
    "                # Count composites whose mean over poly > p90 over AOI\n",
    "                # Build list of images in period\n",
    "                imgs = coll_8d.toList(coll_8d.size())\n",
    "                n = int(coll_8d.size().getInfo())\n",
    "                cnt = 0\n",
    "                thr_c = reduce_mean(pct90, ee.Geometry(aoi), scale=1000)\n",
    "                for k in range(n):\n",
    "                    im = ee.Image(imgs.get(k)).multiply(0.02).subtract(273.15).rename(\"c\")\n",
    "                    mval = reduce_mean(im, geom, scale=1000)\n",
    "                    if (mval is not None) and (thr_c is not None) and (mval > thr_c):\n",
    "                        cnt += 1\n",
    "                extreme_cnt = cnt\n",
    "            except Exception:\n",
    "                extreme_cnt = None\n",
    "\n",
    "        # Heat index proxy (ERA5)\n",
    "        hi_c = None\n",
    "        if (t2m is not None) and (td2m is not None):\n",
    "            t_mean = reduce_mean(t2m, geom, scale=9000)\n",
    "            td_mean= reduce_mean(td2m, geom, scale=9000)\n",
    "            if (t_mean is not None) and (td_mean is not None):\n",
    "                # RH from T & Td (Magnus)\n",
    "                T = t_mean\n",
    "                Td = td_mean\n",
    "                es = 6.1094 * math.exp(17.625*Td/(243.04+Td))\n",
    "                e  = 6.1094 * math.exp(17.625*T /(243.04+T))\n",
    "                rh = max(0.0, min(100.0, 100.0*es/e)) if e > 0 else None\n",
    "                hi_c = heat_index_c_from_t_rh(T, rh) if rh is not None else None\n",
    "\n",
    "        # Print (plain language)\n",
    "        print(f\"\\nHot zone #{rank} (cluster {cid})\")\n",
    "        print(f\"• Area: ~{area_km2:.2f} km²\")\n",
    "        print(f\"• People living inside: {(f'{int(pop_sum):,}' if pop_sum is not None else 'n/a')}\")\n",
    "        if (child_pct is not None) or (elder_pct is not None):\n",
    "            ch = f\"{child_pct:.1f}%\" if child_pct is not None else \"n/a\"\n",
    "            el = f\"{elder_pct:.1f}%\" if elder_pct is not None else \"n/a\"\n",
    "            print(f\"• Vulnerable groups: children {ch}, elderly {el}\")\n",
    "        else:\n",
    "            print(f\"• Vulnerable groups: n/a\")\n",
    "        if informal_proxy is not None:\n",
    "            print(f\"• Density / informal proxy: {informal_proxy}\")\n",
    "        else:\n",
    "            print(f\"• Density / informal proxy: n/a\")\n",
    "\n",
    "        imp = f\"{imperv_pct:.1f}%\" if imperv_pct is not None else \"n/a\"\n",
    "        trp = f\"{tree_pct:.1f}%\" if tree_pct is not None else \"n/a\"\n",
    "        ndv = f\"{ndvi_mean:.2f}\" if ndvi_mean is not None else \"n/a\"\n",
    "        print(f\"• Surfaces: impervious {imp} | tree canopy {trp} | mean NDVI {ndv}\")\n",
    "\n",
    "        print(f\"• Roof area total: {int(roof_area_m2):,} m² | large roofs: {int(large_roofs_n)} bldgs / {int(large_roofs_m2):,} m² (cool-roof potential)\")\n",
    "        if mean_levels is not None:\n",
    "            dens = (roof_area_m2 / (area_km2*1e6)) if area_km2>0 else None\n",
    "            dens_txt = f\"{dens*100:.1f}% footprint cover\" if dens is not None else \"n/a\"\n",
    "            print(f\"• Building height/density: mean levels ≈ {mean_levels:.1f} | {dens_txt}\")\n",
    "        else:\n",
    "            print(f\"• Building height/density: n/a\")\n",
    "\n",
    "        if dist_water_m is not None:\n",
    "            print(f\"• Nearest water: ~{dist_water_m:.0f} m → blue-corridor greening potential\")\n",
    "        else:\n",
    "            print(f\"• Nearest water: n/a\")\n",
    "\n",
    "        day_txt = f\"{day_c:.1f} °C\" if day_c is not None else \"n/a\"\n",
    "        night_txt = f\"{night_c:.1f} °C\" if night_c is not None else \"n/a\"\n",
    "        dnd_txt = (f\"{dn_delta:+.1f} °C (day − night)\" if dn_delta is not None else \"n/a\")\n",
    "        print(f\"• Day vs Night: day {day_txt} | night {night_txt} | Δ {dnd_txt}\")\n",
    "\n",
    "        seas_txt = []\n",
    "        seas_txt.append(f\"pre-monsoon {pre_c:.1f} °C\" if pre_c is not None else \"pre-monsoon n/a\")\n",
    "        seas_txt.append(f\"monsoon {mon_c:.1f} °C\" if mon_c is not None else \"monsoon n/a\")\n",
    "        seas_txt.append(f\"post-monsoon {post_c:.1f} °C\" if post_c is not None else \"post-monsoon n/a\")\n",
    "        print(\"• Seasonality: \" + \" | \".join(seas_txt))\n",
    "\n",
    "        if extreme_cnt is not None:\n",
    "            print(f\"• Extreme hot periods (8-day composites above local 90th pct): {extreme_cnt}\")\n",
    "        else:\n",
    "            print(f\"• Extreme hot periods: n/a\")\n",
    "\n",
    "        if hi_c is not None:\n",
    "            print(f\"• Heat index (air temp + humidity proxy): ~{hi_c:.1f} °C\")\n",
    "        else:\n",
    "            print(f\"• Heat index: n/a\")\n",
    "\n",
    "        # Sensitive sites\n",
    "        print(f\"• Sensitive sites: schools:{sens.get('schools',0)}, clinics:{sens.get('clinics',0)}, \"\n",
    "              f\"hospitals:{sens.get('hospitals',0)}, elder homes:{sens.get('elder_homes',0)}\")\n",
    "\n",
    "    # Map (Top-3 only)\n",
    "    m = build_map(AOI_BBOX, hotspots, selected)\n",
    "    os.makedirs(os.path.dirname(OUT_HTML), exist_ok=True)\n",
    "    m.save(OUT_HTML)\n",
    "    print(f\"\\n✅ Saved UHI map to: {OUT_HTML}\\nOpen in your browser to explore.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b0d03-1e3c-4262-8ae7-945c88bb6d83",
   "metadata": {},
   "source": [
    "# Satellite data this script uses (and what for)\n",
    "\n",
    "* **MODIS LST (Land Surface Temperature)**\n",
    "  **IDs:** `MODIS/061/MOD11A2` (8-day, 1 km) — bands `LST_Day_1km`, `LST_Night_1km`\n",
    "  **Used for:**\n",
    "\n",
    "  * **Daytime & nighttime LST means** (last `DAYS_BACK` days) and **day–night delta** inside each hot zone.\n",
    "  * **Seasonality** (pre-monsoon / monsoon / post-monsoon) via mean daytime LST in those windows.\n",
    "  * **Extreme hot periods**: count of 8-day composites with polygon-mean LST above the **AOI 90th percentile**.\n",
    "\n",
    "* **Sentinel-2 SR (MSI)**\n",
    "  **ID:** `COPERNICUS/S2_SR`\n",
    "  **Used for:** **NDVI** (from bands **B8** NIR and **B4** red) to report **mean NDVI** inside each hot zone.\n",
    "\n",
    "* **ESA WorldCover**\n",
    "  **IDs:** `ESA/WorldCover/v200` (fallback `v100`) — band `Map`\n",
    "  **Used for:** **Impervious surface %** (class **50**, built-up) and **Tree canopy %** (class **10**) within each polygon.\n",
    "\n",
    "* **WorldPop (Population)**\n",
    "  **ID:** `WorldPop/GP/100m/pop` (fallbacks: `JRC/GHSL/P2019/POP_GLOBE_R2019A`, `CIESIN/GPWv411/GPW_Population_Count`)\n",
    "  **Used for:** **Population inside** each hot zone (sum of residents).\n",
    "\n",
    "* **WorldPop age/sex (if available)**\n",
    "  **IDs:** `WorldPop/GP/100m/pop_age_sex*`\n",
    "  **Used for:** **Children %** and **Elderly %** (vulnerability overlay) inside each polygon.\n",
    "\n",
    "> **Non-satellite context (for completeness):**\n",
    "> **OpenStreetMap** is used for **buildings/roof area**, **sensitive sites** (schools/clinics/hospitals/elder homes), **distance to water**, and a simple **density/informal housing proxy** (roof m² per person).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de25dc0-2f6b-42ef-a472-4befc7564ef5",
   "metadata": {},
   "source": [
    "# Prompt Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352cd8e-5e40-4ab1-b7b7-cb02c0783612",
   "metadata": {},
   "source": [
    "You are an urban planner tasked with analyzing candidate sites, pollution/heat clusters, and urban heat island (UHI) zones.\n",
    "Your role is to generate actionable, clear, and detailed urban planning guidelines for decision-making.\n",
    "Write your response in structured bullet points so it is easy to read.\n",
    "\n",
    "📥 Input (context provided to you will look like this):\n",
    "\n",
    "Candidate sites with details:\n",
    "\n",
    "Coordinates (Lat, Lon: {latitude}, {longitude})\n",
    "\n",
    "Water access: {water proximity, wetness history}\n",
    "\n",
    "Soil: {pH, clay %, sand %, SOC g/kg, notes}\n",
    "\n",
    "Terrain: {HAND proxy, slope, low-lying risk}\n",
    "\n",
    "Heat: {temperature ranges, seasonality}\n",
    "\n",
    "Urban form: {building coverage, road density}\n",
    "\n",
    "Pollution/Cluster analysis:\n",
    "\n",
    "Cluster ID: {cluster_id}\n",
    "\n",
    "Area: {size km²}\n",
    "\n",
    "Current pollution/heat level: {z-score, relative to city typical}\n",
    "\n",
    "Seasonality: {better/worse in monsoon/dry season, Δ value}\n",
    "\n",
    "Sensitive sites: {schools, clinics, hospitals, elder homes}\n",
    "\n",
    "Industrial/point-source features: {list of sources}\n",
    "\n",
    "Urban Heat Island (UHI) hot zones:\n",
    "\n",
    "Hot zone ID: {zone_id}\n",
    "\n",
    "Area: {size km²}\n",
    "\n",
    "Vulnerable groups: {children %, elderly %}\n",
    "\n",
    "Surfaces: {impervious %, tree canopy %, NDVI}\n",
    "\n",
    "Roofs: {total m², large roofs potential m²}\n",
    "\n",
    "Building density: {footprint cover %, height levels}\n",
    "\n",
    "Nearest water: {m distance}\n",
    "\n",
    "Temperature: {day °C, night °C, seasonality, extremes}\n",
    "\n",
    "Sensitive sites: {schools, hospitals, clinics, elder homes}\n",
    "\n",
    "📤 Expected Output (LLM should generate):\n",
    "\n",
    "For each site/cluster/zone, provide:\n",
    "\n",
    "1. Suitability Assessment\n",
    "\n",
    "Strengths (what makes this site suitable for development/greenery)\n",
    "\n",
    "Weaknesses (risks, vulnerabilities, missing data)\n",
    "\n",
    "Key environmental and social concerns\n",
    "\n",
    "2. Urban Planning Recommendations\n",
    "\n",
    "Land-use suggestions (e.g., micro-park, housing, water retention, blue-green corridor)\n",
    "\n",
    "Infrastructure needs (roads, drainage, soil remediation, water treatment)\n",
    "\n",
    "Heat and pollution mitigation measures (e.g., tree planting, cool roofs, water buffers)\n",
    "\n",
    "Social considerations (protecting schools, clinics, vulnerable populations)\n",
    "\n",
    "3. Decision Guidelines\n",
    "\n",
    "Is this site/cluster recommended for development, conservation, or monitoring?\n",
    "\n",
    "Priority level (High/Medium/Low)\n",
    "\n",
    "Trade-offs (e.g., risk of flooding vs. community need)\n",
    "\n",
    "📌 Style Instructions:\n",
    "\n",
    "Always act as an expert urban planner.\n",
    "\n",
    "Write in clear, structured bullet points.\n",
    "\n",
    "Provide detailed, evidence-based reasoning.\n",
    "\n",
    "Highlight practical actions that local governments/NGOs could implement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
